#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì—‘ì…€ íŒŒì¼ í—¤ë” ë° ìƒ˜í”Œ ë°ì´í„° í™•ì¸ + AI ì •ë¦¬ + DB ì €ì¥
ë³µì¡í•œ í—¤ë” êµ¬ì¡° ëŒ€ì‘ + í•™ì› ë°ì´í„° íŠ¹í™”
"""

import pandas as pd
import sys
import os
from datetime import datetime
import json
from typing import Dict, List, Optional, Any
import re
import sqlite3

# ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

try:
    import google.generativeai as genai
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False
    print("âš ï¸ Google Generative AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. AI ê¸°ëŠ¥ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

from database.database import ChurchCRMDatabase
from database.models import OrganizationType

def load_env_file(env_path: str = None) -> Dict[str, str]:
    """í™˜ê²½ ë³€ìˆ˜ íŒŒì¼(.env) ë¡œë“œ"""
    if env_path is None:
        # ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ ê²½ë¡œ
        env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
    
    env_vars = {}
    
    try:
        if os.path.exists(env_path):
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"').strip("'")  # ë”°ì˜´í‘œ ì œê±°
                        env_vars[key] = value
            print(f"âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {env_path}")
        else:
            print(f"âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {env_path}")
    except Exception as e:
        print(f"âš ï¸ .env íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return env_vars

def _initialize_database(self):
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)"""
    try:
        print(f"ğŸ” ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ í™•ì¸ ì¤‘: {self.db_path}")
        
        # ê¸°ì¡´ DB íŒŒì¼ì´ ìˆìœ¼ë©´ ì™„ì „íˆ ê²€ì¦
        if os.path.exists(self.db_path):
            is_valid_db = False
            
            try:
                # íŒŒì¼ í¬ê¸° í™•ì¸ (0ë°”ì´íŠ¸ë©´ ì†ìƒ)
                file_size = os.path.getsize(self.db_path)
                if file_size == 0:
                    print(f"âš ï¸ ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {self.db_path} (í¬ê¸°: 0)")
                    is_valid_db = False
                else:
                    # SQLite íŒŒì¼ í—¤ë” í™•ì¸
                    with open(self.db_path, 'rb') as f:
                        header = f.read(16)
                        if not header.startswith(b'SQLite format 3'):
                            print(f"âš ï¸ SQLite íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {self.db_path}")
                            is_valid_db = False
                        else:
                            # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸
                            conn = sqlite3.connect(self.db_path)
                            conn.execute("SELECT 1")
                            conn.close()
                            is_valid_db = True
                            print(f"âœ… ìœ íš¨í•œ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼: {self.db_path}")
                            
            except Exception as e:
                print(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
                is_valid_db = False
            
            # ì†ìƒëœ íŒŒì¼ ì²˜ë¦¬
            if not is_valid_db:
                print(f"ğŸ”§ ì†ìƒëœ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
                
                # ë°±ì—… ì‹œë„
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_path = f"{self.db_path}.corrupted_{timestamp}"
                
                try:
                    # ê°•ì œë¡œ íŒŒì¼ ì‚­ì œ ì‹œë„
                    if os.path.exists(self.db_path):
                        # ì½ê¸° ì „ìš© ì†ì„± ì œê±°
                        os.chmod(self.db_path, 0o777)
                        
                        # ë°±ì—… ì‹œë„
                        try:
                            os.rename(self.db_path, backup_path)
                            print(f"ğŸ“ ì†ìƒëœ íŒŒì¼ ë°±ì—… ì™„ë£Œ: {backup_path}")
                        except:
                            # ë°±ì—… ì‹¤íŒ¨ ì‹œ ì§ì ‘ ì‚­ì œ
                            os.remove(self.db_path)
                            print(f"ğŸ—‘ï¸ ì†ìƒëœ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                            
                except Exception as delete_error:
                    print(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {delete_error}")
                    
                    # ìµœí›„ì˜ ìˆ˜ë‹¨: ë‹¤ë¥¸ íŒŒì¼ëª… ì‚¬ìš©
                    original_path = self.db_path
                    self.db_path = f"{original_path}.new_{timestamp}.db"
                    print(f"ğŸ”„ ìƒˆ íŒŒì¼ëª… ì‚¬ìš©: {self.db_path}")
        
        # ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
        print(f"ğŸ”„ ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì¤‘: {self.db_path}")
        
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        db_dir = os.path.dirname(self.db_path)
        if db_dir and not os.path.exists(db_dir):
            os.makedirs(db_dir)
        
        # ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
        return ChurchCRMDatabase(self.db_path)
        
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ìµœì¢… ì‹¤íŒ¨: {e}")
        
        # ë§ˆì§€ë§‰ ì‹œë„: ì„ì‹œ íŒŒì¼ëª…ìœ¼ë¡œ ìƒì„±
        temp_db_path = f"temp_academy_db_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
        print(f"ğŸš¨ ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì‹œë„: {temp_db_path}")
        
        try:
            self.db_path = temp_db_path
            return ChurchCRMDatabase(self.db_path)
        except Exception as final_error:
            print(f"âŒ ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±ë„ ì‹¤íŒ¨: {final_error}")
            raise

class ExcelAnalyzerWithAI:
    """Excel íŒŒì¼ ë¶„ì„ + AI ì •ë¦¬ + DB ë³€í™˜ í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, ai_api_key: str = None):
        self.excel_file_path = r"C:\Users\kimyh\makedb\Python\cradcrawl_adv\í•™ì›êµìŠµì†Œì •ë³´_2024ë…„10ì›”31ì¼ê¸°ì¤€20250617ìˆ˜ì •.xlsx"
        self.db_path = r"C:\Users\kimyh\makedb\Python\cradcrawl_adv\churches_crm_company.db"
        
        # AI ì„¤ì •
        self.use_ai = AI_AVAILABLE and ai_api_key is not None
        self.ai_model = None
        
        if self.use_ai:
            try:
                genai.configure(api_key=ai_api_key)
                self.ai_model = genai.GenerativeModel('gemini-pro')
                print("ğŸ¤– AI ê¸°ëŠ¥ í™œì„±í™”ë¨ (Gemini)")
            except Exception as e:
                print(f"âš ï¸ AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_ai = False
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
        self.db = self._initialize_database()
        
        # í†µê³„
        self.stats = {
            "total_processed": 0,
            "successfully_created": 0,
            "ai_enhanced": 0,
            "duplicates_skipped": 0,
            "failed": 0,
            "errors": []
        }
    
    def _initialize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)"""
        try:
            print(f"ğŸ” ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ í™•ì¸ ì¤‘: {self.db_path}")
            
            # ê¸°ì¡´ DB íŒŒì¼ì´ ìˆìœ¼ë©´ ì™„ì „íˆ ê²€ì¦
            if os.path.exists(self.db_path):
                is_valid_db = False
                
                try:
                    # íŒŒì¼ í¬ê¸° í™•ì¸ (0ë°”ì´íŠ¸ë©´ ì†ìƒ)
                    file_size = os.path.getsize(self.db_path)
                    if file_size == 0:
                        print(f"âš ï¸ ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {self.db_path} (í¬ê¸°: 0)")
                        is_valid_db = False
                    else:
                        # SQLite íŒŒì¼ í—¤ë” í™•ì¸
                        with open(self.db_path, 'rb') as f:
                            header = f.read(16)
                            if not header.startswith(b'SQLite format 3'):
                                print(f"âš ï¸ SQLite íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {self.db_path}")
                                is_valid_db = False
                            else:
                                # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸
                                conn = sqlite3.connect(self.db_path)
                                conn.execute("SELECT 1")
                                conn.close()
                                is_valid_db = True
                                print(f"âœ… ìœ íš¨í•œ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼: {self.db_path}")
                                
                except Exception as e:
                    print(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
                    is_valid_db = False
                
                # ì†ìƒëœ íŒŒì¼ ì²˜ë¦¬
                if not is_valid_db:
                    print(f"ğŸ”§ ì†ìƒëœ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
                    
                    # ë°±ì—… ì‹œë„
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    backup_path = f"{self.db_path}.corrupted_{timestamp}"
                    
                    try:
                        # ê°•ì œë¡œ íŒŒì¼ ì‚­ì œ ì‹œë„
                        if os.path.exists(self.db_path):
                            # ì½ê¸° ì „ìš© ì†ì„± ì œê±°
                            os.chmod(self.db_path, 0o777)
                            
                            # ë°±ì—… ì‹œë„
                            try:
                                os.rename(self.db_path, backup_path)
                                print(f"ğŸ“ ì†ìƒëœ íŒŒì¼ ë°±ì—… ì™„ë£Œ: {backup_path}")
                            except:
                                # ë°±ì—… ì‹¤íŒ¨ ì‹œ ì§ì ‘ ì‚­ì œ
                                os.remove(self.db_path)
                                print(f"ğŸ—‘ï¸ ì†ìƒëœ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                                
                    except Exception as delete_error:
                        print(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {delete_error}")
                        
                        # ìµœí›„ì˜ ìˆ˜ë‹¨: ë‹¤ë¥¸ íŒŒì¼ëª… ì‚¬ìš©
                        original_path = self.db_path
                        self.db_path = f"{original_path}.new_{timestamp}.db"
                        print(f"ğŸ”„ ìƒˆ íŒŒì¼ëª… ì‚¬ìš©: {self.db_path}")
            
            # ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            print(f"ğŸ”„ ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì¤‘: {self.db_path}")
            
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            db_dir = os.path.dirname(self.db_path)
            if db_dir and not os.path.exists(db_dir):
                os.makedirs(db_dir)
            
            # ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            return ChurchCRMDatabase(self.db_path)
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ìµœì¢… ì‹¤íŒ¨: {e}")
            
            # ë§ˆì§€ë§‰ ì‹œë„: ì„ì‹œ íŒŒì¼ëª…ìœ¼ë¡œ ìƒì„±
            temp_db_path = f"temp_academy_db_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            print(f"ğŸš¨ ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì‹œë„: {temp_db_path}")
            
            try:
                self.db_path = temp_db_path
                return ChurchCRMDatabase(self.db_path)
            except Exception as final_error:
                print(f"âŒ ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±ë„ ì‹¤íŒ¨: {final_error}")
                raise
    
    def analyze_excel_structure(self):
        """ì—‘ì…€ íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
        print("=" * 60)
        print("ğŸ” ì—‘ì…€ íŒŒì¼ êµ¬ì¡° ë¶„ì„ (ë³µì¡í•œ í—¤ë”)")
        print("=" * 60)
        
        try:
            # Excel íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(self.excel_file_path):
                print(f"âŒ Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.excel_file_path}")
                return None, []
            
            # ì›ë³¸ êµ¬ì¡° í™•ì¸
            print("ğŸ“‹ ì›ë³¸ íŒŒì¼ êµ¬ì¡° (ì²˜ìŒ 5í–‰):")
            df_raw = pd.read_excel(self.excel_file_path, header=None, nrows=5)
            
            for i in range(len(df_raw)):
                print(f"\n[í–‰ {i+1}]")
                non_empty_cols = []
                for j, value in enumerate(df_raw.iloc[i]):
                    if pd.notna(value) and str(value).strip():
                        non_empty_cols.append(f"ì»¬ëŸ¼{j}: {value}")
                if non_empty_cols:
                    print("  " + " | ".join(non_empty_cols[:10]))
                else:
                    print("  (ëª¨ë“  ì»¬ëŸ¼ì´ ë¹„ì–´ìˆìŒ)")
            
            # 3í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
            print("\n" + "="*60)
            print("ğŸ“Š 3í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì½ê¸°")
            print("="*60)
            
            df = pd.read_excel(self.excel_file_path, header=2)
            print(f"ğŸ“Š ì´ í–‰ìˆ˜: {len(df)}")
            print(f"ğŸ“Š ì´ ì—´ìˆ˜: {len(df.columns)}")
            
            # í—¤ë” ë¶„ì„
            print(f"\nğŸ“‹ ì˜ë¯¸ìˆëŠ” í—¤ë”ë“¤:")
            meaningful_headers = []
            for i, col in enumerate(df.columns):
                if pd.notna(col) and str(col).strip() and not str(col).startswith('Unnamed'):
                    meaningful_headers.append((i, col))
                    print(f"  [{i}] '{col}'")
            
            # ìƒ˜í”Œ ë°ì´í„°
            self._show_sample_data(df)
            
            # í•™ì› íŠ¹í™” ì»¬ëŸ¼ ë¶„ì„
            self._analyze_academy_columns(df)
            
            return df, meaningful_headers
            
        except Exception as e:
            print(f"âŒ êµ¬ì¡° ë¶„ì„ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None, []
    
    def _show_sample_data(self, df):
        """ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ"""
        print(f"\nğŸ” ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3í–‰):")
        for i in range(min(3, len(df))):
            print(f"\n[ë°ì´í„° í–‰ {i+1}]")
            data_found = False
            for col in df.columns:
                value = df.iloc[i][col]
                if pd.notna(value) and str(value).strip():
                    print(f"  {col}: {value}")
                    data_found = True
            if not data_found:
                print("  (ëª¨ë“  ì»¬ëŸ¼ì´ ë¹„ì–´ìˆìŒ)")
    
    def _analyze_academy_columns(self, df):
        """í•™ì› ë°ì´í„° íŠ¹í™” ì»¬ëŸ¼ ë¶„ì„"""
        # í•™ì›ëª… ê´€ë ¨
        academy_cols = self._find_columns_by_keywords(df, ['í•™ì›', 'êµìŠµì†Œ', 'ëª…ì¹­', 'ê¸°ê´€ëª…', 'ìƒí˜¸'])
        # ì£¼ì†Œ ê´€ë ¨  
        address_cols = self._find_columns_by_keywords(df, ['ì£¼ì†Œ', 'ì†Œì¬ì§€', 'ìœ„ì¹˜', 'ë„ë¡œëª…'])
        # ì „í™”ë²ˆí˜¸ ê´€ë ¨
        phone_cols = self._find_columns_by_keywords(df, ['ì „í™”', 'ë²ˆí˜¸', 'tel', 'phone'])
        # êµìŠµ ê³¼ëª©
        subject_cols = self._find_columns_by_keywords(df, ['ê³¼ëª©', 'êµìŠµ', 'ë¶„ì•¼', 'ì¢…ë¥˜'])
        # ì„¤ë¦½/ë“±ë¡ ê´€ë ¨
        register_cols = self._find_columns_by_keywords(df, ['ë“±ë¡', 'ì„¤ë¦½', 'ì¸ê°€', 'ìŠ¹ì¸'])
        
        self._print_column_analysis("ğŸ« í•™ì›ëª… ê´€ë ¨ ì»¬ëŸ¼", academy_cols, df)
        self._print_column_analysis("ğŸ¢ ì£¼ì†Œ ê´€ë ¨ ì»¬ëŸ¼", address_cols, df)
        self._print_column_analysis("ğŸ“ ì „í™”ë²ˆí˜¸ ê´€ë ¨ ì»¬ëŸ¼", phone_cols, df)
        self._print_column_analysis("ğŸ“š êµìŠµê³¼ëª© ê´€ë ¨ ì»¬ëŸ¼", subject_cols, df)
        self._print_column_analysis("ğŸ“‹ ë“±ë¡/ì„¤ë¦½ ê´€ë ¨ ì»¬ëŸ¼", register_cols, df)
    
    def _find_columns_by_keywords(self, df, keywords):
        """í‚¤ì›Œë“œë¡œ ì»¬ëŸ¼ ì°¾ê¸°"""
        found_cols = []
        for col in df.columns:
            col_str = str(col).lower()
            if any(keyword in col_str for keyword in keywords):
                found_cols.append(col)
        return found_cols
    
    def _print_column_analysis(self, title, columns, df):
        """ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        if columns:
            print(f"\n{title}:")
            for col in columns:
                non_empty = df[col].notna() & (df[col] != "")
                non_empty_count = non_empty.sum()
                print(f"  {col}: {non_empty_count}ê°œ ë°ì´í„° ì¡´ì¬")
                if non_empty_count > 0:
                    samples = df[df[col].notna() & (df[col] != "")][col].head(3)
                    print(f"    ìƒ˜í”Œ: {list(samples)}")
    
    def convert_to_database_with_ai(self, batch_size: int = 20):
        """AIë¡œ ì •ë¦¬í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë³€í™˜"""
        print("\n" + "="*60)
        print("ğŸ¤– AI ì •ë¦¬ + ë°ì´í„°ë² ì´ìŠ¤ ë³€í™˜ ì‹œì‘")
        print("="*60)
        
        try:
            # Excel ë°ì´í„° ë¡œë“œ
            df = pd.read_excel(self.excel_file_path, header=2)
            print(f"ğŸ“Š ì²˜ë¦¬í•  ë°ì´í„°: {len(df)}í–‰")
            
            # ë°°ì¹˜ ì²˜ë¦¬
            for i in range(0, len(df), batch_size):
                batch = df.iloc[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                total_batches = (len(df) + batch_size - 1) // batch_size
                
                print(f"\nğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ)...")
                
                for _, row in batch.iterrows():
                    try:
                        self.stats["total_processed"] += 1
                        
                        # ê¸°ë³¸ ë°ì´í„° ë³€í™˜
                        org_data = self._transform_academy_row_to_org(row)
                        
                        # í•„ìˆ˜ ë°ì´í„° ê²€ì¦
                        if not org_data.get('name', '').strip():
                            self.stats["failed"] += 1
                            self.stats["errors"].append("í•™ì›ëª…ì´ ì—†ëŠ” ë°ì´í„°")
                            continue
                        
                        # AIë¡œ ë°ì´í„° ì •ë¦¬ ë° ë³´ì™„
                        if self.use_ai:
                            enhanced_data = self._enhance_academy_data_with_ai(org_data, row)
                            if enhanced_data:
                                org_data.update(enhanced_data)
                                self.stats["ai_enhanced"] += 1
                                print(f"ğŸ¤– AI ì •ë¦¬ ì™„ë£Œ: {org_data.get('name', 'Unknown')}")
                        
                        # ì¤‘ë³µ ì²´í¬
                        if self._check_duplicate_in_db(org_data):
                            self.stats["duplicates_skipped"] += 1
                            continue
                        
                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                        org_id = self.db.create_organization(org_data)
                        if org_id:
                            self.stats["successfully_created"] += 1
                            if self.stats["successfully_created"] % 10 == 0:
                                print(f"âœ… {self.stats['successfully_created']}ê°œ ì €ì¥ ì™„ë£Œ...")
                        else:
                            self.stats["failed"] += 1
                            self.stats["errors"].append(f"ì €ì¥ ì‹¤íŒ¨: {org_data.get('name', 'Unknown')}")
                            
                    except Exception as e:
                        self.stats["failed"] += 1
                        error_msg = f"í–‰ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                        self.stats["errors"].append(error_msg)
                        print(f"âš ï¸ {error_msg}")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = (self.stats["total_processed"] / len(df)) * 100
                print(f"ğŸ“ˆ ì§„í–‰ë¥ : {progress:.1f}% ({self.stats['total_processed']}/{len(df)})")
            
            # ê²°ê³¼ ì¶œë ¥
            self._print_conversion_summary()
            
        except Exception as e:
            print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def _transform_academy_row_to_org(self, row: pd.Series) -> Dict[str, Any]:
        """í•™ì› Excel í–‰ì„ organization ë°ì´í„°ë¡œ ë³€í™˜"""
        
        # í•™ì› íŠ¹í™” ë§¤í•‘
        org_data = {
            'name': self._get_value_from_row(row, [
                'í•™ì›ëª…', 'êµìŠµì†Œëª…', 'ê¸°ê´€ëª…', 'ìƒí˜¸', 'ëª…ì¹­', 'ì—…ì²´ëª…', 
                'í•™êµëª…', 'name', 'ì‹œì„¤ëª…'
            ]),
            'type': OrganizationType.ACADEMY.value,
            'category': self._get_value_from_row(row, [
                'êµìŠµê³¼ëª©', 'ë¶„ì•¼', 'ê³¼ëª©', 'ì¢…ë¥˜', 'ì—…ì¢…', 'êµìŠµê³„ì—´', 
                'êµìŠµí˜•íƒœ', 'category', 'ì „ê³µë¶„ì•¼'
            ]),
            'address': self._get_value_from_row(row, [
                'ì†Œì¬ì§€', 'ì£¼ì†Œ', 'ë„ë¡œëª…ì£¼ì†Œ', 'ì§€ë²ˆì£¼ì†Œ', 'ìœ„ì¹˜', 
                'ë³¸ì ì†Œì¬ì§€', 'address', 'ì „ì²´ì£¼ì†Œ'
            ]),
            'phone': self._get_value_from_row(row, [
                'ì „í™”ë²ˆí˜¸', 'ì—°ë½ì²˜', 'ëŒ€í‘œì „í™”', 'tel', 'phone', 'ë²ˆí˜¸'
            ]),
            'email': self._get_value_from_row(row, [
                'ì´ë©”ì¼', 'email', 'e-mail', 'ì „ììš°í¸'
            ]),
            'homepage': self._get_value_from_row(row, [
                'í™ˆí˜ì´ì§€', 'ì›¹ì‚¬ì´íŠ¸', 'website', 'url', 'homepage'
            ]),
            
            # í•™ì› íŠ¹í™” ì •ë³´
            'organization_size': self._get_value_from_row(row, [
                'ê·œëª¨', 'ì •ì›', 'í•™ìƒìˆ˜', 'ìˆ˜ìš©ì¸ì›', 'ì‹œì„¤ê·œëª¨'
            ]),
            'founding_year': self._get_numeric_value_from_row(row, [
                'ë“±ë¡ë…„ë„', 'ì„¤ë¦½ë…„ë„', 'ì¸ê°€ë…„ë„', 'ê°œì›ë…„ë„', 'ìŠ¹ì¸ë…„ë„'
            ]),
            'denomination': self._get_value_from_row(row, [
                'êµìŠµê³„ì—´', 'êµìœ¡ê³¼ì •', 'ì „ê³µë¶„ì•¼', 'íŠ¹ì„±í™”ë¶„ì•¼'
            ]),
            
            # CRM ê¸°ë³¸ê°’
            'contact_status': 'NEW',
            'priority': 'MEDIUM',
            'lead_source': 'ACADEMY_EXCEL',
            'estimated_value': 0,
            'sales_notes': f"í•™ì›êµìŠµì†Œ ì •ë³´ì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°",
            'internal_notes': f"ê°€ì ¸ì˜¨ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            'created_by': 'ACADEMY_IMPORT'
        }
        
        return org_data
    
    def _get_value_from_row(self, row: pd.Series, column_names: List[str]) -> str:
        """í–‰ì—ì„œ ê°’ ì¶”ì¶œ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì»¬ëŸ¼ëª… ì‹œë„)"""
        for col_name in column_names:
            if col_name in row.index and pd.notna(row[col_name]):
                value = str(row[col_name]).strip()
                if value and value.lower() not in ['nan', 'none', 'null', '']:
                    return value
        return ""
    
    def _get_numeric_value_from_row(self, row: pd.Series, column_names: List[str]) -> Optional[int]:
        """í–‰ì—ì„œ ìˆ«ì ê°’ ì¶”ì¶œ"""
        value_str = self._get_value_from_row(row, column_names)
        if value_str:
            try:
                numbers = re.findall(r'\d+', value_str)
                if numbers:
                    return int(numbers[0])
            except:
                pass
        return None
    
    def _enhance_academy_data_with_ai(self, org_data: Dict[str, Any], 
                                     original_row: pd.Series) -> Optional[Dict[str, Any]]:
        """AIë¡œ í•™ì› ë°ì´í„° ì •ë¦¬ ë° ë³´ì™„"""
        if not self.use_ai or not self.ai_model:
            return None
        
        try:
            academy_name = org_data.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
            
            # ì›ë³¸ ë°ì´í„° ì •ë³´ ìˆ˜ì§‘
            raw_data_info = []
            for col, value in original_row.items():
                if pd.notna(value) and str(value).strip():
                    raw_data_info.append(f"- {col}: {str(value).strip()}")
            
            raw_data_text = "\n".join(raw_data_info) if raw_data_info else "ì •ë³´ ì—†ìŒ"
            
            # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„± (í•™ì› íŠ¹í™”)
            prompt = f"""
'{academy_name}' í•™ì›/êµìŠµì†Œì˜ Excel ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”.

**ì›ë³¸ Excel ë°ì´í„°:**
{raw_data_text}

**í˜„ì¬ ë§¤í•‘ëœ ì •ë³´:**
- í•™ì›ëª…: {org_data.get('name', '')}
- êµìŠµê³¼ëª©/ë¶„ì•¼: {org_data.get('category', '')}
- ì£¼ì†Œ: {org_data.get('address', '')}
- ì „í™”ë²ˆí˜¸: {org_data.get('phone', '')}

**ë¶„ì„ ìš”ì²­ (í•™ì›/êµìŠµì†Œ íŠ¹í™”):**
1. í•™ì› ìœ í˜• ë¶„ë¥˜ (í•™ì›/êµìŠµì†Œ/ê³¼ì™¸/ì˜¨ë¼ì¸êµìœ¡/ê¸°íƒ€)
2. ì£¼ìš” êµìŠµë¶„ì•¼ ì •ë¦¬ (ìˆ˜í•™/ì˜ì–´/êµ­ì–´/ê³¼í•™/ì˜ˆì²´ëŠ¥/ì…ì‹œ/ìê²©ì¦ ë“±)
3. ëŒ€ìƒ í•™ë…„/ì—°ë ¹ì¸µ (ì´ˆë“±/ì¤‘ë“±/ê³ ë“±/ì„±ì¸/ì „ì—°ë ¹)
4. í•™ì› ê·œëª¨ ì¶”ì • (ëŒ€í˜•/ì¤‘í˜•/ì†Œí˜•)
5. ì§€ì—­ íŠ¹ì„± íŒŒì•… (ê°•ë‚¨/ì„œì´ˆ/ëª©ë™ ë“± êµìœ¡íŠ¹êµ¬ ì—¬ë¶€)
6. ì˜ì—… ìš°ì„ ìˆœìœ„ ì œì•ˆ (HIGH/MEDIUM/LOW)
7. í•™ì› íŠ¹ì§• ë° ì¥ì  (2-3ë¬¸ì¥)
8. ì˜ì—… ì ‘ê·¼ ë°©ë²• ì œì•ˆ

**ì‘ë‹µ í˜•ì‹:**
TYPE: [í•™ì›ìœ í˜•]
SUBJECT: [ì£¼ìš”êµìŠµë¶„ì•¼]
TARGET: [ëŒ€ìƒí•™ë…„/ì—°ë ¹]
SIZE: [í•™ì›ê·œëª¨]
LOCATION_TYPE: [ì§€ì—­íŠ¹ì„±]
PRIORITY: [ì˜ì—…ìš°ì„ ìˆœìœ„]
DESCRIPTION: [í•™ì›íŠ¹ì§•ë°ì¥ì ]
SALES_APPROACH: [ì˜ì—…ì ‘ê·¼ë°©ë²•]
NOTES: [ê¸°íƒ€íŠ¹ì´ì‚¬í•­]
"""
            
            # AI í˜¸ì¶œ
            response = self.ai_model.generate_content(prompt)
            response_text = response.text.strip()
            
            # ì‘ë‹µ íŒŒì‹±
            enhanced_data = self._parse_ai_academy_response(response_text, academy_name)
            
            return enhanced_data
            
        except Exception as e:
            print(f"âš ï¸ AI ì •ë¦¬ ì‹¤íŒ¨: {academy_name} - {e}")
            return None
    
    def _parse_ai_academy_response(self, response_text: str, academy_name: str) -> Dict[str, Any]:
        """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ í•™ì› ë°ì´í„°ë¡œ ë³€í™˜"""
        enhanced_data = {}
        
        try:
            # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì •ë³´ ì¶”ì¶œ
            patterns = {
                'type': r'TYPE:\s*(.+)',
                'subject': r'SUBJECT:\s*(.+)',
                'target': r'TARGET:\s*(.+)',
                'size': r'SIZE:\s*(.+)',
                'location_type': r'LOCATION_TYPE:\s*(.+)',
                'priority': r'PRIORITY:\s*(.+)',
                'description': r'DESCRIPTION:\s*(.+)',
                'sales_approach': r'SALES_APPROACH:\s*(.+)',
                'notes': r'NOTES:\s*(.+)'
            }
            
            for key, pattern in patterns.items():
                match = re.search(pattern, response_text, re.IGNORECASE | re.MULTILINE)
                if match:
                    value = match.group(1).strip()
                    
                    if key == 'subject':
                        enhanced_data['category'] = value
                    elif key == 'size':
                        enhanced_data['organization_size'] = value
                    elif key == 'priority':
                        enhanced_data['priority'] = value.upper() if value.upper() in ['HIGH', 'MEDIUM', 'LOW'] else 'MEDIUM'
                    elif key == 'description':
                        enhanced_data['sales_notes'] = value
                    elif key == 'sales_approach':
                        enhanced_data['internal_notes'] = f"ì˜ì—…ì ‘ê·¼: {value}"
                    elif key == 'notes':
                        existing_notes = enhanced_data.get('internal_notes', '')
                        enhanced_data['internal_notes'] = f"{existing_notes}\nê¸°íƒ€: {value}"
            
            # AI ì •ë¦¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            enhanced_data['crawling_data'] = {
                'ai_processed': True,
                'ai_response': response_text,
                'ai_processed_at': datetime.now().isoformat(),
                'data_source': 'academy_excel'
            }
            
        except Exception as e:
            print(f"âš ï¸ AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {academy_name} - {e}")
            enhanced_data = {
                'crawling_data': {
                    'ai_processed': True,
                    'ai_response': response_text,
                    'ai_processed_at': datetime.now().isoformat(),
                    'parsing_error': str(e)
                }
            }
        
        return enhanced_data
    
    def _check_duplicate_in_db(self, org_data: Dict[str, Any]) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¤‘ë³µ ì²´í¬"""
        try:
            with self.db.get_connection() as conn:
                existing = conn.execute('''
                SELECT COUNT(*) FROM organizations 
                WHERE name = ? AND is_active = 1
                ''', (org_data['name'],)).fetchone()[0]
                
                return existing > 0
                
        except Exception as e:
            print(f"âš ï¸ ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {e}")
            return False
    
    def _print_conversion_summary(self):
        """ë³€í™˜ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ‰ í•™ì› ë°ì´í„° AI ì •ë¦¬ + DB ë³€í™˜ ì™„ë£Œ")
        print("="*60)
        print(f"ì´ ì²˜ë¦¬ëœ í–‰: {self.stats['total_processed']:,}ê°œ")
        print(f"ì„±ê³µì ìœ¼ë¡œ ìƒì„±: {self.stats['successfully_created']:,}ê°œ")
        print(f"ğŸ¤– AIë¡œ ì •ë¦¬ë¨: {self.stats['ai_enhanced']:,}ê°œ")
        print(f"ì¤‘ë³µìœ¼ë¡œ ê±´ë„ˆëœ€: {self.stats['duplicates_skipped']:,}ê°œ")
        print(f"ì‹¤íŒ¨: {self.stats['failed']:,}ê°œ")
        
        if self.stats['errors']:
            print(f"\nâŒ ì˜¤ë¥˜ ëª©ë¡ (ìµœê·¼ 10ê°œ):")
            for error in self.stats['errors'][-10:]:
                print(f"  - {error}")
        
        success_rate = (self.stats['successfully_created'] / max(1, self.stats['total_processed'])) * 100
        ai_rate = (self.stats['ai_enhanced'] / max(1, self.stats['successfully_created'])) * 100
        
        print(f"\nâœ… ì„±ê³µë¥ : {success_rate:.1f}%")
        print(f"ğŸ¤– AI ì •ë¦¬ìœ¨: {ai_rate:.1f}%")
        print("="*60)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ« í•™ì› ë°ì´í„° ë¶„ì„ + AI ì •ë¦¬ + DB ë³€í™˜ ë„êµ¬")
    print("="*60)
    
    # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
    env_vars = load_env_file()
    api_key = env_vars.get('GEMINI_API_KEY')
    
    if api_key:
        print(f"ğŸ”‘ .env íŒŒì¼ì—ì„œ API í‚¤ ë°œê²¬: {api_key[:10]}...{api_key[-5:]}")
        use_env_key = input("ğŸ¤– .env íŒŒì¼ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): ").strip().lower()
        
        if use_env_key in ['', 'y', 'yes']:
            print("âœ… .env íŒŒì¼ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            api_key = input("ğŸ”‘ ìƒˆë¡œìš´ Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    else:
        print("âš ï¸ .env íŒŒì¼ì—ì„œ GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        api_key = input("ğŸ”‘ Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—†ìœ¼ë©´ ì—”í„°): ").strip()
    
    if not api_key:
        print("âš ï¸ API í‚¤ê°€ ì—†ì–´ë„ ê¸°ë³¸ ë¶„ì„ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        print("\nğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # ë¶„ì„ê¸° ìƒì„± (ë°ì´í„°ë² ì´ìŠ¤ ë¬¸ì œ í•´ê²°)
        analyzer = ExcelAnalyzerWithAI(ai_api_key=api_key)
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ: {analyzer.db_path}")
        
        # 1. Excel êµ¬ì¡° ë¶„ì„
        print("\nğŸ“Š Excel íŒŒì¼ ë¶„ì„ ì‹œì‘...")
        df, headers = analyzer.analyze_excel_structure()
        
        if df is None:
            print("âŒ Excel íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨")
            return
        
        # 2. ë³€í™˜ ì—¬ë¶€ í™•ì¸
        print(f"\nğŸ“Š ì´ {len(df)}ê°œì˜ í•™ì› ë°ì´í„°ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        
        if api_key:
            convert_choice = input("ğŸ¤– AIë¡œ ì •ë¦¬í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        else:
            convert_choice = input("ğŸ—„ï¸ ê¸°ë³¸ ë§¤í•‘ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        
        if convert_choice in ['y', 'yes']:
            # 3. ë°ì´í„°ë² ì´ìŠ¤ ë³€í™˜
            print(f"\nğŸš€ ë³€í™˜ ì‹œì‘ - ì €ì¥ ìœ„ì¹˜: {analyzer.db_path}")
            analyzer.convert_to_database_with_ai(batch_size=20)
        else:
            print("âœ… ë¶„ì„ë§Œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ìˆ˜ë™ìœ¼ë¡œ íŒŒì¼ ì‚­ì œ ì•ˆë‚´
        print("\n" + "="*60)
        print("ğŸ”§ ìˆ˜ë™ í•´ê²° ë°©ë²•:")
        print("="*60)
        print("1. ë‹¤ìŒ íŒŒì¼ì„ ìˆ˜ë™ìœ¼ë¡œ ì‚­ì œí•´ë³´ì„¸ìš”:")
        print(f"   {os.path.abspath('churches_crm_company.db')}")
        print("2. ë˜ëŠ” Windows íƒìƒ‰ê¸°ì—ì„œ í•´ë‹¹ íŒŒì¼ì„ íœ´ì§€í†µìœ¼ë¡œ ì´ë™")
        print("3. ê·¸ ë‹¤ìŒ ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”")
        print("="*60)
        
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()