#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í™ˆí˜ì´ì§€ ì§ì ‘ íŒŒì‹± ë° AI ì •ë¦¬ ë„êµ¬
ê¸°ì¡´ì— ì°¾ì•„ë‘” í™ˆí˜ì´ì§€ URLë“¤ì„ ì‹¤ì œë¡œ ë°©ë¬¸í•˜ì—¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  AIë¡œ ì •ë¦¬
"""

import json
import os
import sys
import time
import random
import re
import logging
import requests
from typing import List, Dict, Any, Optional
from urllib.parse import urlparse
from datetime import datetime
from pathlib import Path

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

# settings.pyì—ì„œ í•„ìš”í•œ ê²ƒë“¤ import
try:
    from utils.settings import (
        PHONE_EXTRACTION_PATTERNS,
        FAX_EXTRACTION_PATTERNS,
        EMAIL_EXTRACTION_PATTERNS,
        ADDRESS_EXTRACTION_PATTERNS,
        GEMINI_API_KEY,
        LOGGER_NAMES
    )
    print("âœ… settings.py import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ settings.py import ì‹¤íŒ¨: {e}")
    # ê¸°ë³¸ê°’ ì„¤ì •
    PHONE_EXTRACTION_PATTERNS = [r'(\d{2,3}[-\.\s]?\d{3,4}[-\.\s]?\d{4})']
    FAX_EXTRACTION_PATTERNS = [r'íŒ©ìŠ¤[\s]*(\d{2,3}[-\s]?\d{3,4}[-\s]?\d{4})']
    EMAIL_EXTRACTION_PATTERNS = [r'([a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})']
    ADDRESS_EXTRACTION_PATTERNS = [r'([ê°€-í£\s\d\-\(\)]+(?:ì‹œ|êµ°|êµ¬|ë™|ë¡œ|ê¸¸)[ê°€-í£\s\d\-\(\)]*)']
    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
    LOGGER_NAMES = {"parser": "web_parser"}

# AI ë° BS4 ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
AI_AVAILABLE = False
genai = None
BS4_AVAILABLE = False

# AI ëª¨ë¸ import ë° ì´ˆê¸°í™”
try:
    import google.generativeai as genai
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        AI_AVAILABLE = True
        print("ğŸ¤– AI ê¸°ëŠ¥ í™œì„±í™”")
    else:
        AI_AVAILABLE = False
        print("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
except ImportError as e:
    AI_AVAILABLE = False
    genai = None
    print(f"âš ï¸ google.generativeai ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
    print("âœ… BeautifulSoup ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    BS4_AVAILABLE = False
    print("âš ï¸ BeautifulSoupì´ ì—†ìŒ - HTML íŒŒì‹± ì œí•œë¨")

class HomepageParser:
    """í™ˆí˜ì´ì§€ ì§ì ‘ íŒŒì‹± ë° AI ì •ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, headless: bool = False):
        self.headless = headless
        self.driver = None
        self.logger = self.setup_logger()
        
        # AI ëª¨ë¸ ì„¤ì • (ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©)
        self.ai_model = None
        self.use_ai = AI_AVAILABLE  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©
        
        if self.use_ai and genai:
            try:
                self.ai_model = genai.GenerativeModel('gemini-1.5-flash')
                print("âœ… Gemini AI ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                print(f"âŒ AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_ai = False
                self.ai_model = None
        else:
            print("ğŸ”§ AI ê¸°ëŠ¥ ë¹„í™œì„±í™”")
        
        # íŒŒì‹± ì„¤ì •
        self.page_timeout = 30
        self.delay_range = (2, 4)
        self.max_content_length = 10000  # AI ì²˜ë¦¬ìš© ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´
        self.max_wait_time = 20  # JavaScript ë¡œë”© ìµœëŒ€ ëŒ€ê¸°ì‹œê°„

        # ë™ì  ì½˜í…ì¸  ê°ì§€ë¥¼ ìœ„í•œ ì„ íƒìë“¤
        self.content_selectors = [
            'main', 'article', '.content', '#content', '.main-content',
            '.container', '.wrapper', 'section', '.section',
            '.page-content', '.post-content', '.entry-content',
            '[role="main"]', '.main'
        ]
        
        # ì—°ë½ì²˜ ê´€ë ¨ ì„ íƒìë“¤
        self.contact_selectors = [
            '.contact', '#contact', '.contact-info', '.contact-us',
            '.footer', '#footer', '.footer-info',
            '.address', '.phone', '.tel', '.email',
            '[class*="contact"]', '[id*="contact"]',
            '[class*="footer"]', '[id*="footer"]',
            'footer', 'address'
        ]
        
    def setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger('homepage_parser')
        logger.setLevel(logging.INFO)  # DEBUGë¡œ ë³€ê²½í•˜ë©´ í”„ë¡¬í”„íŠ¸ë„ ë³¼ ìˆ˜ ìˆìŒ
        
        # í•¸ë“¤ëŸ¬ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì œê±°
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„° ì„¤ì •
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ë„ ì¶”ê°€ (ì„ íƒì‚¬í•­)
        try:
            file_handler = logging.FileHandler('homepage_parser.log', encoding='utf-8')
            file_handler.setLevel(logging.DEBUG)  # íŒŒì¼ì—ëŠ” ëª¨ë“  ë¡œê·¸ ì €ì¥
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
        except Exception as e:
            print(f"íŒŒì¼ ë¡œê·¸ í•¸ë“¤ëŸ¬ ì„¤ì • ì‹¤íŒ¨: {e}")
        
        return logger
    
    def setup_driver(self):
        """ChromeDriver ì„¤ì • ë° ì´ˆê¸°í™” (ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
        try:
            # ê¸°ì¡´ ë“œë¼ì´ë²„ ì •ë¦¬
            if hasattr(self, 'driver') and self.driver:
                try:
                    self.driver.quit()
                except:
                    pass
                self.driver = None
            
            # Chrome ì˜µì…˜ ì„¤ì •
            options = webdriver.ChromeOptions()
            
            # ê¸°ë³¸ ì˜µì…˜ë“¤
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            
            # ì‚¬ìš©ì ì—ì´ì „íŠ¸ ì„¤ì •
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì„¤ì •
            if self.headless:
                options.add_argument('--headless')
                options.add_argument('--disable-gpu')
                options.add_argument('--window-size=1920,1080')
            
            # ì„±ëŠ¥ ìµœì í™”
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-plugins')
            options.add_argument('--disable-images')  # ì´ë¯¸ì§€ ë¡œë“œ ë¹„í™œì„±í™”
            options.add_argument('--disable-javascript')  # JS ë¹„í™œì„±í™” (í•„ìš”ì‹œ ì œê±°)
            
            # Chrome WebDriver ì´ˆê¸°í™” ì‹œë„
            try:
                self.driver = webdriver.Chrome(options=options)
                self.logger.info("âœ… Chrome WebDriver ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as chrome_error:
                self.logger.warning(f"âš ï¸ Chrome WebDriver ì‹¤íŒ¨: {chrome_error}")
                
                # Edge WebDriver ì‹œë„
                try:
                    from selenium.webdriver import Edge
                    from selenium.webdriver.edge.options import Options as EdgeOptions
                    
                    edge_options = EdgeOptions()
                    edge_options.add_argument('--no-sandbox')
                    edge_options.add_argument('--disable-dev-shm-usage')
                    if self.headless:
                        edge_options.add_argument('--headless')
                    
                    self.driver = Edge(options=edge_options)
                    self.logger.info("âœ… Edge WebDriver ì´ˆê¸°í™” ì„±ê³µ (Chrome ëŒ€ì•ˆ)")
                except Exception as edge_error:
                    self.logger.error(f"âŒ Edge WebDriverë„ ì‹¤íŒ¨: {edge_error}")
                    raise Exception(f"ëª¨ë“  WebDriver ì‹¤íŒ¨ - Chrome: {chrome_error}, Edge: {edge_error}")
            
            # WebDriver ì„¤ì •
            if self.driver:
                self.driver.set_page_load_timeout(30)
                self.driver.implicitly_wait(10)
                
                # ìë™í™” ê°ì§€ ë°©ì§€
                self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
                self.logger.info("ğŸš€ WebDriver ì„¤ì • ì™„ë£Œ")
            else:
                raise Exception("WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨")
            
        except Exception as e:
            self.logger.error(f"âŒ WebDriver ì„¤ì • ì‹¤íŒ¨: {e}")
            self.driver = None
            raise e
    
    def close_driver(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass
            self.driver = None
            self.logger.info("ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ")
    
    def add_delay(self):
        """ìš”ì²­ ê°„ ì§€ì—°"""
        delay = random.uniform(*self.delay_range)
        self.logger.info(f"ì§€ì—° ì‹œê°„: {delay:.1f}ì´ˆ")
        time.sleep(delay)

    def wait_for_dynamic_content(self, url: str) -> bool:
        """ë™ì  ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸° (ê°•í™”ëœ ë²„ì „)"""
        try:
            self.logger.info("ğŸ”„ ê°•í™”ëœ ë™ì  ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸° ì‹œì‘...")
            
            # 1. ê¸°ë³¸ í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸°
            WebDriverWait(self.driver, 15).until(
                lambda driver: driver.execute_script("return document.readyState") == "complete"
            )
            
            # 2. ì´ˆê¸° ì½˜í…ì¸  ê¸¸ì´ ì¸¡ì •
            initial_length = len(self.driver.page_source)
            
            # 3. ì—¬ëŸ¬ JavaScript í”„ë ˆì„ì›Œí¬ ëŒ€ê¸°
            self._wait_for_js_frameworks()
            
            # 4. ë™ì  ë¡œë”© ê°ì§€ ë° ëŒ€ê¸°
            stable_count = 0
            max_wait_cycles = 8
            
            for cycle in range(max_wait_cycles):
                time.sleep(2)
                
                # í˜ì´ì§€ ìŠ¤í¬ë¡¤ë¡œ lazy loading íŠ¸ë¦¬ê±°
                self.trigger_lazy_loading()
                
                # ìƒˆë¡œìš´ ì½˜í…ì¸  ê¸¸ì´ ì¸¡ì •
                current_length = len(self.driver.page_source)
                
                # ì½˜í…ì¸  ë³€í™”ê°€ ì—†ìœ¼ë©´ ì•ˆì •ëœ ê²ƒìœ¼ë¡œ íŒë‹¨
                if abs(current_length - initial_length) < 1000:
                    stable_count += 1
                    if stable_count >= 2:  # 2ë²ˆ ì—°ì† ì•ˆì •ë˜ë©´ ì™„ë£Œ
                        self.logger.info(f"âœ… ì½˜í…ì¸  ì•ˆì •í™” ì™„ë£Œ (ì‚¬ì´í´ {cycle+1})")
                        break
                else:
                    stable_count = 0
                    initial_length = current_length
                    self.logger.info(f"ğŸ“Š ì½˜í…ì¸  ë³€í™” ê°ì§€: {current_length:,} bytes")
            
            # 5. ìµœì¢… ìš”ì†Œ ëŒ€ê¸°
            return self._wait_for_critical_elements()
            
        except Exception as e:
            self.logger.error(f"âŒ ê°•í™”ëœ ë™ì  ì½˜í…ì¸  ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def _wait_for_js_frameworks(self):
        """ë‹¤ì–‘í•œ JavaScript í”„ë ˆì„ì›Œí¬ ë¡œë”© ëŒ€ê¸°"""
        try:
            # jQuery ëŒ€ê¸°
            try:
                WebDriverWait(self.driver, 5).until(
                    lambda driver: driver.execute_script(
                        "return typeof jQuery === 'undefined' || (jQuery.active === 0 && jQuery(':animated').length === 0)"
                    )
                )
                self.logger.info("âœ… jQuery ì™„ë£Œ")
            except:
                pass
            
            # React ëŒ€ê¸°
            try:
                WebDriverWait(self.driver, 5).until(
                    lambda driver: driver.execute_script(
                        """
                        if (typeof React === 'undefined') return true;
                        const reactFiber = document.querySelector('[data-reactroot]');
                        return reactFiber ? true : document.readyState === 'complete';
                        """
                    )
                )
                self.logger.info("âœ… React í™•ì¸")
            except:
                pass
            
            # Vue.js ëŒ€ê¸°
            try:
                WebDriverWait(self.driver, 5).until(
                    lambda driver: driver.execute_script(
                        """
                        if (typeof Vue === 'undefined') return true;
                        return document.readyState === 'complete';
                        """
                    )
                )
                self.logger.info("âœ… Vue.js í™•ì¸")
            except:
                pass
            
            # Angular ëŒ€ê¸°
            try:
                WebDriverWait(self.driver, 5).until(
                    lambda driver: driver.execute_script(
                        """
                        if (typeof angular === 'undefined') return true;
                        const injector = angular.element(document).injector();
                        if (!injector) return true;
                        const http = injector.get('$http');
                        return http.pendingRequests.length === 0;
                        """
                    )
                )
                self.logger.info("âœ… Angular í™•ì¸")
            except:
                pass
                
        except Exception as e:
            self.logger.warning(f"JavaScript í”„ë ˆì„ì›Œí¬ ëŒ€ê¸° ì˜¤ë¥˜: {e}")

    def _wait_for_critical_elements(self) -> bool:
        """í•µì‹¬ ìš”ì†Œë“¤ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        try:
            # í…ìŠ¤íŠ¸ ì½˜í…ì¸ ê°€ ìˆëŠ” ì£¼ìš” ìš”ì†Œ ëŒ€ê¸°
            text_selectors = [
                'p', 'div', 'span', 'article', 'section', 
                '.content', '.main', '.container'
            ]
            
            for selector in text_selectors:
                try:
                    WebDriverWait(self.driver, 3).until(
                        lambda driver: len(driver.find_elements(By.CSS_SELECTOR, f"{selector}:not(:empty)")) > 0
                    )
                    self.logger.info(f"âœ… í…ìŠ¤íŠ¸ ìš”ì†Œ ë°œê²¬: {selector}")
                    break
                except TimeoutException:
                    continue
            
            # ì´ë¯¸ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸° (ì„ íƒì )
            try:
                self.driver.execute_script("""
                    const images = document.querySelectorAll('img');
                    return Array.from(images).every(img => img.complete || img.naturalWidth > 0);
                """)
                self.logger.info("âœ… ì´ë¯¸ì§€ ë¡œë”© í™•ì¸")
            except:
                pass
            
            return True
            
        except Exception as e:
            self.logger.warning(f"í•µì‹¬ ìš”ì†Œ ëŒ€ê¸° ì˜¤ë¥˜: {e}")
            return False

    def trigger_lazy_loading(self):
        """ê°•í™”ëœ Lazy loading íŠ¸ë¦¬ê±°"""
        try:
            # 1. ê¸°ë³¸ ìŠ¤í¬ë¡¤
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)
            
            # 2. ë‹¨ê³„ë³„ ìŠ¤í¬ë¡¤ (ë” ì„¸ë°€í•˜ê²Œ)
            scroll_steps = [0.25, 0.5, 0.75, 1.0, 0.5, 0]
            for step in scroll_steps:
                scroll_position = f"document.body.scrollHeight * {step}"
                self.driver.execute_script(f"window.scrollTo(0, {scroll_position});")
                time.sleep(0.8)
            
            # 3. ê°€ì‹œì„± íŠ¸ë¦¬ê±° (intersection observer ì´ë²¤íŠ¸)
            self.driver.execute_script("""
                // ëª¨ë“  ìš”ì†Œì— ëŒ€í•´ ìŠ¤í¬ë¡¤ ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
                window.dispatchEvent(new Event('scroll'));
                window.dispatchEvent(new Event('resize'));
                
                // lazy loading ì†ì„±ì„ ê°€ì§„ ì´ë¯¸ì§€ë“¤ ê°•ì œ ë¡œë”©
                document.querySelectorAll('img[loading="lazy"], img[data-src]').forEach(img => {
                    if (img.dataset.src) {
                        img.src = img.dataset.src;
                    }
                    img.scrollIntoView({behavior: 'smooth', block: 'center'});
                });
            """)
            
            time.sleep(2)
            self.logger.info("ğŸ“œ ê°•í™”ëœ ìŠ¤í¬ë¡¤ íŠ¸ë¦¬ê±° ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ê°•í™”ëœ ìŠ¤í¬ë¡¤ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
    
    def extract_content_with_multiple_strategies(self) -> Dict[str, str]:
        """ì—¬ëŸ¬ ì „ëµìœ¼ë¡œ ì½˜í…ì¸  ì¶”ì¶œ"""
        content_results = {
            "full_text": "",
            "main_content": "",
            "contact_content": "",
            "method_used": "none"
        }
        
        try:
            # ì „ëµ 1: BeautifulSoupìœ¼ë¡œ ì „ì²´ íŒŒì‹±
            if BS4_AVAILABLE:
                page_source = self.driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                
                # ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼ ì œê±°
                for element in soup(["script", "style", "noscript", "meta", "link"]):
                    element.decompose()
                
                # ì „ì²´ í…ìŠ¤íŠ¸
                full_text = soup.get_text()
                full_text = re.sub(r'\s+', ' ', full_text).strip()
                content_results["full_text"] = full_text
                content_results["method_used"] = "beautifulsoup"
                
                self.logger.info(f"âœ… BeautifulSoup íŒŒì‹±: {len(full_text)} chars")
            
            # ì „ëµ 2: ì£¼ìš” ì½˜í…ì¸  ì˜ì—­ íƒ€ê²ŸíŒ…
            main_content_texts = []
            for selector in self.content_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        if len(text) > 100:  # ì˜ë¯¸ìˆëŠ” ì½˜í…ì¸ ë§Œ
                            main_content_texts.append(text)
                            self.logger.info(f"ğŸ“ ì£¼ìš” ì½˜í…ì¸  ë°œê²¬ ({selector}): {len(text)} chars")
                except:
                    continue
            
            if main_content_texts:
                content_results["main_content"] = " ".join(main_content_texts)
                if not content_results["method_used"] or content_results["method_used"] == "none":
                    content_results["method_used"] = "targeted_selectors"
            
            # ì „ëµ 3: ì—°ë½ì²˜ ì •ë³´ ì˜ì—­ íŠ¹ë³„ ì¶”ì¶œ
            contact_texts = []
            for selector in self.contact_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        if len(text) > 20:  # ì—°ë½ì²˜ ì •ë³´ëŠ” ë” ì§§ì•„ë„ ë¨
                            contact_texts.append(text)
                except:
                    continue
            
            if contact_texts:
                content_results["contact_content"] = " ".join(contact_texts)
                self.logger.info(f"ğŸ“ ì—°ë½ì²˜ ì˜ì—­ ë°œê²¬: {len(contact_texts)}ê°œ ì„¹ì…˜")
            
            # ì „ëµ 4: Selenium ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (fallback)
            if not any([content_results["full_text"], content_results["main_content"]]):
                try:
                    body_element = self.driver.find_element(By.TAG_NAME, "body")
                    selenium_text = body_element.text.strip()
                    content_results["full_text"] = selenium_text
                    content_results["method_used"] = "selenium_direct"
                    self.logger.info(f"ğŸ”„ Selenium ì§ì ‘ ì¶”ì¶œ: {len(selenium_text)} chars")
                except:
                    self.logger.warning("âŒ ëª¨ë“  ì½˜í…ì¸  ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨")
            
            # ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë©”ì¸ìœ¼ë¡œ ì‚¬ìš©
            all_texts = [
                content_results["full_text"],
                content_results["main_content"],
                content_results["contact_content"]
            ]
            
            longest_text = max(all_texts, key=len) if any(all_texts) else ""
            
            self.logger.info(f"ğŸ“Š ì½˜í…ì¸  ì¶”ì¶œ ê²°ê³¼:")
            self.logger.info(f"  - ì „ì²´ í…ìŠ¤íŠ¸: {len(content_results['full_text'])} chars")
            self.logger.info(f"  - ì£¼ìš” ì½˜í…ì¸ : {len(content_results['main_content'])} chars")
            self.logger.info(f"  - ì—°ë½ì²˜ ì½˜í…ì¸ : {len(content_results['contact_content'])} chars")
            self.logger.info(f"  - ì‚¬ìš©ëœ ë°©ë²•: {content_results['method_used']}")
            self.logger.info(f"  - ìµœì¢… ì„ íƒ: {len(longest_text)} chars")
            
            # ìµœì¢… í…ìŠ¤íŠ¸ ì„¤ì •
            if longest_text:
                content_results["final_text"] = longest_text[:self.max_content_length]
            else:
                content_results["final_text"] = ""
            
        except Exception as e:
            self.logger.error(f"âŒ ì½˜í…ì¸  ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            content_results["final_text"] = ""
            content_results["method_used"] = "error"
        
        return content_results
    
    def extract_page_content(self, url: str) -> Dict[str, Any]:
        """
        í–¥ìƒëœ í˜ì´ì§€ íŒŒì‹± (ë‹¤ì¤‘ ì „ëµ + ë™ì  ì½˜í…ì¸  ì²˜ë¦¬)
        """
        result = {
            "url": url,
            "title": "",
            "text_content": "",
            "status": "success",
            "contact_info": {
                "phones": [],
                "faxes": [],
                "emails": [],
                "addresses": []
            },
            "meta_info": {},
            "parsing_details": {},
            "error": None,
            "accessible": False,
            "raw_html": ""  # ì›ë³¸ HTML ì¶”ê°€
        }
        
        try:
            # WebDriver ì´ˆê¸°í™” í™•ì¸
            if not self.driver:
                self.logger.warning("âš ï¸ WebDriverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ. ì¬ì´ˆê¸°í™” ì‹œë„...")
                self.setup_driver()
                
                if not self.driver:
                    result["status"] = "error"
                    result["error"] = "WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨"
                    self.logger.error(f"âŒ WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨: {url}")
                    return result
            
            self.logger.info(f"ğŸŒ í–¥ìƒëœ í˜ì´ì§€ ì ‘ì†: {url}")
            
            # 1. í˜ì´ì§€ ë¡œë“œ
            load_start_time = time.time()
            self.driver.get(url)
            
            # 2. ë™ì  ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸°
            if self.wait_for_dynamic_content(url):
                self.logger.info("âœ… ë™ì  ì½˜í…ì¸  ë¡œë”© ì™„ë£Œ")
            else:
                self.logger.warning("âš ï¸ ë™ì  ì½˜í…ì¸  ë¡œë”© ì‹œê°„ ì´ˆê³¼")
            
            # 3. í˜ì´ì§€ ì ‘ê·¼ ê°€ëŠ¥ì„± í™•ì¸
            if not self.is_page_accessible():
                result["status"] = "error"
                result["error"] = "í˜ì´ì§€ ì ‘ê·¼ ë¶ˆê°€ (404, 403 ë“±)"
                result["accessible"] = False
                self.logger.warning(f"âŒ í˜ì´ì§€ ì ‘ê·¼ ë¶ˆê°€: {url}")
                return result
            
                result["accessible"] = True
                
                # 4. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            try:
                result["title"] = self.driver.title.strip()
                result["raw_html"] = self.driver.page_source
                self.logger.info(f"ğŸ“„ í˜ì´ì§€ ì œëª©: {result['title']}")
                self.logger.info(f"ğŸ“Š HTML í¬ê¸°: {len(result['raw_html']):,} bytes")
            except Exception as e:
                self.logger.warning(f"ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                
            # 5. ì½˜í…ì¸  ì¶”ì¶œ (ë‹¤ì¤‘ ì „ëµ)
            content_results = self.extract_content_with_multiple_strategies()
            result["text_content"] = content_results.get("final_text", "")
                result["parsing_details"] = {
                "content_extraction_method": content_results.get("method_used", "unknown"),
                "full_text_length": len(content_results.get("full_text", "")),
                "main_content_length": len(content_results.get("main_content", "")),
                "contact_content_length": len(content_results.get("contact_content", "")),
                "processing_time": time.time() - load_start_time
                }
                
            # 6. ë©”íƒ€ ì •ë³´ ì¶”ì¶œ (BeautifulSoup ì‚¬ìš©)
            if BS4_AVAILABLE and result["raw_html"]:
                    try:
                    soup = BeautifulSoup(result["raw_html"], 'html.parser')
                        result["meta_info"] = self.extract_meta_info(soup)
                    except Exception as e:
                    self.logger.warning(f"ë©”íƒ€ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            
            # 7. ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ
            if result["text_content"]:
                try:
                    result["contact_info"] = self.extract_contact_info(result["text_content"])
                    contact_count = sum(len(v) for v in result["contact_info"].values())
                    self.logger.info(f"ğŸ“ ì¶”ì¶œëœ ì—°ë½ì²˜: {contact_count}ê°œ")
                    
                    # ì—°ë½ì²˜ë³„ ê°œìˆ˜ ë¡œê¹…
                    for contact_type, contacts in result["contact_info"].items():
                        if contacts:
                            self.logger.info(f"  - {contact_type}: {len(contacts)}ê°œ - {contacts[:3]}")  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                
                except Exception as e:
                    self.logger.warning(f"ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            
            # 8. ê²°ê³¼ ê²€ì¦
            if not result["text_content"] or len(result["text_content"]) < 100:
                result["status"] = "warning"
                result["error"] = "ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ê°€ ë¶€ì¡±í•¨"
                self.logger.warning(f"âš ï¸ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ë¶€ì¡±: {len(result['text_content'])} chars")
            
            load_time = time.time() - load_start_time
            self.logger.info(f"âœ… í˜ì´ì§€ íŒŒì‹± ì™„ë£Œ: {url} ({load_time:.2f}ì´ˆ)")
        
        except TimeoutException:
            result["status"] = "timeout"
            result["error"] = "í˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì´ˆê³¼"
            self.logger.warning(f"â° íƒ€ì„ì•„ì›ƒ: {url}")
        
        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)
            self.logger.error(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {url} - {e}")
            
            # WebDriver ì¬ì´ˆê¸°í™” ì‹œë„
            if "NoneType" in str(e) or "driver" in str(e).lower():
                self.logger.warning("ğŸ”„ WebDriver ê´€ë ¨ ì˜¤ë¥˜ë¡œ ì¬ì´ˆê¸°í™” ì‹œë„...")
                try:
                    self.setup_driver()
                except Exception as setup_error:
                    self.logger.error(f"âŒ WebDriver ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {setup_error}")
        
        return result
    
    def is_page_accessible(self) -> bool:
        """í˜ì´ì§€ ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (ê°œì„ ëœ ë²„ì „)"""
        try:
            # 1. íƒ€ì´í‹€ í™•ì¸
            title = self.driver.title.lower()
            if any(keyword in title for keyword in ['404', 'not found', 'error', 'ì˜¤ë¥˜', 'ì°¾ì„ ìˆ˜ ì—†', 'ì ‘ê·¼ ê±°ë¶€']):
                return False
            
            # 2. í˜ì´ì§€ ì†ŒìŠ¤ í¬ê¸° í™•ì¸
            page_source = self.driver.page_source
            if len(page_source) < 1000:  # ìµœì†Œ í¬ê¸° ì¦ê°€
                return False
            
            # 3. ì‹¤ì œ body í…ìŠ¤íŠ¸ í™•ì¸
            try:
                body_text = self.driver.find_element(By.TAG_NAME, "body").text.strip()
                if len(body_text) < 50:  # ì‹¤ì œ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ìŒ
                    return False
            except:
                return False
            
            # 4. ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸ (í˜ì´ì§€ ì†ŒìŠ¤ì™€ body í…ìŠ¤íŠ¸ ëª¨ë‘)
            error_keywords = ['404', 'not found', 'page not found', 'í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†', 
                            'ì ‘ê·¼ì´ ê±°ë¶€', 'access denied', 'forbidden', '503', '500']
            
            combined_text = (page_source + " " + body_text).lower()
            if any(keyword in combined_text for keyword in error_keywords):
                return False
            
            return True
            
        except Exception:
            return False
    
    def extract_meta_info(self, soup) -> Dict[str, str]:
        """ë©”íƒ€ ì •ë³´ ì¶”ì¶œ"""
        meta_info = {
            "description": "",
            "keywords": "",
            "author": "",
            "og_title": "",
            "og_description": ""
        }
        
        try:
            # ê¸°ë³¸ ë©”íƒ€ íƒœê·¸
            meta_tags = soup.find_all('meta')
            for tag in meta_tags:
                name = tag.get('name', '').lower()
                property_name = tag.get('property', '').lower()
                content = tag.get('content', '')
                
                if name == 'description':
                    meta_info["description"] = content
                elif name == 'keywords':
                    meta_info["keywords"] = content
                elif name == 'author':
                    meta_info["author"] = content
                elif property_name == 'og:title':
                    meta_info["og_title"] = content
                elif property_name == 'og:description':
                    meta_info["og_description"] = content
        
        except Exception as e:
            self.logger.warning(f"ë©”íƒ€ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return meta_info
    
    def extract_contact_info(self, text: str) -> Dict[str, List[str]]:
        """ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ"""
        contact_info = {
            "phones": [],
            "faxes": [],
            "emails": [],
            "addresses": []
        }
        
        try:
            # ì „í™”ë²ˆí˜¸ ì¶”ì¶œ
            for pattern in PHONE_EXTRACTION_PATTERNS:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    phone = self.clean_phone_number(match)
                    if phone and phone not in contact_info["phones"]:
                        contact_info["phones"].append(phone)
            
            # íŒ©ìŠ¤ë²ˆí˜¸ ì¶”ì¶œ
            for pattern in FAX_EXTRACTION_PATTERNS:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    fax = self.clean_phone_number(match)
                    if fax and fax not in contact_info["faxes"]:
                        contact_info["faxes"].append(fax)
            
            # ì´ë©”ì¼ ì¶”ì¶œ
            for pattern in EMAIL_EXTRACTION_PATTERNS:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    email = match.strip()
                    if self.is_valid_email(email) and email not in contact_info["emails"]:
                        contact_info["emails"].append(email)
            
            # ì£¼ì†Œ ì¶”ì¶œ
            for pattern in ADDRESS_EXTRACTION_PATTERNS:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    address = self.clean_address(match)
                    if address and address not in contact_info["addresses"]:
                        contact_info["addresses"].append(address)
        
        except Exception as e:
            self.logger.warning(f"ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return contact_info
    
    def clean_phone_number(self, phone: str) -> Optional[str]:
        """ì „í™”ë²ˆí˜¸ ì •ë¦¬"""
        if not phone:
            return None
        
        # ìˆ«ìë§Œ ì¶”ì¶œ
        digits = re.sub(r'[^\d]', '', phone)
        
        # ê¸¸ì´ í™•ì¸
        if len(digits) < 9 or len(digits) > 11:
            return None
        
        # í¬ë§·íŒ…
        if digits.startswith('02'):
            if len(digits) == 9:
                return f"{digits[:2]}-{digits[2:5]}-{digits[5:]}"
            else:
                return f"{digits[:2]}-{digits[2:6]}-{digits[6:]}"
        elif digits.startswith(('010', '011', '016', '017', '018', '019', '070')):
            return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
        else:
            if len(digits) == 10:
                return f"{digits[:3]}-{digits[3:6]}-{digits[6:]}"
            else:
                return f"{digits[:3]}-{digits[3:7]}-{digits[7:]}"
    
    def is_valid_email(self, email: str) -> bool:
        """ì´ë©”ì¼ ìœ íš¨ì„± í™•ì¸"""
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return re.match(email_pattern, email) is not None
    
    def clean_address(self, address: str) -> Optional[str]:
        """ì£¼ì†Œ ì •ë¦¬"""
        if not address:
            return None
        
        # ê³µë°± ì •ë¦¬
        cleaned = re.sub(r'\s+', ' ', address.strip())
        
        # ìµœì†Œ ê¸¸ì´ í™•ì¸
        if len(cleaned) < 10:
            return None
        
        return cleaned
    
    def summarize_with_ai(self, organization_name: str, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """AIë¡œ í˜ì´ì§€ ë‚´ìš© ìš”ì•½ ë° ì •ë¦¬ (Gemini í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬)"""
        if not self.use_ai or not self.ai_model:
            self.logger.warning("AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
            return self._create_fallback_summary("AI ê¸°ëŠ¥ ë¹„í™œì„±í™”", page_data)
        
        try:
            # AI í”„ë¡¬í”„íŠ¸ êµ¬ì„± (JSON ìš”ì²­í•˜ì§€ë§Œ í…ìŠ¤íŠ¸ë¡œ ë°›ì„ ê²ƒì„ ì—¼ë‘)
            prompt = f"""
    '{organization_name}' ê¸°ê´€ì˜ í™ˆí˜ì´ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

    **ê¸°ë³¸ ì •ë³´:**
    - ì œëª©: {page_data.get('title', '')}
    - URL: {page_data.get('url', '')}
    - ë©”íƒ€ ì„¤ëª…: {page_data.get('meta_info', {}).get('description', '')}

    **í™ˆí˜ì´ì§€ ë‚´ìš©:**
    {page_data.get('text_content', '')[:3000]}

    **ì¶”ì¶œëœ ì—°ë½ì²˜:**
    - ì „í™”ë²ˆí˜¸: {', '.join(page_data.get('contact_info', {}).get('phones', []))}
    - íŒ©ìŠ¤ë²ˆí˜¸: {', '.join(page_data.get('contact_info', {}).get('faxes', []))}
    - ì´ë©”ì¼: {', '.join(page_data.get('contact_info', {}).get('emails', []))}
    - ì£¼ì†Œ: {', '.join(page_data.get('contact_info', {}).get('addresses', []))}

    **ë¶„ì„ ìš”ì²­:**
    1. ê¸°ê´€ ìš”ì•½ (3-4ë¬¸ì¥)
    2. ê¸°ê´€ ìœ í˜• ë¶„ë¥˜ (êµíšŒ, ë³‘ì›, í•™êµ, ì •ë¶€ê¸°ê´€, ê¸°ì—…, ë‹¨ì²´ ë“±)
    3. ì£¼ìš” ì„œë¹„ìŠ¤ë‚˜ í™œë™ (ìµœëŒ€ 3ê°œ)
    4. ì„¤ë¦½ì—°ë„ (í™ˆí˜ì´ì§€ì—ì„œ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´)
    5. ì£¼ìš” ìœ„ì¹˜ë‚˜ ì§€ì—­
    6. ì—°ë½ì²˜ ì •ë³´ ì™„ì„±ë„ í‰ê°€ (ìƒ/ì¤‘/í•˜)
    7. í™ˆí˜ì´ì§€ í’ˆì§ˆ í‰ê°€ (ìƒ/ì¤‘/í•˜)
    8. íŠ¹ë³„í•œ íŠ¹ì§•ì´ë‚˜ ì„œë¹„ìŠ¤

    **ì‘ë‹µ í˜•ì‹ (ê°€ëŠ¥í•˜ë©´ ì´ í˜•ì‹ìœ¼ë¡œ, ì•„ë‹ˆë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ):**
    SUMMARY: [ê¸°ê´€ ìš”ì•½]
    CATEGORY: [ê¸°ê´€ ìœ í˜•]
    SERVICES: [ì„œë¹„ìŠ¤1, ì„œë¹„ìŠ¤2, ì„œë¹„ìŠ¤3]
    ESTABLISHMENT: [ì„¤ë¦½ì—°ë„ ë˜ëŠ” "ì •ë³´ì—†ìŒ"]
    LOCATION: [ìœ„ì¹˜ì •ë³´]
    CONTACT_QUALITY: [ìƒ/ì¤‘/í•˜]
    WEBSITE_QUALITY: [ìƒ/ì¤‘/í•˜]
    FEATURES: [íŠ¹ì§•1, íŠ¹ì§•2]
    """
            
            # í”„ë¡¬í”„íŠ¸ ë¡œê¹… (ë””ë²„ê¹…ìš©)
            self.logger.debug(f"ğŸ¤– AI í”„ë¡¬í”„íŠ¸ ({organization_name}):\n{'-'*50}\n{prompt}\n{'-'*50}")
            
            # AI í˜¸ì¶œ
            response = self.ai_model.generate_content(prompt)
            response_text = response.text.strip()
            
            # AI ì‘ë‹µ ì „ì²´ ë‚´ìš© ë¡œê¹…
            self.logger.info(f"ğŸ¤– AI ì‘ë‹µ ({organization_name}) - ê¸¸ì´: {len(response_text)} chars")
            self.logger.info(f"ğŸ“ AI ì‘ë‹µ ë‚´ìš©:\n{'-'*50}\n{response_text}\n{'-'*50}")
            
            # ì‘ë‹µì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ê²½ê³ 
            if len(response_text) < 50:
                self.logger.warning(f"âš ï¸ AI ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {response_text}")
            
            # ì‘ë‹µ íŒŒì‹± (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
            ai_summary = self._parse_ai_summary_response(response_text, organization_name)
            
            # íŒŒì‹± ê²°ê³¼ë„ ë¡œê¹…
            self.logger.info(f"ğŸ” íŒŒì‹± ê²°ê³¼ ({organization_name}):")
            self.logger.info(f"  - ìš”ì•½: {ai_summary.get('summary', 'None')[:100]}...")
            self.logger.info(f"  - ì¹´í…Œê³ ë¦¬: {ai_summary.get('category', 'None')}")
            self.logger.info(f"  - ì„œë¹„ìŠ¤: {ai_summary.get('services', [])}")
            self.logger.info(f"  - ìœ„ì¹˜: {ai_summary.get('location', 'None')}")
            
            self.logger.info(f"âœ… AI ìš”ì•½ ì™„ë£Œ: {organization_name}")
            return ai_summary
            
        except Exception as e:
            self.logger.error(f"âŒ AI ìš”ì•½ ì‹¤íŒ¨: {organization_name} - {e}")
            import traceback
            self.logger.error(f"ğŸ“Š ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")
            return self._create_fallback_summary(str(e), page_data)
    
    def _parse_ai_summary_response(self, response_text: str, organization_name: str) -> Dict[str, Any]:
        """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜"""
        try:
            # ë°©ë²• 1: JSON í˜•íƒœ ì‘ë‹µ ì‹œë„
            json_result = self._try_parse_json_response(response_text)
            if json_result:
                self.logger.info("JSON í˜•íƒœ ì‘ë‹µ íŒŒì‹± ì„±ê³µ")
                return json_result
            
            # ë°©ë²• 2: êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì‘ë‹µ íŒŒì‹±
            structured_result = self._parse_structured_text_response(response_text)
            if structured_result:
                self.logger.info("êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì‘ë‹µ íŒŒì‹± ì„±ê³µ")
                return structured_result
            
            # ë°©ë²• 3: ììœ  í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ
            text_result = self._extract_from_free_text(response_text, organization_name)
            self.logger.info("ììœ  í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ")
            return text_result
            
        except Exception as e:
            self.logger.error(f"ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_fallback_summary(f"íŒŒì‹± ì˜¤ë¥˜: {e}", {})

    def _try_parse_json_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """JSON í˜•íƒœ ì‘ë‹µ íŒŒì‹± ì‹œë„"""
        try:
            import json
            
            # ```json ë¸”ë¡ì—ì„œ ì¶”ì¶œ
            if '```json' in response_text:
                json_part = response_text.split('```json')[1].split('```')[0].strip()
                parsed = json.loads(json_part)
                return self._normalize_json_structure(parsed)
            
            # { } ì‚¬ì´ì˜ JSON ì¶”ì¶œ
            elif '{' in response_text and '}' in response_text:
                start = response_text.find('{')
                end = response_text.rfind('}') + 1
                json_str = response_text[start:end]
                parsed = json.loads(json_str)
                return self._normalize_json_structure(parsed)
            
            return None
            
        except (json.JSONDecodeError, KeyError, IndexError) as e:
            self.logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None

    def _parse_structured_text_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """SUMMARY:, CATEGORY: í˜•íƒœì˜ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ íŒŒì‹±"""
        try:
            result = {
                "summary": "",
                "category": "ê¸°íƒ€",
                "main_services": [],
                "key_info": {},
                "extracted_features": []
            }
            
            lines = response_text.split('\n')
            
            for line in lines:
                line = line.strip()
                
                if line.startswith('SUMMARY:'):
                    result["summary"] = line.replace('SUMMARY:', '').strip()
                
                elif line.startswith('CATEGORY:'):
                    result["category"] = line.replace('CATEGORY:', '').strip()
                
                elif line.startswith('SERVICES:'):
                    services_text = line.replace('SERVICES:', '').strip()
                    # [ì„œë¹„ìŠ¤1, ì„œë¹„ìŠ¤2] ë˜ëŠ” "ì„œë¹„ìŠ¤1, ì„œë¹„ìŠ¤2" í˜•íƒœ íŒŒì‹±
                    services = self._parse_list_string(services_text)
                    result["main_services"] = services[:3]  # ìµœëŒ€ 3ê°œ
                
                elif line.startswith('ESTABLISHMENT:'):
                    establishment = line.replace('ESTABLISHMENT:', '').strip()
                    if establishment and establishment != "ì •ë³´ì—†ìŒ":
                        result["key_info"]["establishment_year"] = establishment
                
                elif line.startswith('LOCATION:'):
                    location = line.replace('LOCATION:', '').strip()
                    if location:
                        result["key_info"]["location"] = location
                
                elif line.startswith('CONTACT_QUALITY:'):
                    contact_quality = line.replace('CONTACT_QUALITY:', '').strip()
                    if contact_quality in ['ìƒ', 'ì¤‘', 'í•˜']:
                        result["key_info"]["contact_verified"] = contact_quality
                
                elif line.startswith('WEBSITE_QUALITY:'):
                    website_quality = line.replace('WEBSITE_QUALITY:', '').strip()
                    if website_quality in ['ìƒ', 'ì¤‘', 'í•˜']:
                        result["key_info"]["website_quality"] = website_quality
                
                elif line.startswith('FEATURES:'):
                    features_text = line.replace('FEATURES:', '').strip()
                    features = self._parse_list_string(features_text)
                    result["extracted_features"] = features
            
            # ìµœì†Œí•œì˜ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            if result["summary"] or result["category"] != "ê¸°íƒ€":
                return result
            
            return None
            
        except Exception as e:
            self.logger.warning(f"êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None

    def _extract_from_free_text(self, response_text: str, organization_name: str) -> Dict[str, Any]:
        """ììœ  í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)"""
        result = {
            "summary": "",
            "category": "ê¸°íƒ€",
            "main_services": [],
            "key_info": {},
            "extracted_features": []
        }
        
        try:
            # í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½ìœ¼ë¡œ ì‚¬ìš© (ê¸¸ì´ ì œí•œ)
            clean_text = re.sub(r'\s+', ' ', response_text).strip()
            result["summary"] = clean_text[:500] + ("..." if len(clean_text) > 500 else "")
            
            # í‚¤ì›Œë“œë¡œ ì¹´í…Œê³ ë¦¬ ì¶”ì •
            text_lower = response_text.lower()
            
            if any(keyword in text_lower for keyword in ['êµíšŒ', 'church', 'ì˜ˆë°°', 'ëª©íšŒ', 'ì‹ ì•™', 'ì„±ë‹¹']):
                result["category"] = "êµíšŒ"
            elif any(keyword in text_lower for keyword in ['ë³‘ì›', 'hospital', 'ì˜ë£Œ', 'ì§„ë£Œ', 'ì¹˜ë£Œ', 'í´ë¦¬ë‹‰']):
                result["category"] = "ë³‘ì›"
            elif any(keyword in text_lower for keyword in ['í•™êµ', 'school', 'êµìœ¡', 'í•™ìƒ', 'ëŒ€í•™', 'í•™ì›']):
                result["category"] = "êµìœ¡ê¸°ê´€"
            elif any(keyword in text_lower for keyword in ['ì •ë¶€', 'ì‹œì²­', 'êµ¬ì²­', 'ê´€ì²­', '.go.kr', 'ê³µê³µ']):
                result["category"] = "ì •ë¶€ê¸°ê´€"
            elif any(keyword in text_lower for keyword in ['íšŒì‚¬', 'ê¸°ì—…', 'ì‚¬ì—…', '.co.kr', 'ì£¼ì‹íšŒì‚¬']):
                result["category"] = "ê¸°ì—…"
            elif any(keyword in text_lower for keyword in ['ë‹¨ì²´', 'í˜‘íšŒ', 'ì¬ë‹¨', 'ì„¼í„°', '.or.kr']):
                result["category"] = "ë¹„ì˜ë¦¬ë‹¨ì²´"
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ê°€
            result["key_info"]["text_analysis"] = True
            result["key_info"]["organization_name"] = organization_name
            
            self.logger.info(f"ììœ  í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ: {result['category']}")
            
        except Exception as e:
            self.logger.error(f"ììœ  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            result["summary"] = f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
        
        return result

    def _parse_list_string(self, list_str: str) -> List[str]:
        """ë¬¸ìì—´ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ì—¬ëŸ¬ í˜•íƒœ ì§€ì›)"""
        if not list_str:
            return []
        
        try:
            # [item1, item2] í˜•íƒœ
            if list_str.startswith('[') and list_str.endswith(']'):
                import json
                return json.loads(list_str)
            
            # "item1, item2" í˜•íƒœ
            elif ',' in list_str:
                items = [item.strip().strip('"\'') for item in list_str.split(',')]
                return [item for item in items if item]
            
            # ë‹¨ì¼ í•­ëª©
            else:
                clean_item = list_str.strip().strip('"\'')
                return [clean_item] if clean_item else []
                
        except Exception:
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return [list_str.strip()] if list_str.strip() else []

    def _normalize_json_structure(self, parsed_json: Dict[str, Any]) -> Dict[str, Any]:
        """JSON êµ¬ì¡°ë¥¼ í‘œì¤€ í˜•íƒœë¡œ ì •ê·œí™”"""
        normalized = {
            "summary": "",
            "category": "ê¸°íƒ€",
            "main_services": [],
            "key_info": {},
            "extracted_features": []
        }
        
        try:
            # ê¸°ë³¸ í•„ë“œ ë§¤í•‘
            if 'summary' in parsed_json:
                normalized["summary"] = str(parsed_json['summary'])
            
            if 'category' in parsed_json:
                normalized["category"] = str(parsed_json['category'])
            
            if 'main_services' in parsed_json:
                services = parsed_json['main_services']
                if isinstance(services, list):
                    normalized["main_services"] = [str(s) for s in services[:3]]
                elif isinstance(services, str):
                    normalized["main_services"] = [services]
            
            if 'key_info' in parsed_json and isinstance(parsed_json['key_info'], dict):
                normalized["key_info"] = parsed_json['key_info']
            
            if 'extracted_features' in parsed_json:
                features = parsed_json['extracted_features']
                if isinstance(features, list):
                    normalized["extracted_features"] = [str(f) for f in features]
                elif isinstance(features, str):
                    normalized["extracted_features"] = [features]
            
            return normalized
            
        except Exception as e:
            self.logger.error(f"JSON ì •ê·œí™” ì˜¤ë¥˜: {e}")
            return normalized

    def _create_fallback_summary(self, error_msg: str, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ìš”ì•½ ìƒì„±"""
        return {
            "summary": f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {error_msg}",
            "category": "ë¶„ë¥˜ë¶ˆê°€",
            "main_services": [],
            "key_info": {
                "ai_error": True,
                "error_message": error_msg,
                "page_title": page_data.get('title', ''),
                "has_content": bool(page_data.get('text_content', ''))
            },
            "extracted_features": ["AI ë¶„ì„ ì‹¤íŒ¨"]
        }
    
    def process_organizations(self, organizations: List[Dict]) -> List[Dict]:
        """ê¸°ê´€ ëª©ë¡ ì²˜ë¦¬"""
        if not self.driver:
            self.setup_driver()
        
        processed_orgs = []
        total_count = len(organizations)
        success_count = 0
        
        try:
            for i, org in enumerate(organizations, 1):
                try:
                    org_name = org.get('name', 'Unknown')
                    homepage_url = org.get('homepage', '').strip()
                    
                    self.logger.info(f"ì²˜ë¦¬ ì¤‘ ({i}/{total_count}): {org_name}")
                    
                    # ê¸°ì¡´ ë°ì´í„° ë³µì‚¬
                    processed_org = org.copy()
                    
                    # í™ˆí˜ì´ì§€ URLì´ ìˆëŠ” ê²½ìš°ì—ë§Œ íŒŒì‹±
                    if homepage_url and homepage_url.startswith(('http://', 'https://')):
                        self.logger.info(f"ğŸ” í™ˆí˜ì´ì§€ íŒŒì‹± ì‹œì‘: {homepage_url}")
                        
                        # í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ
                        page_data = self.extract_page_content(homepage_url)
                        
                        if page_data["status"] == "success" and page_data["accessible"]:
                            # AI ìš”ì•½
                            ai_summary = self.summarize_with_ai(org_name, page_data)
                            
                            # ê²°ê³¼ í†µí•©
                            processed_org.update({
                                "homepage_parsed": True,
                                "page_title": page_data["title"],
                                "page_content_length": len(page_data["text_content"]),
                                "contact_info_extracted": page_data["contact_info"],
                                "meta_info": page_data["meta_info"],
                                "ai_summary": ai_summary,
                                "parsing_timestamp": datetime.now().isoformat(),
                                "parsing_status": "success"
                            })
                            
                            success_count += 1
                            self.logger.info(f"âœ… íŒŒì‹± ì„±ê³µ: {org_name}")
                            
                        else:
                            # íŒŒì‹± ì‹¤íŒ¨
                            processed_org.update({
                                "homepage_parsed": False,
                                "parsing_status": "failed",
                                "parsing_error": page_data.get("error", "Unknown error"),
                                "parsing_timestamp": datetime.now().isoformat()
                            })
                            self.logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: {org_name} - {page_data.get('error')}")
                    
                    else:
                        # í™ˆí˜ì´ì§€ URLì´ ì—†ëŠ” ê²½ìš°
                        processed_org.update({
                            "homepage_parsed": False,
                            "parsing_status": "no_homepage",
                            "parsing_timestamp": datetime.now().isoformat()
                        })
                        self.logger.info(f"â­ï¸ í™ˆí˜ì´ì§€ ì—†ìŒ: {org_name}")
                    
                    processed_orgs.append(processed_org)
                    
                    # ì§„í–‰ ìƒí™© ì¶œë ¥
                    if i % 10 == 0:
                        success_rate = success_count / i * 100
                        self.logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {success_count}/{i} ({success_rate:.1f}%)")
                    
                    # ì§€ì—° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                    if i < total_count:
                        self.add_delay()
                
                except Exception as e:
                    self.logger.error(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {org.get('name', 'Unknown')} - {e}")
                    # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ ê¸°ë³¸ ë°ì´í„°ëŠ” ë³´ì¡´
                    processed_org = org.copy()
                    processed_org.update({
                        "homepage_parsed": False,
                        "parsing_status": "error",
                        "parsing_error": str(e),
                        "parsing_timestamp": datetime.now().isoformat()
                    })
                    processed_orgs.append(processed_org)
                    continue
        
        finally:
            self.close_driver()
        
        return processed_orgs
    
    def save_results(self, organizations: List[Dict], output_file: str) -> bool:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # ê²°ê³¼ ì €ì¥
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(organizations, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
            return True
            
        except Exception as e:
            self.logger.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    async def ai_search_homepage(self, org_name: str, category: str) -> List[Dict]:
        """AI ê¸°ë°˜ í™ˆí˜ì´ì§€ ê²€ìƒ‰"""
        try:
            self.logger.info(f"ğŸ” AI í™ˆí˜ì´ì§€ ê²€ìƒ‰: {org_name} ({category})")
            
            # AIë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ì „ëµ
            search_results = []
            
            # 1. ê¸°ë³¸ ê²€ìƒ‰ì–´ ìƒì„±
            search_queries = [
                f"{org_name}",
                f"{org_name} {category}",
                f"{org_name} í™ˆí˜ì´ì§€",
                f"{org_name} ê³µì‹ì‚¬ì´íŠ¸"
            ]
            
            # 2. AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ê°œì„ 
            if self.use_ai and self.ai_model:
                try:
                    enhanced_query = await self._generate_enhanced_search_query(org_name, category)
                    if enhanced_query:
                        search_queries.append(enhanced_query)
                except Exception as e:
                    self.logger.warning(f"AI ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            
            # 3. ê° ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰ (ê°„ë‹¨í•œ êµ¬í˜„)
            for query in search_queries[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                try:
                    # ì‹¤ì œ ê²€ìƒ‰ ë¡œì§ (Google ê²€ìƒ‰ API ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
                    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ êµ¬í˜„
                    result = await self._perform_search(query, org_name)
                    if result:
                        search_results.append(result)
                        break  # ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ì°¾ìœ¼ë©´ ì¤‘ë‹¨
                except Exception as e:
                    self.logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨ [{query}]: {e}")
                    continue
            
            self.logger.info(f"AI í™ˆí˜ì´ì§€ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results
            
        except Exception as e:
            self.logger.error(f"AI í™ˆí˜ì´ì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def _generate_enhanced_search_query(self, org_name: str, category: str) -> str:
        """AIë¡œ í–¥ìƒëœ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        try:
            prompt = f"""
            ë‹¤ìŒ ê¸°ê´€ì˜ í™ˆí˜ì´ì§€ë¥¼ ì°¾ê¸° ìœ„í•œ ìµœì ì˜ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
            
            ê¸°ê´€ëª…: {org_name}
            ì¹´í…Œê³ ë¦¬: {category}
            
            ê°€ì¥ íš¨ê³¼ì ì¸ ê²€ìƒ‰ì–´ í•˜ë‚˜ë§Œ ì œì•ˆí•´ì£¼ì„¸ìš”.
            """
            
            response = self.ai_model.generate_content(prompt)
            enhanced_query = response.text.strip()
            
            # ê²€ìƒ‰ì–´ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(enhanced_query) > 100:
                enhanced_query = enhanced_query[:100]
            
            return enhanced_query
            
        except Exception as e:
            self.logger.warning(f"AI ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì˜¤ë¥˜: {e}")
            return ""
    
    async def _perform_search(self, query: str, org_name: str) -> Optional[Dict]:
        """ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰ (ê°„ë‹¨í•œ êµ¬í˜„)"""
        try:
            # ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ì ì¸ URL íŒ¨í„´ì„ ì¶”ì •
            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Google Search API ë“±ì„ ì‚¬ìš©
            
            # ê¸°ë³¸ ë„ë©”ì¸ íŒ¨í„´ë“¤
            domain_patterns = [
                f"www.{org_name.lower().replace(' ', '')}.com",
                f"www.{org_name.lower().replace(' ', '')}.co.kr",
                f"www.{org_name.lower().replace(' ', '')}.or.kr",
                f"{org_name.lower().replace(' ', '')}.com",
                f"{org_name.lower().replace(' ', '')}.co.kr"
            ]
            
            # ê° íŒ¨í„´ì— ëŒ€í•´ ì ‘ê·¼ ì‹œë„
            for pattern in domain_patterns:
                try:
                    test_url = f"https://{pattern}"
                    # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ HTTP ìš”ì²­ì„ ë³´ë‚´ì„œ í™•ì¸
                    # ì§€ê¸ˆì€ ê°„ë‹¨íˆ íŒ¨í„´ë§Œ ë°˜í™˜
                    return {
                        "url": test_url,
                        "type": "ì¶”ì •",
                        "confidence": 0.6,
                        "search_query": query
                    }
                except:
                    continue
            
            return None
            
        except Exception as e:
            self.logger.warning(f"ê²€ìƒ‰ ìˆ˜í–‰ ì˜¤ë¥˜: {e}")
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 70)
    print("ğŸ” í™ˆí˜ì´ì§€ ì§ì ‘ íŒŒì‹± ë° AI ì •ë¦¬ ë„êµ¬")
    print("=" * 70)
    
    try:
        # ì„¤ì •
        use_headless = False  # GUI ëª¨ë“œë¡œ ë¸Œë¼ìš°ì € ì°½ í‘œì‹œ
        print(f"ğŸŒ ë¸Œë¼ìš°ì € ëª¨ë“œ: {'Headless' if use_headless else 'GUI'}")
        print(f"ğŸ¤– AI ìš”ì•½ ê¸°ëŠ¥: {'í™œì„±í™”' if AI_AVAILABLE else 'ë¹„í™œì„±í™”'}")
        print(f"ğŸ² HTML íŒŒì‹±: {'BeautifulSoup ì‚¬ìš©' if BS4_AVAILABLE else 'ê¸°ë³¸ íŒŒì‹±'}")
        
        # íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        parser = HomepageParser(headless=use_headless)
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì • - ë™ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
        current_dir = os.path.dirname(os.path.abspath(__file__))  # test ë””ë ‰í† ë¦¬
        base_dir = os.path.dirname(current_dir)  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        data_json_dir = os.path.join(base_dir, "data", "json")
        
        print(f"ğŸ“‚ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {base_dir}")
        print(f"ğŸ“‚ JSON ë””ë ‰í† ë¦¬: {data_json_dir}")
        
        # ìš°ì„  ìˆœìœ„ íŒŒì¼ ëª©ë¡
        priority_files = [
            "combined.json"
            
        ]
        
        input_file = None
        output_file = os.path.join(base_dir, f"parsed_homepages_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        
        # ìš°ì„ ìˆœìœ„ íŒŒì¼ë“¤ í™•ì¸
        for priority_file in priority_files:
            priority_path = os.path.join(data_json_dir, priority_file)
            if os.path.exists(priority_path):
                input_file = priority_path
                print(f"âœ… ìš°ì„ ìˆœìœ„ íŒŒì¼ ë°œê²¬: {priority_file}")
                break
        
        # ìš°ì„ ìˆœìœ„ íŒŒì¼ì´ ì—†ìœ¼ë©´ data/json ë””ë ‰í† ë¦¬ì—ì„œ íƒìƒ‰
        if not input_file:
            print(f"ğŸ“‚ data/json ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ íƒìƒ‰ ì¤‘...")
            
            if os.path.exists(data_json_dir):
                json_files = [f for f in os.listdir(data_json_dir) 
                             if f.endswith('.json') and 'homepage' in f.lower()]
                
                if json_files:
                    # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹  íŒŒì¼ ìš°ì„ )
                    json_files.sort(reverse=True)
                    print(f"ğŸ“ data/json ë””ë ‰í† ë¦¬ì˜ í™ˆí˜ì´ì§€ ê´€ë ¨ JSON íŒŒì¼ë“¤:")
                    for i, file in enumerate(json_files, 1):
                        file_path = os.path.join(data_json_dir, file)
                        file_size = os.path.getsize(file_path) // 1024  # KB
                        print(f"  {i}. {file} ({file_size}KB)")
                    
                    # ì‚¬ìš©ìê°€ íŒŒì¼ ì„ íƒí•  ìˆ˜ ìˆë„ë¡
                    choice = input(f"\nì‚¬ìš©í•  íŒŒì¼ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(json_files)}, ì—”í„°=1ë²ˆ íŒŒì¼): ").strip()
                    
                    if choice == "":
                        choice_idx = 0  # ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ íŒŒì¼
                    elif choice.isdigit():
                        choice_idx = int(choice) - 1
                    else:
                        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                        return 1
                    
                    if 0 <= choice_idx < len(json_files):
                        input_file = os.path.join(data_json_dir, json_files[choice_idx])
                        print(f"âœ… ì„ íƒëœ íŒŒì¼: {json_files[choice_idx]}")
                    else:
                        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                        return 1
                else:
                    print("âŒ data/json ë””ë ‰í† ë¦¬ì— í™ˆí˜ì´ì§€ ê´€ë ¨ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # ì¼ë°˜ JSON íŒŒì¼ë“¤ë„ íƒìƒ‰
                    all_json_files = [f for f in os.listdir(data_json_dir) if f.endswith('.json')]
                    if all_json_files:
                        print(f"ğŸ“ data/json ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  JSON íŒŒì¼ë“¤:")
                        for i, file in enumerate(all_json_files, 1):
                            file_path = os.path.join(data_json_dir, file)
                            file_size = os.path.getsize(file_path) // 1024  # KB
                            print(f"  {i}. {file} ({file_size}KB)")
                        
                        choice = input(f"\nì‚¬ìš©í•  íŒŒì¼ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(all_json_files)}, ì—”í„°=ì¢…ë£Œ): ").strip()
                        if choice and choice.isdigit():
                            choice_idx = int(choice) - 1
                            if 0 <= choice_idx < len(all_json_files):
                                input_file = os.path.join(data_json_dir, all_json_files[choice_idx])
                                print(f"âœ… ì„ íƒëœ íŒŒì¼: {all_json_files[choice_idx]}")
                            else:
                                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                                return 1
                        else:
                            print("â¹ï¸ ì‘ì—…ì„ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                            return 1
                    else:
                        print("âŒ data/json ë””ë ‰í† ë¦¬ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                        return 1
            else:
                print(f"âŒ data/json ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_json_dir}")
                return 1
        
        print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {input_file}")
        print(f"ğŸ’¾ ì¶œë ¥ íŒŒì¼: {output_file}")
        
        # JSON íŒŒì¼ ë¡œë“œ
        print("ğŸ“– ë°ì´í„° ë¡œë”© ì¤‘...")
        with open(input_file, 'r', encoding='utf-8') as f:
            organizations = json.load(f)
        
        print(f"ğŸ“Š ë¡œë“œëœ ê¸°ê´€ ìˆ˜: {len(organizations)}")
        
        # í™ˆí˜ì´ì§€ê°€ ìˆëŠ” ê¸°ê´€ë§Œ í™•ì¸
        orgs_with_homepage = [org for org in organizations 
                            if org.get('homepage') and org['homepage'].strip().startswith(('http://', 'https://'))]
        print(f"ğŸŒ í™ˆí˜ì´ì§€ê°€ ìˆëŠ” ê¸°ê´€: {len(orgs_with_homepage)}ê°œ")
        
        # ì²˜ë¦¬í•  ê¸°ê´€ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
        max_process = input(f"ì²˜ë¦¬í•  ê¸°ê´€ ìˆ˜ (ì „ì²´: {len(organizations)}, í™ˆí˜ì´ì§€ ìˆìŒ: {len(orgs_with_homepage)}, ì—”í„°=ì „ì²´): ").strip()
        if max_process:
            max_process = int(max_process)
            organizations = organizations[:max_process]
        
        print(f"\nğŸ”„ {len(organizations)}ê°œ ê¸°ê´€ ì²˜ë¦¬ ì‹œì‘...")
        print("ğŸ“ ì‹¤ì œ ë¸Œë¼ìš°ì €ë¡œ í™ˆí˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ íŒŒì‹±í•©ë‹ˆë‹¤.")
        print("ğŸ¤– AIê°€ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.")
        
        # ì²˜ë¦¬ ì‹œì‘
        processed_organizations = parser.process_organizations(organizations)
        
        # ê²°ê³¼ ì €ì¥
        if parser.save_results(processed_organizations, output_file):
            print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
            
            # í†µê³„ ê³„ì‚°
            total_processed = len(processed_organizations)
            successful_parses = sum(1 for org in processed_organizations 
                                  if org.get('parsing_status') == 'success')
            failed_parses = sum(1 for org in processed_organizations 
                              if org.get('parsing_status') == 'failed')
            no_homepage = sum(1 for org in processed_organizations 
                            if org.get('parsing_status') == 'no_homepage')
            error_count = sum(1 for org in processed_organizations 
                            if org.get('parsing_status') == 'error')
            
            print(f"\nğŸ“ˆ ìµœì¢… í†µê³„:")
            print(f"  - ì „ì²´ ê¸°ê´€: {total_processed}ê°œ")
            print(f"  - íŒŒì‹± ì„±ê³µ: {successful_parses}ê°œ")
            print(f"  - íŒŒì‹± ì‹¤íŒ¨: {failed_parses}ê°œ")
            print(f"  - í™ˆí˜ì´ì§€ ì—†ìŒ: {no_homepage}ê°œ")
            print(f"  - ì²˜ë¦¬ ì˜¤ë¥˜: {error_count}ê°œ")
            if successful_parses > 0:
                print(f"  - ì„±ê³µë¥ : {successful_parses/(successful_parses+failed_parses)*100:.1f}%")
            
            # ìƒ˜í”Œ ê²°ê³¼ ì¶œë ¥
            successful_orgs = [org for org in processed_organizations 
                             if org.get('parsing_status') == 'success']
            if successful_orgs:
                print(f"\nğŸ“‹ ìƒ˜í”Œ ê²°ê³¼:")
                sample_org = successful_orgs[0]
                print(f"  ê¸°ê´€ëª…: {sample_org.get('name', 'Unknown')}")
                print(f"  í™ˆí˜ì´ì§€: {sample_org.get('homepage', 'None')}")
                print(f"  AI ìš”ì•½: {sample_org.get('ai_summary', {}).get('summary', 'None')[:100]}...")
        
        else:
            print(f"\nâŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")
            return 1
        
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())