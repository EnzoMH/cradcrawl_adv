#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê³ ê¸‰ êµíšŒ ì—°ë½ì²˜ í¬ë¡¤ëŸ¬
í™ˆí˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ê³  AIë¥¼ í™œìš©í•˜ì—¬ ì—°ë½ì²˜ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import json
import requests
import asyncio
import re
import time
import random
import os
import glob
from datetime import datetime
from typing import Dict, List, Any, Optional
from urllib.parse import urljoin, urlparse
import logging

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    print("âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install python-dotenv ì‹¤í–‰ í•„ìš”")
    print("ğŸ’¡ ìˆ˜ë™ìœ¼ë¡œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •ì„ ì‹œë„í•©ë‹ˆë‹¤...")
    
    # .env íŒŒì¼ ìˆ˜ë™ ë¡œë“œ
    try:
        env_path = os.path.join(os.getcwd(), '.env')
        if os.path.exists(env_path):
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"\'')  # ë”°ì˜´í‘œ ì œê±°
                        os.environ[key] = value
            print("âœ… .env íŒŒì¼ ìˆ˜ë™ ë¡œë“œ ì™„ë£Œ")
        else:
            print("âŒ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ .env íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

from bs4 import BeautifulSoup
from parser import WebPageParser
from validator import ContactValidator
from ai_helpers import AIModelManager
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class AdvancedChurchCrawler:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.setup_logger()
        
        # API í‚¤ í™•ì¸
        api_key = os.getenv('GEMINI_API_KEY')
        if api_key:
            print(f"ğŸ”‘ GEMINI_API_KEY ë¡œë“œ ì„±ê³µ: {api_key[:10]}...{api_key[-4:]}")
        else:
            print("âŒ GEMINI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ .env íŒŒì¼ì— GEMINI_API_KEY='your_api_key' í˜•ì‹ìœ¼ë¡œ ì €ì¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.web_parser = WebPageParser()
        self.validator = ContactValidator()
        
        # AI ë§¤ë‹ˆì € ì´ˆê¸°í™” (ê°œì„ )
        self.ai_manager = None
        self.use_ai = False
        
        try:
            if api_key:
                self.ai_manager = AIModelManager()
                self.use_ai = True
                print("ğŸ¤– AI ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì„±ê³µ")
            else:
                print("ğŸ”§ AI ê¸°ëŠ¥ ë¹„í™œì„±í™” (API í‚¤ ì—†ìŒ)")
        except Exception as e:
            print(f"âŒ AI ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.ai_manager = None
            self.use_ai = False
        
        # í¬ë¡¤ë§ ì„¤ì •
        self.timeout = 10
        self.max_retries = 3
        self.delay_range = (1, 3)
        
        # í†µê³„
        self.stats = {
            'total_processed': 0,
            'successful_crawls': 0,
            'failed_crawls': 0,
            'ai_enhanced': 0,
            'contacts_found': 0,
            'api_calls_made': 0,
            'ai_failures': 0
        }
        
        # ì„¸ì…˜ ì„¤ì •
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
    
    def setup_logger(self):
        """ë¡œê±° ì„¤ì •"""
        self.logger = logging.getLogger('adv_crawler')
        self.logger.setLevel(logging.INFO)
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter('%(asctime)s - [ê³ ê¸‰í¬ë¡¤ëŸ¬] - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(console_handler)
    
    def load_json_data(self, filepath: str) -> List[Dict]:
        """JSON íŒŒì¼ ë¡œë“œ"""
        try:
            print(f"ğŸ“‚ JSON íŒŒì¼ ë¡œë”©: {filepath}")
            
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                print(f"âœ… {len(data)}ê°œ êµíšŒ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                return data
            else:
                print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” JSON í˜•ì‹ì…ë‹ˆë‹¤.")
                return []
                
        except Exception as e:
            print(f"âŒ JSON íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
            return []
    
    def fetch_webpage(self, url: str) -> Optional[str]:
        """ì›¹í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        if not url or not url.startswith(('http://', 'https://')):
            return None
        
        try:
            self.logger.info(f"ì›¹í˜ì´ì§€ ìš”ì²­: {url}")
            
            response = self.session.get(
                url, 
                timeout=self.timeout, 
                verify=False,
                allow_redirects=True
            )
            
            # ì¸ì½”ë”© ì„¤ì •
            response.encoding = response.apparent_encoding or 'utf-8'
            
            if response.status_code == 200:
                self.logger.info(f"ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {url}")
                return response.text
            else:
                self.logger.warning(f"HTTP ì˜¤ë¥˜ {response.status_code}: {url}")
                return None
                
        except requests.exceptions.Timeout:
            self.logger.warning(f"íƒ€ì„ì•„ì›ƒ: {url}")
            return None
        except requests.exceptions.RequestException as e:
            self.logger.warning(f"ìš”ì²­ ì‹¤íŒ¨: {url} - {e}")
            return None
        except Exception as e:
            self.logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {url} - {e}")
            return None
    
    def parse_with_bs4(self, html_content: str, base_url: str) -> Dict[str, Any]:
        """BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            parsed_data = {
                'title': '',
                'meta_description': '',
                'all_text': '',
                'footer_text': '',
                'contact_sections': []
            }
            
            # ì œëª© ì¶”ì¶œ
            title_tag = soup.find('title')
            if title_tag:
                parsed_data['title'] = title_tag.get_text().strip()
            
            # ë©”íƒ€ ì„¤ëª… ì¶”ì¶œ
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc:
                parsed_data['meta_description'] = meta_desc.get('content', '')
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼ ì œê±°)
            for script in soup(["script", "style"]):
                script.decompose()
            
            parsed_data['all_text'] = soup.get_text()
            
            # footer ì˜ì—­ ì¶”ì¶œ
            footer_elements = soup.find_all(['footer', 'div'], 
                                          class_=re.compile(r'footer|bottom|contact|info', re.I))
            footer_texts = []
            for footer in footer_elements:
                footer_text = footer.get_text().strip()
                if footer_text and len(footer_text) > 20:
                    footer_texts.append(footer_text)
            
            parsed_data['footer_text'] = '\n'.join(footer_texts)
            
            # ì—°ë½ì²˜ ê´€ë ¨ ì„¹ì…˜ ì¶”ì¶œ
            contact_keywords = ['ì—°ë½ì²˜', 'contact', 'ì „í™”', 'phone', 'íŒ©ìŠ¤', 'fax', 'ì´ë©”ì¼', 'email']
            contact_elements = soup.find_all(text=re.compile('|'.join(contact_keywords), re.I))
            
            for element in contact_elements[:10]:  # ìµœëŒ€ 10ê°œë§Œ
                parent = element.parent
                if parent:
                    section_text = parent.get_text().strip()
                    if len(section_text) > 10:
                        parsed_data['contact_sections'].append(section_text)
            
            return parsed_data
            
        except Exception as e:
            self.logger.error(f"BS4 íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {'all_text': html_content[:5000]}  # ì‹¤íŒ¨ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì¼ë¶€ ë°˜í™˜
    
    def extract_with_parser(self, parsed_data: Dict[str, Any]) -> Dict[str, List]:
        """parser.pyë¥¼ ì´ìš©í•œ ê¸°ë³¸ ì¶”ì¶œ"""
        try:
            # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ
            all_text = parsed_data.get('all_text', '')
            footer_text = parsed_data.get('footer_text', '')
            contact_sections = ' '.join(parsed_data.get('contact_sections', []))
            
            # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í…ìŠ¤íŠ¸ ê²°í•©
            combined_text = f"{footer_text}\n{contact_sections}\n{all_text}"
            
            # parserë¡œ ì¶”ì¶œ
            extracted_contacts = self.web_parser.extract_contact_info(combined_text)
            
            self.logger.info(f"Parser ì¶”ì¶œ ì™„ë£Œ: {len(extracted_contacts.get('phones', []))}ê°œ ì „í™”ë²ˆí˜¸, "
                           f"{len(extracted_contacts.get('faxes', []))}ê°œ íŒ©ìŠ¤ë²ˆí˜¸, "
                           f"{len(extracted_contacts.get('emails', []))}ê°œ ì´ë©”ì¼")
            
            return extracted_contacts
            
        except Exception as e:
            self.logger.error(f"Parser ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {'phones': [], 'faxes': [], 'emails': [], 'addresses': []}
    
    def validate_with_validator(self, extracted_data: Dict[str, List]) -> Dict[str, List]:
        """validator.pyë¥¼ ì´ìš©í•œ ê²€ì¦"""
        try:
            validated_data = {
                'phones': [],
                'faxes': [],
                'emails': [],
                'addresses': [],
                'postal_codes': []
            }
            
            # ì „í™”ë²ˆí˜¸ ê²€ì¦
            for phone in extracted_data.get('phones', []):
                is_valid, result = self.validator.validate_phone_number(phone)
                if is_valid:
                    validated_data['phones'].append(result)
            
            # íŒ©ìŠ¤ë²ˆí˜¸ ê²€ì¦
            for fax in extracted_data.get('faxes', []):
                is_valid, result = self.validator.validate_fax_number(fax)
                if is_valid:
                    validated_data['faxes'].append(result)
            
            # ì´ë©”ì¼ì€ ê¸°ë³¸ ê²€ì¦ë§Œ (validatorì— ì´ë©”ì¼ ê²€ì¦ í•¨ìˆ˜ê°€ ì—†ìœ¼ë¯€ë¡œ)
            validated_data['emails'] = extracted_data.get('emails', [])
            validated_data['addresses'] = extracted_data.get('addresses', [])
            
            # ìš°í¸ë²ˆí˜¸ ì¶”ì¶œ (ì£¼ì†Œì—ì„œ)
            for address in validated_data['addresses']:
                postal_matches = re.findall(r'\b\d{5}\b', address)
                for postal in postal_matches:
                    if postal not in validated_data['postal_codes']:
                        validated_data['postal_codes'].append(postal)
            
            self.logger.info(f"Validator ê²€ì¦ ì™„ë£Œ: {len(validated_data['phones'])}ê°œ ìœ íš¨ ì „í™”ë²ˆí˜¸, "
                           f"{len(validated_data['faxes'])}ê°œ ìœ íš¨ íŒ©ìŠ¤ë²ˆí˜¸")
            
            return validated_data
            
        except Exception as e:
            self.logger.error(f"Validator ê²€ì¦ ì˜¤ë¥˜: {e}")
            return extracted_data
    
    async def enhance_with_ai(self, parsed_data: Dict[str, Any], church_name: str) -> Dict[str, List]:
        """AIë¥¼ ì´ìš©í•œ ì¶”ê°€ ì¶”ì¶œ"""
        if not self.use_ai or not self.ai_manager:
            print(f"  ğŸ”§ AI ê¸°ëŠ¥ ë¹„í™œì„±í™” - ê¸°ë³¸ ì¶”ì¶œë§Œ ì‚¬ìš©")
            return {}
        
        try:
            print(f"  ğŸ¤– AI ì¶”ê°€ ì¶”ì¶œ ì‹œì‘: {church_name}")
            self.stats['api_calls_made'] += 1
            
            # AIìš© í…ìŠ¤íŠ¸ ì¤€ë¹„ (ê¸¸ì´ ì œí•œ)
            all_text = parsed_data.get('all_text', '')
            footer_text = parsed_data.get('footer_text', '')
            contact_sections = ' '.join(parsed_data.get('contact_sections', []))
            
            # ì¤‘ìš” ì„¹ì…˜ ìš°ì„  ì¡°í•©
            ai_text_parts = []
            if footer_text:
                ai_text_parts.append(f"=== Footer ì •ë³´ ===\n{footer_text[:1500]}")
            if contact_sections:
                ai_text_parts.append(f"=== ì—°ë½ì²˜ ì„¹ì…˜ ===\n{contact_sections[:1500]}")
            if all_text:
                ai_text_parts.append(f"=== ê¸°íƒ€ ë‚´ìš© ===\n{all_text[:2000]}")
            
            ai_text = '\n\n'.join(ai_text_parts)
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 5000ì)
            if len(ai_text) > 5000:
                ai_text = ai_text[:5000]
            
            # AI í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt_template = """
'{church_name}' êµíšŒì˜ ì—°ë½ì²˜ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**êµíšŒëª…:** {church_name}

**ì¶”ì¶œí•  ì •ë³´:**
- ì „í™”ë²ˆí˜¸: í•œêµ­ í˜•ì‹ (02-1234-5678, 031-123-4567, 010-1234-5678)
- íŒ©ìŠ¤ë²ˆí˜¸: í•œêµ­ í˜•ì‹ (02-1234-5679)
- ì´ë©”ì¼: ìœ íš¨í•œ í˜•ì‹ (info@church.com)
- íœ´ëŒ€í°: 010ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë²ˆí˜¸
- ìš°í¸ë²ˆí˜¸: 5ìë¦¬ ìˆ«ì
- ì£¼ì†Œ: ì™„ì „í•œ ì£¼ì†Œ

**ì‘ë‹µ í˜•ì‹:** (ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”)
```markdown
## ì—°ë½ì²˜ ì •ë³´

**ì „í™”ë²ˆí˜¸:** [ë°œê²¬ëœ ë²ˆí˜¸ ë˜ëŠ” "ì—†ìŒ"]
**íŒ©ìŠ¤ë²ˆí˜¸:** [ë°œê²¬ëœ ë²ˆí˜¸ ë˜ëŠ” "ì—†ìŒ"]  
**ì´ë©”ì¼:** [ë°œê²¬ëœ ì´ë©”ì¼ ë˜ëŠ” "ì—†ìŒ"]
**íœ´ëŒ€í°:** [ë°œê²¬ëœ íœ´ëŒ€í° ë˜ëŠ” "ì—†ìŒ"]
**ìš°í¸ë²ˆí˜¸:** [ë°œê²¬ëœ ìš°í¸ë²ˆí˜¸ ë˜ëŠ” "ì—†ìŒ"]
**ì£¼ì†Œ:** [ë°œê²¬ëœ ì£¼ì†Œ ë˜ëŠ” "ì—†ìŒ"]
```

**ì¤‘ìš” ê·œì¹™:**
1. {church_name}ì™€ ì§ì ‘ ê´€ë ¨ëœ ì—°ë½ì²˜ë§Œ ì¶”ì¶œ
2. ëŒ€í‘œë²ˆí˜¸, ë©”ì¸ ì—°ë½ì²˜ ìš°ì„ 
3. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ "ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ

**ë¶„ì„í•  í…ìŠ¤íŠ¸:**
{{text_content}}
"""
            
            # í”„ë¡¬í”„íŠ¸ì— êµíšŒëª…ê³¼ í…ìŠ¤íŠ¸ ì‚½ì…
            final_prompt = prompt_template.format(church_name=church_name)
            
            # AI í˜¸ì¶œ
            ai_response = await self.ai_manager.extract_with_gemini(ai_text, final_prompt)
            
            if ai_response:
                ai_extracted = self.parse_ai_response(ai_response)
                self.stats['ai_enhanced'] += 1
                print(f"  âœ… AI ì¶”ì¶œ ì™„ë£Œ: {church_name}")
                return ai_extracted
            else:
                print(f"  âš ï¸ AI ì‘ë‹µ ì—†ìŒ: {church_name}")
                self.stats['ai_failures'] += 1
                return {}
                
        except Exception as e:
            print(f"  âŒ AI ì¶”ì¶œ ì˜¤ë¥˜ ({church_name}): {e}")
            self.stats['ai_failures'] += 1
            self.logger.error(f"AI ì¶”ì¶œ ì˜¤ë¥˜ ({church_name}): {e}")
            return {}
    
    def parse_ai_response(self, ai_response: str) -> Dict[str, List]:
        """AI ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”"""
        try:
            result = {
                'phones': [],
                'faxes': [],
                'emails': [],
                'mobiles': [],
                'postal_codes': [],
                'addresses': []
            }
            
            # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ íŒŒì‹±
            lines = ai_response.split('\n')
            
            for line in lines:
                line = line.strip()
                if ':' in line and ('**' in line or '*' in line):
                    # ë§ˆí¬ë‹¤ìš´ ë³¼ë“œ ì œê±°
                    line = line.replace('**', '').replace('*', '')
                    
                    try:
                        key, value = line.split(':', 1)
                        key = key.strip().lower()
                        value = value.strip()
                        
                        if value and value not in ["ì—†ìŒ", "ì •ë³´ì—†ìŒ", "í™•ì¸ì•ˆë¨", "-"]:
                            if 'ì „í™”ë²ˆí˜¸' in key or 'phone' in key:
                                if self._is_valid_phone_format(value):
                                    result['phones'].append(value)
                            elif 'íŒ©ìŠ¤' in key or 'fax' in key:
                                if self._is_valid_phone_format(value):
                                    result['faxes'].append(value)
                            elif 'ì´ë©”ì¼' in key or 'email' in key:
                                if self._is_valid_email_format(value):
                                    result['emails'].append(value)
                            elif 'íœ´ëŒ€í°' in key or 'mobile' in key:
                                if value.startswith('010') and self._is_valid_phone_format(value):
                                    result['mobiles'].append(value)
                            elif 'ìš°í¸ë²ˆí˜¸' in key or 'postal' in key:
                                if re.match(r'^\d{5}$', value):
                                    result['postal_codes'].append(value)
                            elif 'ì£¼ì†Œ' in key or 'address' in key:
                                if len(value) > 10:
                                    result['addresses'].append(value)
                    except ValueError:
                        continue
            
            return result
            
        except Exception as e:
            self.logger.error(f"AI ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {}
    
    def _is_valid_phone_format(self, phone: str) -> bool:
        """ì „í™”ë²ˆí˜¸ í˜•ì‹ ê²€ì¦"""
        phone_pattern = r'^\d{2,3}-\d{3,4}-\d{4}$'
        return bool(re.match(phone_pattern, phone))
    
    def _is_valid_email_format(self, email: str) -> bool:
        """ì´ë©”ì¼ í˜•ì‹ ê²€ì¦"""
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return bool(re.match(email_pattern, email))
    
    def merge_extraction_results(self, parser_result: Dict, validator_result: Dict, ai_result: Dict) -> Dict:
        """ëª¨ë“  ì¶”ì¶œ ê²°ê³¼ë¥¼ ë³‘í•©"""
        merged = {
            'phone': [],
            'fax': [],
            'email': [],
            'mobile': [],
            'postal_code': [],
            'address': []
        }
        
        try:
            # ì „í™”ë²ˆí˜¸ ë³‘í•© (ê²€ì¦ëœ ê²ƒ ìš°ì„ )
            all_phones = validator_result.get('phones', []) + parser_result.get('phones', []) + ai_result.get('phones', [])
            merged['phone'] = list(dict.fromkeys(all_phones))  # ì¤‘ë³µ ì œê±°
            
            # íŒ©ìŠ¤ë²ˆí˜¸ ë³‘í•©
            all_faxes = validator_result.get('faxes', []) + parser_result.get('faxes', []) + ai_result.get('faxes', [])
            merged['fax'] = list(dict.fromkeys(all_faxes))
            
            # ì´ë©”ì¼ ë³‘í•©
            all_emails = validator_result.get('emails', []) + parser_result.get('emails', []) + ai_result.get('emails', [])
            merged['email'] = list(dict.fromkeys(all_emails))
            
            # íœ´ëŒ€í° ë³‘í•© (AI ê²°ê³¼ ìš°ì„ )
            merged['mobile'] = list(dict.fromkeys(ai_result.get('mobiles', [])))
            
            # ìš°í¸ë²ˆí˜¸ ë³‘í•©
            all_postals = validator_result.get('postal_codes', []) + ai_result.get('postal_codes', [])
            merged['postal_code'] = list(dict.fromkeys(all_postals))
            
            # ì£¼ì†Œ ë³‘í•©
            all_addresses = validator_result.get('addresses', []) + parser_result.get('addresses', []) + ai_result.get('addresses', [])
            merged['address'] = list(dict.fromkeys(all_addresses))
            
            # ìµœëŒ€ 1ê°œì”©ë§Œ ìœ ì§€ (ê°€ì¥ ì²« ë²ˆì§¸ ê°’)
            for key in merged:
                if merged[key]:
                    merged[key] = merged[key][0]  # ì²« ë²ˆì§¸ ê°’ë§Œ
                else:
                    merged[key] = ""  # ë¹ˆ ë¬¸ìì—´
            
            return merged
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ë³‘í•© ì˜¤ë¥˜: {e}")
            return merged
    
    async def process_single_church(self, church_data: Dict) -> Dict:
        """ë‹¨ì¼ êµíšŒ ì²˜ë¦¬"""
        church_name = church_data.get('name', 'Unknown')
        homepage = church_data.get('homepage', '')
        
        print(f"\nğŸ¢ ì²˜ë¦¬ ì¤‘: {church_name}")
        self.logger.info(f"êµíšŒ ì²˜ë¦¬ ì‹œì‘: {church_name}")
        
        result = church_data.copy()  # ê¸°ì¡´ ë°ì´í„° ë³µì‚¬
        
        # ì¶”ì¶œëœ ì—°ë½ì²˜ ì •ë³´ ì´ˆê¸°í™”
        extraction_summary = {
            'parser_extracted': {},
            'validator_result': {},
            'ai_enhanced': {},
            'final_merged': {},
            'extraction_timestamp': datetime.now().isoformat(),
            'homepage_status': 'not_processed',
            'ai_used': self.use_ai
        }
        
        self.stats['total_processed'] += 1
        
        # í™ˆí˜ì´ì§€ê°€ ì—†ëŠ” ê²½ìš°
        if not homepage:
            print(f"  âš ï¸ í™ˆí˜ì´ì§€ URL ì—†ìŒ")
            extraction_summary['homepage_status'] = 'no_url'
            result['extraction_summary'] = extraction_summary
            return result
        
        try:
            # 1ë‹¨ê³„: ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
            print(f"  ğŸŒ í™ˆí˜ì´ì§€ ì ‘ì†: {homepage}")
            html_content = self.fetch_webpage(homepage)
            
            if not html_content:
                print(f"  âŒ í™ˆí˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨")
                extraction_summary['homepage_status'] = 'fetch_failed'
                self.stats['failed_crawls'] += 1
                result['extraction_summary'] = extraction_summary
                return result
            
            # 2ë‹¨ê³„: BS4ë¡œ íŒŒì‹±
            print(f"  ğŸ“„ HTML íŒŒì‹± ì¤‘...")
            parsed_data = self.parse_with_bs4(html_content, homepage)
            extraction_summary['homepage_status'] = 'parsed'
            
            # 3ë‹¨ê³„: parser.pyë¡œ ê¸°ë³¸ ì¶”ì¶œ
            print(f"  ğŸ” ê¸°ë³¸ ì—°ë½ì²˜ ì¶”ì¶œ ì¤‘...")
            parser_result = self.extract_with_parser(parsed_data)
            extraction_summary['parser_extracted'] = parser_result
            
            # 4ë‹¨ê³„: validator.pyë¡œ ê²€ì¦
            print(f"  âœ… ì—°ë½ì²˜ ê²€ì¦ ì¤‘...")
            validator_result = self.validate_with_validator(parser_result)
            extraction_summary['validator_result'] = validator_result
            
            # 5ë‹¨ê³„: AIë¡œ ì¶”ê°€ ì¶”ì¶œ
            ai_result = await self.enhance_with_ai(parsed_data, church_name)
            extraction_summary['ai_enhanced'] = ai_result
            
            # 6ë‹¨ê³„: ê²°ê³¼ ë³‘í•©
            print(f"  ğŸ”„ ê²°ê³¼ ë³‘í•© ì¤‘...")
            merged_result = self.merge_extraction_results(parser_result, validator_result, ai_result)
            extraction_summary['final_merged'] = merged_result
            
            # 7ë‹¨ê³„: ê¸°ì¡´ ë¹ˆ ê°’ì„ ì¶”ì¶œëœ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            contact_fields = ['phone', 'fax', 'email', 'mobile', 'postal_code', 'address']
            updated_fields = []
            
            for field in contact_fields:
                if not result.get(field) and merged_result.get(field):
                    result[field] = merged_result[field]
                    updated_fields.append(field)
            
            if updated_fields:
                print(f"  âœ¨ ì—…ë°ì´íŠ¸ëœ í•„ë“œ: {', '.join(updated_fields)}")
                self.stats['contacts_found'] += 1
            
            extraction_summary['updated_fields'] = updated_fields
            extraction_summary['homepage_status'] = 'completed'
            self.stats['successful_crawls'] += 1
            
            print(f"  âœ… ì²˜ë¦¬ ì™„ë£Œ: {church_name}")
            
        except Exception as e:
            print(f"  âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            extraction_summary['homepage_status'] = 'error'
            extraction_summary['error'] = str(e)
            self.stats['failed_crawls'] += 1
            self.logger.error(f"êµíšŒ ì²˜ë¦¬ ì˜¤ë¥˜ ({church_name}): {e}")
        
        result['extraction_summary'] = extraction_summary
        return result
    
    async def process_all_churches(self, churches_data: List[Dict]) -> List[Dict]:
        """ëª¨ë“  êµíšŒ ì²˜ë¦¬"""
        print(f"\nğŸš€ ì´ {len(churches_data)}ê°œ êµíšŒ ì²˜ë¦¬ ì‹œì‘")
        
        results = []
        
        for i, church in enumerate(churches_data):
            print(f"\nğŸ“ ì§„í–‰ìƒí™©: {i+1}/{len(churches_data)}")
            
            # êµíšŒ ì²˜ë¦¬
            result = await self.process_single_church(church)
            results.append(result)
            
            # ì¤‘ê°„ ì €ì¥ (50ê°œë§ˆë‹¤)
            if (i + 1) % 50 == 0:
                await self.save_intermediate_results(results, i + 1)
            
            # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
            delay = random.uniform(*self.delay_range)
            await asyncio.sleep(delay)
        
        return results
    
    async def save_intermediate_results(self, results: List[Dict], count: int):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"churches_enhanced_intermediate_{count}_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {filename} ({count}ê°œ ì²˜ë¦¬ë¨)")
            
        except Exception as e:
            print(f"âŒ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def cleanup_intermediate_files(self):
        """ì¤‘ê°„ ê²°ê³¼ íŒŒì¼ë“¤ ì¼ê´„ ì‚­ì œ"""
        try:
            # churches_enhanced_intermediate_*.json íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°
            intermediate_files = glob.glob("churches_enhanced_intermediate_*.json")
            
            if not intermediate_files:
                print("ğŸ—‚ï¸ ì‚­ì œí•  ì¤‘ê°„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            deleted_count = 0
            for file in intermediate_files:
                try:
                    os.remove(file)
                    print(f"ğŸ—‘ï¸ ì‚­ì œë¨: {file}")
                    deleted_count += 1
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({file}): {e}")
            
            print(f"âœ… ì¤‘ê°„ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {deleted_count}ê°œ íŒŒì¼ ì‚­ì œ")
            
        except Exception as e:
            print(f"âŒ ì¤‘ê°„ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def save_final_results(self, results: List[Dict]) -> str:
        """ìµœì¢… ê²°ê³¼ ì €ì¥"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"churches_enhanced_final_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ìµœì¢… ê²°ê³¼ ì €ì¥: {filename}")
            
            # ì¤‘ê°„ íŒŒì¼ë“¤ ì •ë¦¬
            print("ğŸ§¹ ì¤‘ê°„ íŒŒì¼ ì •ë¦¬ ì¤‘...")
            self.cleanup_intermediate_files()
            
            return filename
            
        except Exception as e:
            print(f"âŒ ìµœì¢… ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def print_final_statistics(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        print(f"\nğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ í†µê³„:")
        print(f"  ğŸ“‹ ì´ ì²˜ë¦¬: {self.stats['total_processed']}ê°œ")
        print(f"  âœ… ì„±ê³µ: {self.stats['successful_crawls']}ê°œ")
        print(f"  âŒ ì‹¤íŒ¨: {self.stats['failed_crawls']}ê°œ")
        print(f"  ğŸ¤– AI í˜¸ì¶œ: {self.stats['api_calls_made']}íšŒ")
        print(f"  ğŸ¯ AI ì„±ê³µ: {self.stats['ai_enhanced']}ê°œ")
        print(f"  âš ï¸ AI ì‹¤íŒ¨: {self.stats['ai_failures']}ê°œ")
        print(f"  ğŸ“ ì—°ë½ì²˜ ë°œê²¬: {self.stats['contacts_found']}ê°œ")
        
        if self.stats['total_processed'] > 0:
            success_rate = (self.stats['successful_crawls'] / self.stats['total_processed']) * 100
            print(f"  ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        if self.stats['api_calls_made'] > 0:
            ai_success_rate = (self.stats['ai_enhanced'] / self.stats['api_calls_made']) * 100
            print(f"  ğŸ¤– AI ì„±ê³µë¥ : {ai_success_rate:.1f}%")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ ê³ ê¸‰ êµíšŒ ì—°ë½ì²˜ í¬ë¡¤ëŸ¬ v2.0")
    print("=" * 60)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    api_key = os.getenv('GEMINI_API_KEY')
    if api_key:
        print(f"ğŸ”‘ API í‚¤ í™•ì¸: ...{api_key[-10:]}")
    else:
        print("âš ï¸ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ”§ AI ê¸°ëŠ¥ ì—†ì´ ê¸°ë³¸ í¬ë¡¤ë§ë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.")
    
    # í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    crawler = AdvancedChurchCrawler()
    
    # JSON íŒŒì¼ ë¡œë“œ
    input_file = "combined_20250605_131931.json"
    churches_data = crawler.load_json_data(input_file)
    
    if not churches_data:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {input_file}")
    print(f"ğŸ“Š ì²˜ë¦¬í•  êµíšŒ ìˆ˜: {len(churches_data)}")
    
    # ì‚¬ìš©ì í™•ì¸
    print(f"\nâš ï¸ {len(churches_data)}ê°œ êµíšŒì˜ í™ˆí˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.")
    print("ì´ ì‘ì—…ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    try:
        # ëª¨ë“  êµíšŒ ì²˜ë¦¬
        enhanced_results = await crawler.process_all_churches(churches_data)
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        output_file = crawler.save_final_results(enhanced_results)
        
        # í†µê³„ ì¶œë ¥
        crawler.print_final_statistics()
        
        print(f"\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    asyncio.run(main())