#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì™„ì „í•œ AI ì—ì´ì „íŠ¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ í†µí•© ì˜ˆì œ
ê¸°ì¡´ centercrawling.py + ìƒˆë¡œìš´ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì™„ì „ í†µí•©

ì´ ì˜ˆì œëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤:
1. í•˜ì´ë¸Œë¦¬ë“œ í¬ë¡¤ë§ (ì—‘ì…€ + ë°ì´í„°ë² ì´ìŠ¤)
2. AI ê¸°ë°˜ ê²€ìƒ‰ ì „ëµ ë° ê²€ì¦
3. GCP e2-small ìµœì í™”
4. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
5. ë°ì´í„° í’ˆì§ˆ ë“±ê¸‰ ì‹œìŠ¤í…œ
"""

import os
import sys
import json
import time
import logging
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

# í†µí•© ì‹œìŠ¤í…œ import
from aiagent.integration.crawler_integration import IntegratedCrawlingBot
from aiagent.core.enhanced_agent_system import EnhancedAIAgentSystem
from aiagent.config.gcp_optimization import GCPOptimizer, GCPDeploymentHelper
from database.database import ChurchCRMDatabase


def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('complete_integration.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger("CompleteIntegration")


def test_database_connection():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    logger = logging.getLogger("DatabaseTest")
    
    try:
        logger.info("ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        db = ChurchCRMDatabase()
        result = db.execute_query("SELECT COUNT(*) as count FROM organizations", fetch_all=False)
        
        logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ: {result['count']}ê°œ ê¸°ê´€ í™•ì¸")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return False


def test_ai_agent_system():
    """AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger = logging.getLogger("AIAgentTest")
    
    try:
        logger.info("ğŸ¤– AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        agent_system = EnhancedAIAgentSystem()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_organization = {
            'id': 999,
            'name': 'í…ŒìŠ¤íŠ¸êµíšŒ',
            'address': 'ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ',
            'phone': '02-1234-5678'
        }
        
        # ë‹¨ì¼ ê¸°ê´€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        result = agent_system.process_single_organization(test_organization)
        
        if result:
            logger.info(f"âœ… AI ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ: ë“±ê¸‰ {result.data_quality_grade}")
            logger.info(f"   ê²€ì¦ ì ìˆ˜: {result.validation_score:.2f}")
            logger.info(f"   í¬ë¡¤ë§ ì†ŒìŠ¤: {result.crawling_source}")
        else:
            logger.warning("âš ï¸ AI ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—†ìŒ")
        
        # í†µê³„ ì¡°íšŒ
        stats = agent_system.get_crawling_statistics()
        logger.info(f"ğŸ“Š ì‹œìŠ¤í…œ í†µê³„: {stats.get('total_organizations', 0)}ê°œ ê¸°ê´€")
        
        # ì‹œìŠ¤í…œ ì •ë¦¬
        agent_system.stop_crawling()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def test_gcp_optimization():
    """GCP ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger = logging.getLogger("GCPOptimizationTest")
    
    try:
        logger.info("âš¡ GCP ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # GCP ìµœì í™” ê´€ë¦¬ì ì´ˆê¸°í™”
        optimizer = GCPOptimizer()
        optimizer.start_monitoring()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        batch_size = optimizer.get_optimal_batch_size()
        logger.info(f"ğŸ”§ ìµœì  ë°°ì¹˜ í¬ê¸°: {batch_size}")
        
        # WebDriver ì˜µì…˜ í™•ì¸
        webdriver_options = optimizer.get_webdriver_options()
        logger.info(f"ğŸŒ WebDriver ì˜µì…˜: {len(webdriver_options['chrome_options'])}ê°œ")
        
        # Gemini ì„¤ì • í™•ì¸
        gemini_config = optimizer.get_gemini_config()
        logger.info(f"ğŸ¤– Gemini RPM ì œí•œ: {gemini_config['rate_limits']['requests_per_minute']}")
        
        # ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„± (5ì´ˆ ëŒ€ê¸°)
        time.sleep(5)
        report = optimizer.get_performance_report()
        
        logger.info(f"ğŸ“Š í˜„ì¬ ë©”ëª¨ë¦¬: {report['current_status']['memory_percent']:.1f}%")
        logger.info(f"ğŸ“Š í˜„ì¬ CPU: {report['current_status']['cpu_percent']:.1f}%")
        
        # ê²½ê³  í™•ì¸
        alerts = optimizer.get_alerts()
        if alerts:
            logger.warning(f"ğŸš¨ ì‹œìŠ¤í…œ ê²½ê³ : {len(alerts)}ê°œ")
        else:
            logger.info("âœ… ì‹œìŠ¤í…œ ìƒíƒœ ì •ìƒ")
        
        # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
        optimizer.stop_monitoring()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ GCP ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def run_complete_integration_demo():
    """ì™„ì „í•œ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨"""
    logger = logging.getLogger("CompleteDemo")
    
    try:
        logger.info("ğŸš€ ì™„ì „í•œ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨ ì‹œì‘")
        
        # 1. í†µí•© í¬ë¡¤ë§ ë´‡ ì´ˆê¸°í™”
        logger.info("1ï¸âƒ£ í†µí•© í¬ë¡¤ë§ ë´‡ ì´ˆê¸°í™”")
        bot = IntegratedCrawlingBot(
            use_ai=True,
            send_email=False,  # ë°ëª¨ì—ì„œëŠ” ì´ë©”ì¼ ë¹„í™œì„±í™”
            use_database=True,
            integration_mode="hybrid"
        )
        
        # 2. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        logger.info("2ï¸âƒ£ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        status = bot.get_system_status()
        logger.info(f"   í†µí•© ëª¨ë“œ: {status['integration_mode']}")
        logger.info(f"   ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {status['database_connection']}")
        logger.info(f"   AI ì—ì´ì „íŠ¸ ì‚¬ìš© ê°€ëŠ¥: {status['ai_agent_available']}")
        
        # 3. ì†Œê·œëª¨ ë°ì´í„°ë² ì´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
        logger.info("3ï¸âƒ£ ì†Œê·œëª¨ ë°ì´í„°ë² ì´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰")
        results = bot.run_database_crawling(batch_size=3)  # ì‘ì€ ë°°ì¹˜ë¡œ í…ŒìŠ¤íŠ¸
        
        logger.info(f"   ì´ ì²˜ë¦¬: {results.get('total_processed', 0)}ê°œ")
        logger.info(f"   ì„±ê³µ: {results.get('success_count', 0)}ê°œ")
        logger.info(f"   ì‘ì—… ID: {results.get('job_id', 'N/A')}")
        
        # 4. í†µê³„ í™•ì¸
        logger.info("4ï¸âƒ£ í¬ë¡¤ë§ í†µê³„ í™•ì¸")
        if 'crawling_stats' in results:
            stats = results['crawling_stats']
            logger.info(f"   ì „ì²´ ê¸°ê´€: {stats.get('total_organizations', 0)}ê°œ")
            logger.info(f"   AI í¬ë¡¤ë§ ì™„ë£Œ: {stats.get('ai_crawled_count', 0)}ê°œ")
            
            # í’ˆì§ˆ ë“±ê¸‰ ë¶„í¬
            quality_grades = stats.get('quality_grades', {})
            if quality_grades:
                logger.info("   í’ˆì§ˆ ë“±ê¸‰ ë¶„í¬:")
                for grade, count in quality_grades.items():
                    logger.info(f"     {grade}ë“±ê¸‰: {count}ê°œ")
        
        # 5. ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±
        logger.info("5ï¸âƒ£ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±")
        if hasattr(bot, 'ai_agent_system') and bot.ai_agent_system:
            system_stats = bot.ai_agent_system.resource_manager.get_system_stats()
            logger.info(f"   í˜„ì¬ ì›Œì»¤: {system_stats['current_workers']}")
            logger.info(f"   ìµœëŒ€ ì›Œì»¤: {system_stats['max_workers']}")
            logger.info(f"   ë©”ëª¨ë¦¬: {system_stats['memory_percent']:.1f}%")
        
        # 6. ì‹œìŠ¤í…œ ì •ë¦¬
        logger.info("6ï¸âƒ£ ì‹œìŠ¤í…œ ì •ë¦¬")
        bot.cleanup()
        
        logger.info("ğŸ‰ ì™„ì „í•œ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨ ì‹¤íŒ¨: {e}")
        return False


def run_excel_integration_demo():
    """ì—‘ì…€ í†µí•© ë°ëª¨ (íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)"""
    logger = logging.getLogger("ExcelDemo")
    
    try:
        # ì—‘ì…€ íŒŒì¼ ê²½ë¡œ í™•ì¸
        excel_path = project_root / "childcenter.xlsx"
        
        if not excel_path.exists():
            logger.info("ğŸ“Š ì—‘ì…€ íŒŒì¼ì´ ì—†ì–´ ì—‘ì…€ í†µí•© ë°ëª¨ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
            return True
        
        logger.info("ğŸ“Š ì—‘ì…€ í†µí•© ë°ëª¨ ì‹œì‘")
        
        # í†µí•© í¬ë¡¤ë§ ë´‡ ì´ˆê¸°í™”
        bot = IntegratedCrawlingBot(
            use_ai=True,
            send_email=False,
            use_database=True,
            integration_mode="hybrid"
        )
        
        # í•˜ì´ë¸Œë¦¬ë“œ í¬ë¡¤ë§ ì‹¤í–‰ (ì†Œê·œëª¨)
        logger.info("   í•˜ì´ë¸Œë¦¬ë“œ í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘...")
        
        # ì‹¤ì œë¡œëŠ” ì „ì²´ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì§€ë§Œ, ë°ëª¨ì—ì„œëŠ” ì œí•œ
        results = bot.run_hybrid_crawling(str(excel_path))
        
        # ê²°ê³¼ ì¶œë ¥
        if 'excel_crawling' in results:
            excel_stats = results['excel_crawling']
            logger.info(f"   ì—‘ì…€ ì²˜ë¦¬: {excel_stats.get('processed_count', 0)}ê°œ")
            logger.info(f"   ì—‘ì…€ ì„±ê³µ: {excel_stats.get('success_count', 0)}ê°œ")
        
        if 'database_crawling' in results:
            db_stats = results['database_crawling']
            logger.info(f"   DB ì²˜ë¦¬: {db_stats.get('total_processed', 0)}ê°œ")
            logger.info(f"   DB ì„±ê³µ: {db_stats.get('success_count', 0)}ê°œ")
        
        # ì‹œìŠ¤í…œ ì •ë¦¬
        bot.cleanup()
        
        logger.info("âœ… ì—‘ì…€ í†µí•© ë°ëª¨ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì—‘ì…€ í†µí•© ë°ëª¨ ì‹¤íŒ¨: {e}")
        return False


def generate_deployment_files():
    """GCP ë°°í¬ íŒŒì¼ ìƒì„±"""
    logger = logging.getLogger("DeploymentFiles")
    
    try:
        logger.info("ğŸ“¦ GCP ë°°í¬ íŒŒì¼ ìƒì„± ì‹œì‘")
        
        # ë°°í¬ ë””ë ‰í† ë¦¬ ìƒì„±
        deployment_dir = project_root / "deployment"
        deployment_dir.mkdir(exist_ok=True)
        
        # ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        startup_script = GCPDeploymentHelper.create_startup_script()
        with open(deployment_dir / "startup.sh", "w", encoding="utf-8") as f:
            f.write(startup_script)
        logger.info("   âœ… startup.sh ìƒì„± ì™„ë£Œ")
        
        # systemd ì„œë¹„ìŠ¤ íŒŒì¼ ìƒì„±
        service_config = GCPDeploymentHelper.create_systemd_service()
        with open(deployment_dir / "crawling-system.service", "w", encoding="utf-8") as f:
            f.write(service_config)
        logger.info("   âœ… crawling-system.service ìƒì„± ì™„ë£Œ")
        
        # requirements.txt ìƒì„±
        requirements = GCPDeploymentHelper.create_requirements_txt()
        with open(deployment_dir / "requirements.txt", "w", encoding="utf-8") as f:
            f.write(requirements)
        logger.info("   âœ… requirements.txt ìƒì„± ì™„ë£Œ")
        
        # ë°°í¬ ê°€ì´ë“œ ìƒì„±
        deployment_guide = f"""# GCP e2-small ë°°í¬ ê°€ì´ë“œ

## 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
```bash
gcloud compute instances create crawling-system \\
    --zone=asia-northeast3-a \\
    --machine-type=e2-small \\
    --image-family=ubuntu-2004-lts \\
    --image-project=ubuntu-os-cloud \\
    --boot-disk-size=20GB \\
    --boot-disk-type=pd-standard
```

## 2. íŒŒì¼ ì—…ë¡œë“œ
```bash
gcloud compute scp startup.sh crawling-system:~/ --zone=asia-northeast3-a
gcloud compute scp crawling-system.service crawling-system:~/ --zone=asia-northeast3-a
gcloud compute scp requirements.txt crawling-system:~/ --zone=asia-northeast3-a
```

## 3. ì„¤ì • ì‹¤í–‰
```bash
gcloud compute ssh crawling-system --zone=asia-northeast3-a

# ì¸ìŠ¤í„´ìŠ¤ ë‚´ì—ì„œ ì‹¤í–‰
chmod +x startup.sh
sudo ./startup.sh

# ì„œë¹„ìŠ¤ ë“±ë¡
sudo cp crawling-system.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable crawling-system
sudo systemctl start crawling-system
```

## 4. ìƒíƒœ í™•ì¸
```bash
sudo systemctl status crawling-system
sudo journalctl -u crawling-system -f
```

ìƒì„± ì‹œê°„: {datetime.now().isoformat()}
"""
        
        with open(deployment_dir / "DEPLOYMENT_GUIDE.md", "w", encoding="utf-8") as f:
            f.write(deployment_guide)
        logger.info("   âœ… DEPLOYMENT_GUIDE.md ìƒì„± ì™„ë£Œ")
        
        logger.info(f"ğŸ“¦ ë°°í¬ íŒŒì¼ ìƒì„± ì™„ë£Œ: {deployment_dir}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°°í¬ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ì™„ì „í•œ AI ì—ì´ì „íŠ¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging()
    logger.info("ğŸ¯ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶”ì 
    test_results = {}
    
    # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸")
    test_results['database'] = test_database_connection()
    
    # 2. AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    test_results['ai_agent'] = test_ai_agent_system()
    
    # 3. GCP ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ GCP ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    test_results['gcp_optimization'] = test_gcp_optimization()
    
    # 4. ì™„ì „í•œ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨
    print("\n4ï¸âƒ£ ì™„ì „í•œ í†µí•© ì‹œìŠ¤í…œ ë°ëª¨")
    test_results['complete_integration'] = run_complete_integration_demo()
    
    # 5. ì—‘ì…€ í†µí•© ë°ëª¨
    print("\n5ï¸âƒ£ ì—‘ì…€ í†µí•© ë°ëª¨")
    test_results['excel_integration'] = run_excel_integration_demo()
    
    # 6. ë°°í¬ íŒŒì¼ ìƒì„±
    print("\n6ï¸âƒ£ GCP ë°°í¬ íŒŒì¼ ìƒì„±")
    test_results['deployment_files'] = generate_deployment_files()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    total_tests = len(test_results)
    passed_tests = sum(test_results.values())
    
    for test_name, result in test_results.items():
        status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
        print(f"   {test_name}: {status}")
    
    print(f"\nğŸ¯ ì „ì²´ ê²°ê³¼: {passed_tests}/{total_tests} í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    if passed_tests == total_tests:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. deployment/ í´ë”ì˜ íŒŒì¼ë“¤ì„ GCPì— ì—…ë¡œë“œ")
        print("   2. DEPLOYMENT_GUIDE.mdë¥¼ ì°¸ê³ í•˜ì—¬ ë°°í¬ ì‹¤í–‰")
        print("   3. ì‹¤ì œ í¬ë¡¤ë§ ì‘ì—… ì‹œì‘")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    logger.info(f"ğŸ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {passed_tests}/{total_tests} ì„±ê³µ")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc() 