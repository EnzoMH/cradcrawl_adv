#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê³ ë„í™”ëœ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ - CenterCrawlingBot í†µí•©
ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ

ì£¼ìš” ê¸°ëŠ¥:
1. ê²€ìƒ‰ ì „ëµ AI ì—ì´ì „íŠ¸ (Google->Naver->Bing ìˆœ)
2. ë°ì´í„° ê²€ì¦ AI ì—ì´ì „íŠ¸ (ì£¼ì†Œ-ì§€ì—­ë²ˆí˜¸ ë§¤ì¹­, ìœ ì‚¬ì„± ê²€ì‚¬)
3. ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì (GCP e2-small ìµœì í™”)
4. PostgreSQL ì§ì ‘ ì—°ë™ (Pydantic ëª¨ë¸ ê¸°ë°˜)
5. ë°ì´í„° í’ˆì§ˆ ë“±ê¸‰ ì‹œìŠ¤í…œ (A~F)
"""

import os
import re
import time
import json
import logging
import asyncio
import psutil
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from contextlib import contextmanager
import multiprocessing

# AI ê´€ë ¨
import google.generativeai as genai
from dotenv import load_dotenv

# ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨
import psycopg2
import psycopg2.extras
from pydantic import BaseModel, Field, validator
from pydantic.dataclasses import dataclass as pydantic_dataclass

# ì›¹ í¬ë¡¤ë§ ê´€ë ¨
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import undetected_chromedriver as uc
from bs4 import BeautifulSoup
import requests

# ê¸°ì¡´ ì‹œìŠ¤í…œ ëª¨ë“ˆ
from database.database import ChurchCRMDatabase
from database.models import Organization, CrawlingJob


# ==================== ì„¤ì • ë° ìƒìˆ˜ ====================

load_dotenv()

# Gemini API ì„¤ì •
GEMINI_CONFIG = {
    "temperature": 0.1,
    "top_p": 0.8,
    "top_k": 40,
    "max_output_tokens": 2048,
}

# ê²€ìƒ‰ ì—”ì§„ ìš°ì„ ìˆœìœ„
SEARCH_ENGINES = ['google', 'naver', 'bing']

# ë°ì´í„° í’ˆì§ˆ ë“±ê¸‰ ê¸°ì¤€
class DataQualityGrade(Enum):
    A = "A"  # ê¸°ê´€ëª… + ì£¼ì†Œ + ì „í™”ë²ˆí˜¸ + íŒ©ìŠ¤ + í™ˆí˜ì´ì§€ + ì´ë©”ì¼
    B = "B"  # ê¸°ê´€ëª… + ì£¼ì†Œ + ì „í™”ë²ˆí˜¸ + íŒ©ìŠ¤ + í™ˆí˜ì´ì§€
    C = "C"  # ê¸°ê´€ëª… + ì£¼ì†Œ + ì „í™”ë²ˆí˜¸ + íŒ©ìŠ¤
    D = "D"  # ê¸°ê´€ëª… + ì£¼ì†Œ + ì „í™”ë²ˆí˜¸ + í™ˆí˜ì´ì§€
    E = "E"  # ê¸°ê´€ëª… + ì£¼ì†Œ + ì „í™”ë²ˆí˜¸
    F = "F"  # ê¸°ê´€ëª… + ì£¼ì†Œ

# ë¦¬ì†ŒìŠ¤ ì œì•½ ì¡°ê±´
class ResourceConstraints:
    """ë¦¬ì†ŒìŠ¤ ì œì•½ ì¡°ê±´"""
    
    @staticmethod
    def get_optimal_workers() -> int:
        """ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°"""
        try:
            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ í™•ì¸
            memory_gb = psutil.virtual_memory().total / (1024**3)
            cpu_count = psutil.cpu_count()
            
            # GCP e2-small ê°ì§€ (2GB RAM, 0.5 vCPU)
            if memory_gb <= 2.5:
                return 1  # GCP e2-smallì€ ë‹¨ì¼ ì›Œì»¤
            elif memory_gb <= 4:
                return 2  # e2-medium
            elif memory_gb <= 16:
                return min(4, cpu_count)  # ë¡œì»¬ í™˜ê²½
            else:
                return min(8, cpu_count)  # ê³ ì„±ëŠ¥ í™˜ê²½
                
        except:
            return 2  # ê¸°ë³¸ê°’


# ==================== Pydantic ëª¨ë¸ ====================

class CrawlingResult(BaseModel):
    """í¬ë¡¤ë§ ê²°ê³¼ ëª¨ë¸"""
    organization_id: Optional[int] = None
    name: str
    address: str
    phone: str = ""
    fax: str = ""
    homepage: str = ""
    email: str = ""
    mobile: str = ""
    
    # ë©”íƒ€ë°ì´í„°
    data_quality_grade: str = "F"
    crawling_source: str = ""
    validation_score: float = 0.0
    ai_confidence: float = 0.0
    crawled_at: datetime = Field(default_factory=datetime.now)
    
    # ê²€ì¦ í”Œë˜ê·¸
    phone_validated: bool = False
    fax_validated: bool = False
    address_validated: bool = False
    homepage_validated: bool = False
    email_validated: bool = False

    @validator('phone', 'fax', 'mobile')
    def validate_phone_format(cls, v):
        if not v:
            return v
        # í•œêµ­ ì „í™”ë²ˆí˜¸ í˜•ì‹ ê²€ì¦
        phone_pattern = r'^(\d{2,3})-(\d{3,4})-(\d{4})$'
        if not re.match(phone_pattern, v):
            raise ValueError('ì „í™”ë²ˆí˜¸ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤')
        return v
    
    @validator('email')
    def validate_email_format(cls, v):
        if not v:
            return v
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if not re.match(email_pattern, v):
            raise ValueError('ì´ë©”ì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤')
        return v
    
    def calculate_quality_grade(self) -> str:
        """ë°ì´í„° í’ˆì§ˆ ë“±ê¸‰ ê³„ì‚°"""
        fields = [
            bool(self.name and self.address),  # í•„ìˆ˜
            bool(self.phone),
            bool(self.fax),
            bool(self.homepage),
            bool(self.email),
            bool(self.mobile)
        ]
        
        if all(fields):
            return DataQualityGrade.A.value
        elif fields[0] and fields[1] and fields[2] and fields[3]:
            return DataQualityGrade.B.value
        elif fields[0] and fields[1] and fields[2]:
            return DataQualityGrade.C.value
        elif fields[0] and fields[1] and fields[3]:
            return DataQualityGrade.D.value
        elif fields[0] and fields[1]:
            return DataQualityGrade.E.value
        else:
            return DataQualityGrade.F.value


# ==================== AI ì—ì´ì „íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤ ====================

class BaseAgent:
    """AI ì—ì´ì „íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, gemini_model=None):
        self.name = name
        self.logger = logging.getLogger(f"Agent.{name}")
        self.gemini_model = gemini_model
        self.metrics = {
            'requests_made': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'total_processing_time': 0.0
        }
    
    def _call_gemini(self, prompt: str, max_retries: int = 3) -> str:
        """Gemini API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        for attempt in range(max_retries):
            try:
                self.metrics['requests_made'] += 1
                start_time = time.time()
                
                response = self.gemini_model.generate_content(prompt)
                result = response.text
                
                processing_time = time.time() - start_time
                self.metrics['total_processing_time'] += processing_time
                self.metrics['successful_requests'] += 1
                
                return result
                
            except Exception as e:
                self.metrics['failed_requests'] += 1
                if attempt == max_retries - 1:
                    self.logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (ìµœì¢…): {e}")
                    return f"ì˜¤ë¥˜: {str(e)}"
                else:
                    self.logger.warning(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (ì¬ì‹œë„ {attempt + 1}): {e}")
                    time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
        
        return "ì˜¤ë¥˜: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼"


# ==================== ê²€ìƒ‰ ì „ëµ AI ì—ì´ì „íŠ¸ ====================

class SearchStrategyAgent(BaseAgent):
    """ê²€ìƒ‰ ì „ëµ AI ì—ì´ì „íŠ¸"""
    
    def __init__(self, gemini_model=None):
        super().__init__("SearchStrategy", gemini_model)
        self.search_patterns = {
            'phone': [
                r'ì „í™”[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
                r'TEL[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
                r'T[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            ],
            'fax': [
                r'íŒ©ìŠ¤[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
                r'fax[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
                r'F[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
                r'ì „ì†¡[\s:ï¼š]*(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})',
            ],
            'email': [
                r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',
            ],
            'homepage': [
                r'https?://[^\s<>"\']+',
                r'www\.[^\s<>"\']+',
                r'[a-zA-Z0-9.-]+\.(com|co\.kr|or\.kr|go\.kr|net|org)[^\s<>"\']*'
            ]
        }
    
    def generate_search_queries(self, name: str, address: str, phone: str = "") -> List[Dict[str, str]]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì „ëµ"""
        queries = []
        
        # ì§€ì—­ ì¶”ì¶œ
        region = self._extract_region_from_address(address)
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ë”°ë¥¸ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        if name and address:
            # (1) ê¸°ê´€ëª… + ì „í™”ë²ˆí˜¸
            if phone:
                queries.append({
                    'query': f"{name} ì „í™”ë²ˆí˜¸",
                    'type': 'phone',
                    'priority': 1,
                    'validation_context': {'address': address, 'phone': phone}
                })
            
            # (2) ê¸°ê´€ëª… + íŒ©ìŠ¤ë²ˆí˜¸
            queries.append({
                'query': f"{name} íŒ©ìŠ¤ë²ˆí˜¸",
                'type': 'fax',
                'priority': 2,
                'validation_context': {'address': address, 'phone': phone}
            })
            
            # (3) ì§€ì—­ + ê¸°ê´€ëª… + ì „í™”ë²ˆí˜¸ (ê²€ì¦ ì‹¤íŒ¨ ì‹œ)
            if region:
                queries.append({
                    'query': f"{region} {name} ì „í™”ë²ˆí˜¸",
                    'type': 'phone',
                    'priority': 3,
                    'validation_context': {'address': address, 'region': region}
                })
            
            # (4) ê¸°ê´€ëª… + í™ˆí˜ì´ì§€
            queries.append({
                'query': f"{name} í™ˆí˜ì´ì§€",
                'type': 'homepage',
                'priority': 4,
                'validation_context': {'address': address}
            })
            
            # (5) ê¸°ê´€ëª… + ì´ë©”ì¼
            queries.append({
                'query': f"{name} ì´ë©”ì¼",
                'type': 'email',
                'priority': 5,
                'validation_context': {'address': address}
            })
        
        return sorted(queries, key=lambda x: x['priority'])
    
    def _extract_region_from_address(self, address: str) -> str:
        """ì£¼ì†Œì—ì„œ ì§€ì—­ ì¶”ì¶œ"""
        regions = [
            'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…',
            'ê²½ê¸°', 'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼'
        ]
        
        for region in regions:
            if region in address:
                return region
        
        return ""
    
    def analyze_search_results_with_ai(self, query: str, search_results: str, context: Dict) -> Dict[str, Any]:
        """AIë¥¼ í†µí•œ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„"""
        prompt = f"""
ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ '{query}'ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ê²€ìƒ‰ ì¿¼ë¦¬**: {query}
**ê²€ìƒ‰ ê²°ê³¼**:
{search_results[:3000]}

**ê²€ì¦ ì»¨í…ìŠ¤íŠ¸**:
{json.dumps(context, ensure_ascii=False, indent=2)}

**ìš”ì²­ì‚¬í•­**:
1. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
2. ì»¨í…ìŠ¤íŠ¸ì™€ì˜ ì¼ì¹˜ì„± ê²€ì¦
3. ì‹ ë¢°ë„ ì ìˆ˜ (0-1) ì œê³µ

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
    "extracted_info": "ì¶”ì¶œëœ ì •ë³´",
    "confidence_score": 0.0,
    "validation_passed": false,
    "validation_reason": "ê²€ì¦ ê²°ê³¼ ì„¤ëª…"
}}
"""
        
        try:
            response = self._call_gemini(prompt)
            # JSON íŒŒì‹± ì‹œë„
            import json
            result = json.loads(response)
            return result
        except:
            return {
                "extracted_info": "",
                "confidence_score": 0.0,
                "validation_passed": False,
                "validation_reason": "AI ë¶„ì„ ì‹¤íŒ¨"
            }


# ==================== ë°ì´í„° ê²€ì¦ AI ì—ì´ì „íŠ¸ ====================

class ValidationAgent(BaseAgent):
    """ë°ì´í„° ê²€ì¦ AI ì—ì´ì „íŠ¸"""
    
    def __init__(self, gemini_model=None):
        super().__init__("Validation", gemini_model)
        self.region_area_codes = {
            'ì„œìš¸': ['02'],
            'ë¶€ì‚°': ['051'],
            'ëŒ€êµ¬': ['053'],
            'ì¸ì²œ': ['032'],
            'ê´‘ì£¼': ['062'],
            'ëŒ€ì „': ['042'],
            'ìš¸ì‚°': ['052'],
            'ì„¸ì¢…': ['044'],
            'ê²½ê¸°': ['031'],
            'ê°•ì›': ['033'],
            'ì¶©ë¶': ['043'],
            'ì¶©ë‚¨': ['041'],
            'ì „ë¶': ['063'],
            'ì „ë‚¨': ['061'],
            'ê²½ë¶': ['054'],
            'ê²½ë‚¨': ['055'],
            'ì œì£¼': ['064']
        }
    
    def validate_phone_with_address(self, phone: str, address: str) -> Dict[str, Any]:
        """ì „í™”ë²ˆí˜¸ì™€ ì£¼ì†Œ ì¼ì¹˜ì„± ê²€ì¦"""
        try:
            # ì§€ì—­ ì¶”ì¶œ
            region = self._extract_region_from_address(address)
            if not region:
                return {
                    'valid': False,
                    'reason': 'ì£¼ì†Œì—ì„œ ì§€ì—­ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ',
                    'confidence': 0.0
                }
            
            # ì§€ì—­ë²ˆí˜¸ ì¶”ì¶œ
            area_code = phone.split('-')[0] if '-' in phone else phone[:3]
            
            # ì§€ì—­ë²ˆí˜¸ ë§¤ì¹­
            expected_codes = self.region_area_codes.get(region, [])
            if area_code in expected_codes:
                return {
                    'valid': True,
                    'reason': f'{region} ì§€ì—­ì˜ ì˜¬ë°”ë¥¸ ì§€ì—­ë²ˆí˜¸ ({area_code})',
                    'confidence': 0.9
                }
            else:
                return {
                    'valid': False,
                    'reason': f'{region} ì§€ì—­ì˜ ì§€ì—­ë²ˆí˜¸ ë¶ˆì¼ì¹˜ (ì˜ˆìƒ: {expected_codes}, ì‹¤ì œ: {area_code})',
                    'confidence': 0.1
                }
                
        except Exception as e:
            return {
                'valid': False,
                'reason': f'ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}',
                'confidence': 0.0
            }
    
    def check_phone_similarity(self, phone1: str, phone2: str) -> Dict[str, Any]:
        """ì „í™”ë²ˆí˜¸ ìœ ì‚¬ì„± ê²€ì‚¬"""
        try:
            if not phone1 or not phone2:
                return {'similar': False, 'similarity_score': 0.0}
            
            # ìˆ«ìë§Œ ì¶”ì¶œ
            digits1 = re.sub(r'[^\d]', '', phone1)
            digits2 = re.sub(r'[^\d]', '', phone2)
            
            if len(digits1) != len(digits2):
                return {'similar': False, 'similarity_score': 0.0}
            
            # ìë¦¬ìˆ˜ë³„ ì¼ì¹˜ í™•ì¸
            matches = sum(1 for d1, d2 in zip(digits1, digits2) if d1 == d2)
            similarity_score = matches / len(digits1)
            
            # 80% ì´ìƒ ìœ ì‚¬í•˜ë©´ ìœ ì‚¬í•œ ê²ƒìœ¼ë¡œ íŒë‹¨
            is_similar = similarity_score >= 0.8
            
            return {
                'similar': is_similar,
                'similarity_score': similarity_score,
                'different_digits': len(digits1) - matches
            }
            
        except Exception as e:
            return {'similar': False, 'similarity_score': 0.0}
    
    def validate_with_ai(self, result: CrawlingResult) -> Dict[str, Any]:
        """AIë¥¼ í†µí•œ ì¢…í•© ê²€ì¦"""
        prompt = f"""
ë‹¤ìŒ í¬ë¡¤ë§ ê²°ê³¼ì˜ ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•´ì£¼ì„¸ìš”.

**ê¸°ê´€ ì •ë³´**:
- ê¸°ê´€ëª…: {result.name}
- ì£¼ì†Œ: {result.address}
- ì „í™”ë²ˆí˜¸: {result.phone}
- íŒ©ìŠ¤ë²ˆí˜¸: {result.fax}
- í™ˆí˜ì´ì§€: {result.homepage}
- ì´ë©”ì¼: {result.email}

**ê²€ì¦ í•­ëª©**:
1. ì „í™”ë²ˆí˜¸ì™€ ì£¼ì†Œì˜ ì§€ì—­ ì¼ì¹˜ì„±
2. íŒ©ìŠ¤ë²ˆí˜¸ì™€ ì „í™”ë²ˆí˜¸ì˜ ìœ ì‚¬ì„± (1-4ìë¦¬ ì°¨ì´ í—ˆìš©)
3. ì´ë©”ì¼ í˜•ì‹ ìœ íš¨ì„±
4. í™ˆí˜ì´ì§€ URL ìœ íš¨ì„±
5. ì „ì²´ì ì¸ ë°ì´í„° ì¼ê´€ì„±

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
    "overall_valid": true,
    "validation_score": 0.85,
    "issues": [],
    "recommendations": []
}}
"""
        
        try:
            response = self._call_gemini(prompt)
            import json
            return json.loads(response)
        except:
            return {
                "overall_valid": False,
                "validation_score": 0.0,
                "issues": ["AI ê²€ì¦ ì‹¤íŒ¨"],
                "recommendations": []
            }
    
    def _extract_region_from_address(self, address: str) -> str:
        """ì£¼ì†Œì—ì„œ ì§€ì—­ ì¶”ì¶œ"""
        for region in self.region_area_codes.keys():
            if region in address:
                return region
        return ""


# ==================== ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì ====================

class ResourceManager:
    """ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì - GCP e2-small ìµœì í™”"""
    
    def __init__(self):
        self.logger = logging.getLogger("ResourceManager")
        self.max_workers = ResourceConstraints.get_optimal_workers()
        self.current_workers = 0
        self.memory_threshold = 0.8  # 80% ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì œí•œ
        self.cpu_threshold = 0.7     # 70% CPU ì‚¬ìš©ë¥  ì œí•œ
        self.monitoring_active = False
        self.monitoring_thread = None
        
        # Gemini API ì œí•œ ê´€ë¦¬
        self.gemini_rpm_limit = 2000  # Gemini 1.5 Flash RPM
        self.gemini_requests_per_minute = 0
        self.gemini_minute_start = time.time()
        
        self.logger.info(f"ğŸ”§ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì ì´ˆê¸°í™”: ìµœëŒ€ ì›Œì»¤ {self.max_workers}ê°œ")
    
    def can_create_worker(self) -> bool:
        """ì›Œì»¤ ìƒì„± ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if self.current_workers >= self.max_workers:
            return False
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
        memory_percent = psutil.virtual_memory().percent / 100
        if memory_percent > self.memory_threshold:
            self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {memory_percent:.1%}")
            return False
        
        # CPU ì‚¬ìš©ë¥  í™•ì¸
        cpu_percent = psutil.cpu_percent(interval=1) / 100
        if cpu_percent > self.cpu_threshold:
            self.logger.warning(f"âš ï¸ CPU ì‚¬ìš©ë¥  ë†’ìŒ: {cpu_percent:.1%}")
            return False
        
        return True
    
    def can_call_gemini(self) -> bool:
        """Gemini API í˜¸ì¶œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        current_time = time.time()
        
        # 1ë¶„ ê²½ê³¼ ì‹œ ì¹´ìš´í„° ë¦¬ì…‹
        if current_time - self.gemini_minute_start > 60:
            self.gemini_requests_per_minute = 0
            self.gemini_minute_start = current_time
        
        # RPM ì œí•œ í™•ì¸
        if self.gemini_requests_per_minute >= self.gemini_rpm_limit:
            self.logger.warning(f"âš ï¸ Gemini API RPM ì œí•œ ë„ë‹¬: {self.gemini_requests_per_minute}")
            return False
        
        return True
    
    def record_gemini_request(self):
        """Gemini API ìš”ì²­ ê¸°ë¡"""
        self.gemini_requests_per_minute += 1
    
    def get_system_stats(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        return {
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_percent': psutil.disk_usage('/').percent,
            'current_workers': self.current_workers,
            'max_workers': self.max_workers,
            'gemini_requests_per_minute': self.gemini_requests_per_minute
        }
    
    def start_monitoring(self):
        """ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if not self.monitoring_active:
            self.monitoring_active = True
            self.monitoring_thread = threading.Thread(target=self._monitor_system, daemon=True)
            self.monitoring_thread.start()
            self.logger.info("ğŸ“Š ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def _monitor_system(self):
        """ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ (ë°±ê·¸ë¼ìš´ë“œ)"""
        while self.monitoring_active:
            try:
                stats = self.get_system_stats()
                
                # ê²½ê³  ë ˆë²¨ ì²´í¬
                if stats['memory_percent'] > 85:
                    self.logger.warning(f"ğŸš¨ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {stats['memory_percent']:.1f}%")
                
                if stats['cpu_percent'] > 80:
                    self.logger.warning(f"ğŸš¨ CPU ì‚¬ìš©ë¥  ë†’ìŒ: {stats['cpu_percent']:.1f}%")
                
                # 30ì´ˆë§ˆë‹¤ ì²´í¬
                time.sleep(30)
                
            except Exception as e:
                self.logger.error(f"âŒ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                break
    
    def stop_monitoring(self):
        """ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=1)


# ==================== ë©”ì¸ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ====================

class EnhancedAIAgentSystem:
    """ê³ ë„í™”ëœ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self, db_url: str = None):
        self.logger = logging.getLogger("EnhancedAIAgentSystem")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.db = ChurchCRMDatabase(db_url)
        
        # Gemini AI ëª¨ë¸ ì´ˆê¸°í™”
        self.gemini_model = self._initialize_gemini()
        
        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.search_agent = SearchStrategyAgent(self.gemini_model)
        self.validation_agent = ValidationAgent(self.gemini_model)
        
        # ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì
        self.resource_manager = ResourceManager()
        self.resource_manager.start_monitoring()
        
        # í¬ë¡¤ë§ ìƒíƒœ
        self.current_job_id = None
        self.is_running = False
        
        self.logger.info("ğŸš€ ê³ ë„í™”ëœ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_gemini(self):
        """Gemini AI ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                raise ValueError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(
                "gemini-1.5-flash",
                generation_config=GEMINI_CONFIG
            )
            
            self.logger.info("ğŸ¤– Gemini AI ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
            return model
            
        except Exception as e:
            self.logger.error(f"âŒ Gemini AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def start_crawling_job(self, job_name: str, started_by: str) -> int:
        """í¬ë¡¤ë§ ì‘ì—… ì‹œì‘"""
        try:
            # í¬ë¡¤ë§ ì‘ì—… ìƒì„±
            job_data = {
                'job_name': job_name,
                'status': 'RUNNING',
                'started_by': started_by,
                'started_at': datetime.now(),
                'config_data': {
                    'search_engines': SEARCH_ENGINES,
                    'max_workers': self.resource_manager.max_workers,
                    'gemini_model': 'gemini-1.5-flash'
                }
            }
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì‘ì—… ì €ì¥
            query = """
                INSERT INTO crawling_jobs (job_name, status, started_by, started_at, config_data)
                VALUES (%(job_name)s, %(status)s, %(started_by)s, %(started_at)s, %(config_data)s)
                RETURNING id
            """
            
            result = self.db.execute_insert(query, job_data)
            self.current_job_id = result['id']
            self.is_running = True
            
            self.logger.info(f"ğŸ“‹ í¬ë¡¤ë§ ì‘ì—… ì‹œì‘: {job_name} (ID: {self.current_job_id})")
            return self.current_job_id
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ë¡¤ë§ ì‘ì—… ì‹œì‘ ì‹¤íŒ¨: {e}")
            raise
    
    def process_organization_batch(self, organizations: List[Dict]) -> List[CrawlingResult]:
        """ê¸°ê´€ ë°°ì¹˜ ì²˜ë¦¬"""
        results = []
        
        for org_data in organizations:
            try:
                result = self.process_single_organization(org_data)
                if result:
                    results.append(result)
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    self.save_crawling_result(result)
                    
            except Exception as e:
                self.logger.error(f"âŒ ê¸°ê´€ ì²˜ë¦¬ ì‹¤íŒ¨: {org_data.get('name', 'Unknown')} - {e}")
                continue
        
        return results
    
    def process_single_organization(self, org_data: Dict) -> Optional[CrawlingResult]:
        """ë‹¨ì¼ ê¸°ê´€ ì²˜ë¦¬"""
        try:
            name = org_data.get('name', '')
            address = org_data.get('address', '')
            existing_phone = org_data.get('phone', '')
            
            if not name or not address:
                self.logger.warning(f"âš ï¸ í•„ìˆ˜ ì •ë³´ ëˆ„ë½: {name}")
                return None
            
            self.logger.info(f"ğŸ” ê¸°ê´€ ì²˜ë¦¬ ì‹œì‘: {name}")
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_queries = self.search_agent.generate_search_queries(
                name, address, existing_phone
            )
            
            # í¬ë¡¤ë§ ê²°ê³¼ ì´ˆê¸°í™”
            result = CrawlingResult(
                organization_id=org_data.get('id'),
                name=name,
                address=address,
                phone=existing_phone
            )
            
            # ê° ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰
            for query_info in search_queries:
                if not self.resource_manager.can_call_gemini():
                    self.logger.warning("âš ï¸ Gemini API ì œí•œìœ¼ë¡œ ì¸í•œ ëŒ€ê¸°")
                    time.sleep(60)  # 1ë¶„ ëŒ€ê¸°
                
                # ê²€ìƒ‰ ì‹¤í–‰
                search_result = self._execute_search(query_info)
                
                if search_result and search_result.get('extracted_info'):
                    # ê²°ê³¼ ê²€ì¦
                    validation_result = self._validate_search_result(
                        search_result, query_info, result
                    )
                    
                    if validation_result['valid']:
                        self._update_result_with_search_data(
                            result, query_info['type'], search_result['extracted_info']
                        )
            
            # ìµœì¢… ê²€ì¦ ë° í’ˆì§ˆ ë“±ê¸‰ ê³„ì‚°
            final_validation = self.validation_agent.validate_with_ai(result)
            result.validation_score = final_validation.get('validation_score', 0.0)
            result.data_quality_grade = result.calculate_quality_grade()
            
            self.logger.info(f"âœ… ê¸°ê´€ ì²˜ë¦¬ ì™„ë£Œ: {name} (ë“±ê¸‰: {result.data_quality_grade})")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ê´€ ì²˜ë¦¬ ì˜¤ë¥˜: {org_data.get('name', 'Unknown')} - {e}")
            return None
    
    def _execute_search(self, query_info: Dict) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì‹¤í–‰"""
        # ì‹¤ì œ ê²€ìƒ‰ ë¡œì§ì€ ê¸°ì¡´ centercrawling.pyì˜ ê²€ìƒ‰ ë©”ì„œë“œë¥¼ í™œìš©
        # ì—¬ê¸°ì„œëŠ” AI ë¶„ì„ ë¶€ë¶„ë§Œ êµ¬í˜„
        
        # ê²€ìƒ‰ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” Selenium í¬ë¡¤ë§ ê²°ê³¼)
        search_results = "ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸..."
        
        # AI ë¶„ì„
        analysis_result = self.search_agent.analyze_search_results_with_ai(
            query_info['query'], search_results, query_info['validation_context']
        )
        
        return analysis_result
    
    def _validate_search_result(self, search_result: Dict, query_info: Dict, current_result: CrawlingResult) -> Dict[str, Any]:
        """ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦"""
        extracted_info = search_result.get('extracted_info', '')
        query_type = query_info['type']
        
        if query_type == 'phone':
            return self.validation_agent.validate_phone_with_address(
                extracted_info, current_result.address
            )
        elif query_type == 'fax':
            similarity_check = self.validation_agent.check_phone_similarity(
                extracted_info, current_result.phone
            )
            return {
                'valid': similarity_check['different_digits'] <= 4,
                'reason': f"ì „í™”ë²ˆí˜¸ì™€ {similarity_check['different_digits']}ìë¦¬ ì°¨ì´",
                'confidence': 1.0 - (similarity_check['different_digits'] / 10)
            }
        else:
            return {'valid': True, 'reason': 'ê¸°ë³¸ ê²€ì¦ í†µê³¼', 'confidence': 0.7}
    
    def _update_result_with_search_data(self, result: CrawlingResult, data_type: str, data: str):
        """ê²€ìƒ‰ ê²°ê³¼ë¡œ CrawlingResult ì—…ë°ì´íŠ¸"""
        if data_type == 'phone':
            result.phone = data
            result.phone_validated = True
        elif data_type == 'fax':
            result.fax = data
            result.fax_validated = True
        elif data_type == 'homepage':
            result.homepage = data
            result.homepage_validated = True
        elif data_type == 'email':
            result.email = data
            result.email_validated = True
    
    def save_crawling_result(self, result: CrawlingResult):
        """í¬ë¡¤ë§ ê²°ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        try:
            # Organization í…Œì´ë¸” ì—…ë°ì´íŠ¸
            query = """
                UPDATE organizations 
                SET phone = %(phone)s, fax = %(fax)s, homepage = %(homepage)s, 
                    email = %(email)s, mobile = %(mobile)s, 
                    ai_crawled = true, last_crawled_at = %(crawled_at)s,
                    crawling_data = %(crawling_data)s
                WHERE id = %(organization_id)s
            """
            
            crawling_data = {
                'data_quality_grade': result.data_quality_grade,
                'validation_score': result.validation_score,
                'ai_confidence': result.ai_confidence,
                'crawling_source': result.crawling_source,
                'validation_flags': {
                    'phone_validated': result.phone_validated,
                    'fax_validated': result.fax_validated,
                    'homepage_validated': result.homepage_validated,
                    'email_validated': result.email_validated
                }
            }
            
            params = {
                'phone': result.phone,
                'fax': result.fax,
                'homepage': result.homepage,
                'email': result.email,
                'mobile': result.mobile,
                'crawled_at': result.crawled_at,
                'crawling_data': json.dumps(crawling_data),
                'organization_id': result.organization_id
            }
            
            self.db.execute_update(query, params)
            self.logger.info(f"ğŸ’¾ í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result.name}")
            
        except Exception as e:
            self.logger.error(f"âŒ í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {result.name} - {e}")
    
    def get_crawling_statistics(self) -> Dict[str, Any]:
        """í¬ë¡¤ë§ í†µê³„ ì¡°íšŒ"""
        try:
            query = """
                SELECT 
                    COUNT(*) as total_organizations,
                    COUNT(CASE WHEN ai_crawled = true THEN 1 END) as ai_crawled_count,
                    COUNT(CASE WHEN phone IS NOT NULL AND phone != '' THEN 1 END) as phone_count,
                    COUNT(CASE WHEN fax IS NOT NULL AND fax != '' THEN 1 END) as fax_count,
                    COUNT(CASE WHEN homepage IS NOT NULL AND homepage != '' THEN 1 END) as homepage_count,
                    COUNT(CASE WHEN email IS NOT NULL AND email != '' THEN 1 END) as email_count
                FROM organizations
            """
            
            result = self.db.execute_query(query, fetch_all=False)
            
            # í’ˆì§ˆ ë“±ê¸‰ë³„ í†µê³„
            quality_query = """
                SELECT 
                    crawling_data->>'data_quality_grade' as grade,
                    COUNT(*) as count
                FROM organizations 
                WHERE ai_crawled = true AND crawling_data IS NOT NULL
                GROUP BY crawling_data->>'data_quality_grade'
            """
            
            quality_stats = self.db.execute_query(quality_query)
            
            return {
                'total_organizations': result['total_organizations'],
                'ai_crawled_count': result['ai_crawled_count'],
                'contact_info': {
                    'phone': result['phone_count'],
                    'fax': result['fax_count'],
                    'homepage': result['homepage_count'],
                    'email': result['email_count']
                },
                'quality_grades': {stat['grade']: stat['count'] for stat in quality_stats if stat['grade']},
                'system_stats': self.resource_manager.get_system_stats()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def stop_crawling(self):
        """í¬ë¡¤ë§ ì¤‘ì§€"""
        self.is_running = False
        self.resource_manager.stop_monitoring()
        
        if self.current_job_id:
            try:
                query = """
                    UPDATE crawling_jobs 
                    SET status = 'STOPPED', completed_at = %s 
                    WHERE id = %s
                """
                self.db.execute_update(query, (datetime.now(), self.current_job_id))
                self.logger.info(f"â¹ï¸ í¬ë¡¤ë§ ì‘ì—… ì¤‘ì§€: {self.current_job_id}")
            except Exception as e:
                self.logger.error(f"âŒ í¬ë¡¤ë§ ì‘ì—… ì¤‘ì§€ ì‹¤íŒ¨: {e}")
    
    def __del__(self):
        """ì†Œë©¸ì"""
        try:
            self.stop_crawling()
        except:
            pass


# ==================== ì‚¬ìš© ì˜ˆì œ ====================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        agent_system = EnhancedAIAgentSystem()
        
        # í¬ë¡¤ë§ ì‘ì—… ì‹œì‘
        job_id = agent_system.start_crawling_job("AI ì—ì´ì „íŠ¸ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸", "admin")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_organizations = [
            {
                'id': 1,
                'name': 'ì„œìš¸ì¤‘ì•™êµíšŒ',
                'address': 'ì„œìš¸ì‹œ ì¤‘êµ¬ ëª…ë™',
                'phone': '02-1234-5678'
            },
            {
                'id': 2,
                'name': 'ë¶€ì‚°í•´ìš´ëŒ€êµíšŒ',
                'address': 'ë¶€ì‚°ì‹œ í•´ìš´ëŒ€êµ¬',
                'phone': ''
            }
        ]
        
        # ë°°ì¹˜ ì²˜ë¦¬
        results = agent_system.process_organization_batch(test_organizations)
        
        # í†µê³„ ì¶œë ¥
        stats = agent_system.get_crawling_statistics()
        print(f"ğŸ“Š í¬ë¡¤ë§ í†µê³„: {json.dumps(stats, ensure_ascii=False, indent=2)}")
        
        # ì‹œìŠ¤í…œ ì •ë¦¬
        agent_system.stop_crawling()
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 