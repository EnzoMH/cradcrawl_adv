#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í¬ë¡¤ë§ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í†µí•©
ê¸°ì¡´ 3ê°œ í¬ë¡¤ëŸ¬ì˜ ì¤‘ë³µëœ ì…€ë ˆë‹ˆì›€ ì„¤ì • ë° ê²€ìƒ‰ ê¸°ëŠ¥ì„ í†µí•©
"""

import time
import random
from typing import Optional, List, Dict
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class CrawlerUtils:
    """í¬ë¡¤ë§ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ - ì¤‘ë³µ ì œê±°"""
    
    @staticmethod
    def setup_driver(headless: bool = True, timeout: int = 10) -> Optional[webdriver.Chrome]:
        """
        Chrome ë“œë¼ì´ë²„ ì„¤ì • (í†µí•©)
        fax_crawler.py + naver_map_crawler.py + url_extractor.py í†µí•©
        """
        try:
            chrome_options = Options()
            
            if headless:
                chrome_options.add_argument("--headless")
            
            # ê³µí†µ ì˜µì…˜ë“¤
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
            
            # ì„±ëŠ¥ ìµœì í™”
            chrome_options.add_argument("--disable-images")
            chrome_options.add_argument("--disable-javascript")
            chrome_options.add_argument("--disable-plugins")
            chrome_options.add_argument("--disable-extensions")
            
            # ë¡œê·¸ ë ˆë²¨ ì„¤ì •
            chrome_options.add_argument("--log-level=3")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-logging"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            driver = webdriver.Chrome(options=chrome_options)
            driver.set_page_load_timeout(timeout)
            driver.implicitly_wait(timeout)
            
            print(f"âœ… Chrome ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ (headless={headless})")
            return driver
            
        except Exception as e:
            print(f"âŒ ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            return None
    
    @staticmethod
    def search_google(driver: webdriver.Chrome, query: str) -> bool:
        """
        êµ¬ê¸€ ê²€ìƒ‰ (í†µí•©)
        fax_crawler.pyì˜ search_google() ê¸°ë°˜
        """
        try:
            search_url = f"https://www.google.com/search?q={query}"
            driver.get(search_url)
            
            # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            print(f"âœ… êµ¬ê¸€ ê²€ìƒ‰ ì™„ë£Œ: {query}")
            return True
            
        except TimeoutException:
            print(f"â° êµ¬ê¸€ ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
            return False
        except Exception as e:
            print(f"âŒ êµ¬ê¸€ ê²€ìƒ‰ ì‹¤íŒ¨: {query}, ì˜¤ë¥˜: {e}")
            return False
    
    @staticmethod
    def search_naver(driver: webdriver.Chrome, query: str) -> bool:
        """
        ë„¤ì´ë²„ ê²€ìƒ‰ (í†µí•©)
        url_extractor.pyì˜ search_naver() ê¸°ë°˜
        """
        try:
            search_url = f"https://search.naver.com/search.naver?query={query}"
            driver.get(search_url)
            
            # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "lst_total"))
            )
            
            print(f"âœ… ë„¤ì´ë²„ ê²€ìƒ‰ ì™„ë£Œ: {query}")
            return True
            
        except TimeoutException:
            print(f"â° ë„¤ì´ë²„ ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
            return False
        except Exception as e:
            print(f"âŒ ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {query}, ì˜¤ë¥˜: {e}")
            return False
    
    @staticmethod
    def restart_driver(driver: Optional[webdriver.Chrome], headless: bool = True) -> Optional[webdriver.Chrome]:
        """
        ë“œë¼ì´ë²„ ì¬ì‹œì‘ (í†µí•©)
        fax_crawler.pyì˜ restart_driver() ê¸°ë°˜
        """
        try:
            if driver:
                driver.quit()
                print("ğŸ”„ ê¸°ì¡´ ë“œë¼ì´ë²„ ì¢…ë£Œ")
            
            time.sleep(2)  # ì•ˆì „í•œ ì¬ì‹œì‘ì„ ìœ„í•œ ëŒ€ê¸°
            new_driver = CrawlerUtils.setup_driver(headless=headless)
            
            if new_driver:
                print("âœ… ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì™„ë£Œ")
            else:
                print("âŒ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì‹¤íŒ¨")
            
            return new_driver
            
        except Exception as e:
            print(f"âŒ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    @staticmethod
    def safe_close_driver(driver: Optional[webdriver.Chrome]):
        """
        ì•ˆì „í•œ ë“œë¼ì´ë²„ ì¢…ë£Œ (í†µí•©)
        3ê°œ í¬ë¡¤ëŸ¬ì˜ close() ë©”ì„œë“œ í†µí•©
        """
        try:
            if driver:
                driver.quit()
                print("âœ… ë“œë¼ì´ë²„ ì•ˆì „ ì¢…ë£Œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ë“œë¼ì´ë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
    
    @staticmethod
    def random_delay(min_seconds: float = 1.0, max_seconds: float = 3.0):
        """ëœë¤ ì§€ì—° (ë´‡ íƒì§€ ë°©ì§€)"""
        delay = random.uniform(min_seconds, max_seconds)
        time.sleep(delay)
    
    @staticmethod
    def setup_requests_session() -> requests.Session:
        """
        Requests ì„¸ì…˜ ì„¤ì • (í†µí•©)
        enhanced_detail_extractor.pyì˜ ì„¸ì…˜ ì„¤ì • ê¸°ë°˜
        """
        session = requests.Session()
        
        # ì¬ì‹œë„ ì „ëµ ì„¤ì •
        retry_strategy = Retry(
            total=3,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"],  # method_whitelist â†’ allowed_methods ë³€ê²½
            backoff_factor=1
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # User-Agent ì„¤ì •
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        
        return session
    
    @staticmethod
    def extract_urls_from_page(driver: webdriver.Chrome) -> List[str]:
        """í˜ì´ì§€ì—ì„œ URL ì¶”ì¶œ (ê³µí†µ ê¸°ëŠ¥)"""
        try:
            links = driver.find_elements(By.TAG_NAME, "a")
            urls = []
            
            for link in links:
                href = link.get_attribute("href")
                if href and href.startswith("http"):
                    urls.append(href)
            
            return list(set(urls))  # ì¤‘ë³µ ì œê±°
            
        except Exception as e:
            print(f"âŒ URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []