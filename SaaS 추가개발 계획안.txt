================================================================================
                          SaaS 추가개발 계획안
================================================================================

📋 프로젝트 개요
================================================================================
• 프로젝트명: 교회/기관 크롤링 CRM 시스템 SaaS 전환
• 목적: 현재 FastAPI 기반 시스템을 간편한 SaaS 형태로 전환
• 핵심 요구사항: 
  - 복잡한 HTML/CSS/JS 제거
  - 인터넷 연결만으로 직원 누구나 사용 가능
  - 클라우드 기반 SaaS 서비스
  - 기존 크롤링 로직 100% 재사용

🎯 사용자 요구사항 분석
================================================================================

1. 기술적 요구사항
   ✅ 현재 상태: FastAPI + 복잡한 웹 인터페이스 
   ❌ 문제점: HTML/CSS/JS 유지보수 복잡성
   ✅ 목표: Python만으로 간단한 웹 인터페이스

2. 배포 환경 요구사항
   ❌ On-Premise 방식 → 설치/관리 복잡
   ❌ NAS 방식 → 네트워크 설정 복잡
   ❌ 완전 오프라인 → 확장성 제한
   ✅ SaaS 방식 → 브라우저만으로 접속 가능

3. 데이터베이스 요구사항
   ❓ PostgreSQL 필요성 의문
   ✅ SQLite 유지 가능 (내부 사용 규모 고려)

4. 기능적 요구사항
   ✅ 기존 크롤링 엔진 유지
   ✅ 데이터베이스 관리 기능 유지
   ✅ 사용자 권한 관리 유지
   ✅ 통계/대시보드 기능 유지

🚀 제시된 해결책: Streamlit 기반 SaaS
================================================================================

선택 이유:
• HTML/CSS/JS 코드 불필요 → Python만으로 완전한 웹 인터페이스
• 기존 백엔드 로직 95% 재사용 가능
• 클라우드 배포 간편 (여러 옵션 제공)
• 실시간 데이터 처리 및 시각화 우수
• 브라우저만으로 접속 가능

📊 현재 시스템 분석
================================================================================

재사용 가능한 모듈 (95%):
✅ crawler_main.py        - 통합 크롤링 엔진
✅ data_processor.py      - 데이터 처리 로직
✅ database/             - SQLite 기반 CRM 데이터베이스
✅ parser.py             - 웹페이지 파싱 엔진
✅ ai_helpers.py         - AI 기반 데이터 분석
✅ naver_map_crawler.py  - 네이버 지도 크롤링
✅ utils/                - 모든 유틸리티 모듈
✅ settings.py           - 통합 설정 관리

교체 대상 (5%):
❌ app.py                - FastAPI 애플리케이션
❌ templates/            - HTML/CSS/JS 템플릿
→ streamlit_crm.py로 대체

🛠️ 상세 개발 계획
================================================================================

Phase 1: Streamlit 기반 메인 인터페이스 개발 (3일)
────────────────────────────────────────────────────

1.1 메인 앱 구조 설계 (0.5일)
• streamlit_crm.py 생성
• 페이지 구조 설계: 대시보드/기관관리/크롤링/통계/설정
• 사이드바 네비게이션 구성
• 반응형 레이아웃 설정

1.2 대시보드 페이지 개발 (1일)
• 통계 카드 (총 기관수, 신규등록, 크롤링완료, 연락완료)
• 최근 활동 테이블
• 진행중인 크롤링 작업 상태 표시
• 실시간 업데이트 기능

1.3 기관 관리 페이지 개발 (1일)
• 검색 및 필터링 (기관명, 카테고리, 상태별)
• 페이지네이션 구현
• 데이터 그리드 (편집 가능)
• 일괄 수정/삭제 기능
• 데이터 내보내기 (Excel, CSV)

1.4 크롤링 실행 페이지 개발 (0.5일)
• JSON 파일 업로드 인터페이스
• 크롤링 옵션 설정 (테스트모드, AI사용, 지연시간)
• 실시간 진행률 표시
• 로그 스트리밍 표시
• 결과 미리보기

Phase 2: 기존 로직 통합 및 최적화 (2일)
────────────────────────────────────────────────────

2.1 데이터베이스 연동 (1일)
• get_database() 함수 연동
• @st.cache_resource 적용으로 성능 최적화
• 실시간 데이터 업데이트 구현
• 트랜잭션 처리 안전성 확보

2.2 크롤링 엔진 통합 (1일)
• UnifiedCrawler 클래스 통합
• 비동기 처리를 위한 스레드 구현
• 진행상황 실시간 콜백 구현
• 에러 처리 및 재시도 로직 강화

Phase 3: 고급 기능 개발 (2일)
────────────────────────────────────────────────────

3.1 통계 및 분석 페이지 (1일)
• 지역별 분포 차트 (지도 시각화)
• 카테고리별 분포 (파이차트)
• 크롤링 성공률 추이 (라인차트)
• 월별 데이터 증가 추이
• 사용자별 활동 통계

3.2 시스템 설정 페이지 (1일)
• 사용자 계정 관리
• API 키 설정 (Gemini API)
• 크롤링 기본 설정 (지연시간, 동시처리수)
• 데이터 백업/복원 기능
• 로그 레벨 설정

Phase 4: 보안 및 사용자 관리 강화 (1일)
────────────────────────────────────────────────────

4.1 인증 시스템 개선 (0.5일)
• 기존 database/models.py의 User 모델 활용
• 세션 기반 로그인 구현
• 권한별 메뉴 접근 제어
• 패스워드 정책 강화

4.2 보안 강화 (0.5일)
• SQL Injection 방지
• XSS 공격 방지
• 민감 정보 암호화 저장
• 접근 로그 기록

Phase 5: 배포 및 운영 준비 (2일)
────────────────────────────────────────────────────

5.1 배포 환경 구성 (1일)
• requirements.txt 업데이트
• Dockerfile 작성
• docker-compose.yml 구성
• 환경변수 설정 (.env)
• 헬스체크 엔드포인트 추가

5.2 클라우드 배포 옵션 준비 (1일)
• Streamlit Cloud 배포 준비
• AWS EC2 배포 스크립트
• Google Cloud Run 설정
• 도메인 및 SSL 인증서 설정
• 백업 자동화 스크립트

🗃️ 데이터베이스 유지 결정
================================================================================

SQLite 유지 권장 이유:
✅ 현재 데이터 규모 (28,104개 교회): SQLite로 충분
✅ 예상 사용자 (5-20명): 동시접속 문제없음
✅ 백업 간편: 파일 복사만으로 완료
✅ 관리 용이: DBA 불필요
✅ 비용 절약: DB 서버 불필요
✅ 기존 스키마 100% 재사용

PostgreSQL 전환 고려 시점:
• 동시 사용자 50명 이상
• 데이터 100만 건 이상
• 복잡한 분석 쿼리 필요시
• 다중 서버 환경 구축시

💻 기술 스택 변경 사항
================================================================================

기존 스택:
- Backend: FastAPI + Uvicorn
- Frontend: HTML + CSS + JavaScript
- Database: SQLite
- AI: Google Gemini API

새로운 스택:
- Framework: Streamlit
- Backend Logic: 기존 모듈 재사용
- Database: SQLite (유지)
- AI: Google Gemini API (유지)
- 추가 라이브러리: plotly, altair (차트)

🚀 배포 옵션별 비교
================================================================================

옵션 A: Streamlit Cloud (추천 - 무료)
────────────────────────────────────
• 비용: 무료
• 설정: GitHub 연동으로 자동 배포
• URL: https://company-crawler.streamlit.app
• 장점: 설정 간단, 자동 업데이트
• 단점: 공용 클라우드, 성능 제한

옵션 B: AWS EC2 (중급)
─────────────────────
• 비용: 월 $10-50 (인스턴스 크기별)
• 설정: Docker + 도메인 설정 필요
• URL: 사용자 지정 도메인 가능
• 장점: 완전한 제어권, 확장성
• 단점: 서버 관리 필요

옵션 C: Google Cloud Run (고급)
──────────────────────────────
• 비용: 사용량 기반 과금
• 설정: 컨테이너 기반 배포
• URL: 사용자 지정 도메인 가능
• 장점: 자동 스케일링, 고성능
• 단점: 설정 복잡도 높음

옵션 D: 자체 서버 (기업용)
─────────────────────────
• 비용: 서버 구입/임대비
• 설정: 완전한 자체 관리
• URL: 내부 IP 또는 사설 도메인
• 장점: 완전한 보안, 데이터 제어
• 단점: 인프라 관리 부담

📊 예상 작업 일정
================================================================================

총 소요 기간: 10일 (2주)

Week 1:
• Day 1-3: Phase 1 (Streamlit 인터페이스 개발)
• Day 4-5: Phase 2 (기존 로직 통합)

Week 2:
• Day 6-7: Phase 3 (고급 기능 개발)
• Day 8: Phase 4 (보안 강화)
• Day 9-10: Phase 5 (배포 준비)

병렬 작업 가능:
• UI 개발과 동시에 배포 환경 준비
• 테스트 계정으로 기능 검증

💰 예상 비용 분석
================================================================================

개발 비용: 인건비 (2주)
운영 비용 (월간):
• Streamlit Cloud: $0 (무료)
• AWS EC2 t3.small: ~$15
• Google Cloud Run: ~$5-20 (사용량 기반)
• 도메인: ~$10/년
• SSL 인증서: 무료 (Let's Encrypt)

연간 총 운영비:
• 최소: $0 (Streamlit Cloud)
• 일반: $180-240 (AWS)
• 고급: $60-240 (GCP)

🧪 테스트 계획
================================================================================

단위 테스트:
• 각 페이지별 기능 테스트
• 데이터베이스 연동 테스트
• 크롤링 엔진 통합 테스트

통합 테스트:
• 사용자 시나리오 기반 테스트
• 동시 접속 테스트 (5-10명)
• 대용량 데이터 처리 테스트

성능 테스트:
• 페이지 로딩 속도
• 크롤링 처리 성능
• 데이터베이스 쿼리 속도

보안 테스트:
• 인증/권한 테스트
• SQL Injection 테스트
• XSS 공격 테스트

📚 사용자 매뉴얼 제작
================================================================================

관리자용 매뉴얼:
• 시스템 설치 및 배포 가이드
• 사용자 계정 관리
• 백업 및 복원 절차
• 문제 해결 가이드

사용자용 매뉴얼:
• 로그인 및 기본 사용법
• 기관 정보 조회/수정
• 크롤링 실행 방법
• 데이터 내보내기
• FAQ

🔧 유지보수 계획
================================================================================

정기 유지보수:
• 월 1회: 데이터베이스 백업 확인
• 분기 1회: 보안 업데이트 적용
• 반기 1회: 성능 최적화 검토

기능 개선:
• 사용자 피드백 수집
• 새로운 크롤링 사이트 추가
• AI 모델 성능 개선
• UI/UX 개선

모니터링:
• 시스템 리소스 사용량
• 에러 로그 모니터링
• 사용자 접속 패턴 분석
• 크롤링 성공률 추적

⚠️ 리스크 요소 및 대응 방안
================================================================================

기술적 리스크:
• Streamlit 성능 제한 → 최적화 기법 적용
• SQLite 동시접속 제한 → 연결 풀링 구현
• AI API 할당량 초과 → 사용량 모니터링 및 제한

운영 리스크:
• 서버 장애 → 백업 서버 준비
• 데이터 손실 → 자동 백업 시스템
• 보안 침해 → 정기 보안 점검

비즈니스 리스크:
• 사용자 적응 → 충분한 교육 제공
• 기능 부족 → 단계적 기능 확장
• 성능 불만 → 지속적 최적화

✅ 최종 체크리스트
================================================================================

개발 완료 기준:
□ 모든 기존 기능이 Streamlit에서 정상 작동
□ 사용자 인증 및 권한 관리 구현
□ 실시간 크롤링 진행상황 표시
□ 데이터 내보내기 기능 구현
□ 모바일 반응형 인터페이스 적용
□ 보안 취약점 점검 완료
□ 성능 테스트 통과
□ 사용자 매뉴얼 작성 완료

배포 완료 기준:
□ 클라우드 서버 설정 완료
□ 도메인 및 SSL 인증서 적용
□ 자동 백업 시스템 구축
□ 모니터링 도구 설치
□ 긴급 연락망 구축
□ 롤백 절차 준비

📞 지원 체계
================================================================================

기술 지원:
• 개발자 직접 지원 (평일 9-18시)
• 이메일 지원 (24시간 내 응답)
• 원격 지원 도구 준비

교육 지원:
• 초기 사용자 교육 (2시간)
• 추가 기능 교육 (필요시)
• 매뉴얼 및 동영상 가이드 제공

운영 지원:
• 정기 점검 (월 1회)
• 업데이트 지원
• 성능 최적화 지원

================================================================================
                              계획서 완료
================================================================================

이 계획서는 현재 FastAPI 기반 시스템을 Streamlit 기반 SaaS로 전환하는
완전한 로드맵을 제시합니다. 기존 백엔드 로직의 95%를 재사용하면서도
HTML/CSS/JS의 복잡성을 제거하여 유지보수성을 크게 향상시킬 수 있습니다.

총 개발 기간: 2주 (10일)
예상 성공률: 95% (기존 로직 재사용으로 리스크 최소화)
권장 배포 방식: Streamlit Cloud (무료) 또는 AWS EC2 (안정성)

다음 단계: 이 계획서 검토 후 Phase 1부터 개발 시작 