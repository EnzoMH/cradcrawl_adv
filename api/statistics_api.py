#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µê³„ ë¶„ì„ API
CRM ë°ì´í„°ë² ì´ìŠ¤ì˜ í†µê³„ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± API
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import Counter, defaultdict

from fastapi import APIRouter, HTTPException, Query, BackgroundTasks
from fastapi.responses import JSONResponse

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from database.database import get_database
from services.organization_service import OrganizationService
from utils.logger_utils import LoggerUtils
from utils.settings import (
    KOREAN_AREA_CODES,
    PORTAL_EMAIL_DOMAINS,
    GOVERNMENT_EMAIL_SUFFIXES,
    EDUCATION_EMAIL_SUFFIXES,
    BUSINESS_EMAIL_SUFFIXES,
    RELIGIOUS_EMAIL_KEYWORDS,
    format_phone_number,
    extract_phone_area_code
)

# ë¡œê±° ì„¤ì •
logger = LoggerUtils.setup_logger(name="statistics_api", file_logging=False)

# ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/api/statistics", tags=["í†µê³„ ë¶„ì„"])

class CRMStatisticsAnalyzer:
    """CRM ë°ì´í„° í†µê³„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.db = get_database()
        self.org_service = OrganizationService()
    
    def validate_korean_phone(self, phone: str) -> Dict[str, Any]:
        """í•œêµ­ ì „í™”ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì¦"""
        if not phone:
            return {"is_valid": False, "reason": "ë²ˆí˜¸ ì—†ìŒ"}
        
        import re
        digits = re.sub(r'[^\d]', '', phone)
        
        # ê¸¸ì´ ì²´í¬
        if len(digits) < 9 or len(digits) > 11:
            return {"is_valid": False, "reason": "ê¸¸ì´ ì˜¤ë¥˜"}
        
        # ì§€ì—­ì½”ë“œ ì²´í¬
        area_code = extract_phone_area_code(phone)
        if not area_code:
            return {"is_valid": False, "reason": "ì§€ì—­ì½”ë“œ ì˜¤ë¥˜"}
        
        # ê¸¸ì´ë³„ ìœ íš¨ì„± ì²´í¬
        expected_lengths = {
            '02': [9, 10],  # ì„œìš¸
            '070': [11],    # ì¸í„°ë„·ì „í™”
            '010': [11], '017': [11]  # í•¸ë“œí°
        }
        
        if area_code in expected_lengths:
            if len(digits) not in expected_lengths[area_code]:
                return {"is_valid": False, "reason": "ê¸¸ì´ ë¶ˆì¼ì¹˜"}
        else:
            # ê¸°íƒ€ ì§€ì—­ë²ˆí˜¸ëŠ” 10-11ìë¦¬
            if len(digits) not in [10, 11]:
                return {"is_valid": False, "reason": "ê¸¸ì´ ë¶ˆì¼ì¹˜"}
        
        return {
            "is_valid": True,
            "area_code": area_code,
            "area_name": KOREAN_AREA_CODES.get(area_code, "ì•Œ ìˆ˜ ì—†ìŒ"),
            "formatted": format_phone_number(digits, area_code)
        }
    
    def extract_email_domain(self, email: str) -> Optional[str]:
        """ì´ë©”ì¼ì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
        if not email or '@' not in email:
            return None
        
        try:
            domain = email.split('@')[1].lower()
            return domain
        except:
            return None
    
    def categorize_email_domain(self, domain: str) -> str:
        """ì´ë©”ì¼ ë„ë©”ì¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        if not domain:
            return "ê¸°íƒ€"
        
        if domain in PORTAL_EMAIL_DOMAINS:
            return "í¬í„¸"
        
        if any(domain.endswith(suffix) for suffix in GOVERNMENT_EMAIL_SUFFIXES):
            return "ì •ë¶€/ê³µê³µ"
        
        if any(domain.endswith(suffix) for suffix in EDUCATION_EMAIL_SUFFIXES):
            return "êµìœ¡ê¸°ê´€"
        
        if any(domain.endswith(suffix) for suffix in BUSINESS_EMAIL_SUFFIXES):
            return "ê¸°ì—…/ì¡°ì§"
        
        if any(keyword in domain for keyword in RELIGIOUS_EMAIL_KEYWORDS):
            return "ì¢…êµê¸°ê´€"
        
        return "ê¸°íƒ€"
    
    def analyze_contact_data(self) -> Dict[str, Any]:
        """ì—°ë½ì²˜ ë°ì´í„° ë¶„ì„"""
        logger.info("ğŸ” CRM ì—°ë½ì²˜ ë°ì´í„° ë¶„ì„ ì‹œì‘")
        
        try:
            stats = {
                "analysis_info": {
                    "analysis_time": datetime.now().isoformat(),
                    "analysis_type": "contact_analysis"
                },
                "basic_stats": {},
                "contact_coverage": {},
                "quality_metrics": {},
                "geographic_distribution": {},
                "email_analysis": {},
                "category_breakdown": {}
            }
            
            # ê¸°ë³¸ í†µê³„ ì¡°íšŒ
            with self.db.get_connection() as conn:
                # ì „ì²´ ê¸°ê´€ ìˆ˜
                cursor = conn.execute("SELECT COUNT(*) FROM organizations WHERE is_active = 1")
                total_orgs = cursor.fetchone()[0]
                
                # ì—°ë½ì²˜ë³„ ë³´ìœ  í˜„í™©
                cursor = conn.execute("""
                    SELECT 
                        COUNT(CASE WHEN phone IS NOT NULL AND phone != '' THEN 1 END) as phone_count,
                        COUNT(CASE WHEN fax IS NOT NULL AND fax != '' THEN 1 END) as fax_count,
                        COUNT(CASE WHEN email IS NOT NULL AND email != '' THEN 1 END) as email_count,
                        COUNT(CASE WHEN homepage IS NOT NULL AND homepage != '' THEN 1 END) as homepage_count,
                        COUNT(CASE WHEN phone IS NOT NULL AND phone != '' 
                                   AND fax IS NOT NULL AND fax != ''
                                   AND email IS NOT NULL AND email != '' THEN 1 END) as complete_count
                    FROM organizations WHERE is_active = 1
                """)
                
                contact_counts = cursor.fetchone()
                phone_count, fax_count, email_count, homepage_count, complete_count = contact_counts
                
                # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
                cursor = conn.execute("""
                    SELECT 
                        category,
                        COUNT(*) as total,
                        COUNT(CASE WHEN phone IS NOT NULL AND phone != '' THEN 1 END) as has_phone,
                        COUNT(CASE WHEN fax IS NOT NULL AND fax != '' THEN 1 END) as has_fax,
                        COUNT(CASE WHEN email IS NOT NULL AND email != '' THEN 1 END) as has_email,
                        COUNT(CASE WHEN homepage IS NOT NULL AND homepage != '' THEN 1 END) as has_homepage
                    FROM organizations 
                    WHERE is_active = 1 
                    GROUP BY category
                    ORDER BY total DESC
                """)
                
                category_stats = {}
                for row in cursor.fetchall():
                    category, total, has_phone, has_fax, has_email, has_homepage = row
                    category_stats[category] = {
                        "total": total,
                        "phone_coverage": round((has_phone / total * 100), 1) if total > 0 else 0,
                        "fax_coverage": round((has_fax / total * 100), 1) if total > 0 else 0,
                        "email_coverage": round((has_email / total * 100), 1) if total > 0 else 0,
                        "homepage_coverage": round((has_homepage / total * 100), 1) if total > 0 else 0,
                        "contact_counts": {
                            "phone": has_phone,
                            "fax": has_fax,
                            "email": has_email,
                            "homepage": has_homepage
                        }
                    }
            
            # ê¸°ë³¸ í†µê³„
            stats["basic_stats"] = {
                "total_organizations": total_orgs,
                "complete_contacts": complete_count,
                "incomplete_contacts": total_orgs - complete_count
            }
            
            # ì—°ë½ì²˜ ì»¤ë²„ë¦¬ì§€
            stats["contact_coverage"] = {
                "phone": {
                    "count": phone_count,
                    "rate": round((phone_count / total_orgs * 100), 1) if total_orgs > 0 else 0
                },
                "fax": {
                    "count": fax_count,
                    "rate": round((fax_count / total_orgs * 100), 1) if total_orgs > 0 else 0
                },
                "email": {
                    "count": email_count,
                    "rate": round((email_count / total_orgs * 100), 1) if total_orgs > 0 else 0
                },
                "homepage": {
                    "count": homepage_count,
                    "rate": round((homepage_count / total_orgs * 100), 1) if total_orgs > 0 else 0
                }
            }
            
            # í’ˆì§ˆ ì§€í‘œ ë¶„ì„
            valid_phones = 0
            valid_faxes = 0
            phone_areas = Counter()
            fax_areas = Counter()
            email_domains = Counter()
            
            with self.db.get_connection() as conn:
                # ì „í™”ë²ˆí˜¸ í’ˆì§ˆ ë¶„ì„
                cursor = conn.execute("SELECT phone FROM organizations WHERE phone IS NOT NULL AND phone != '' AND is_active = 1")
                for (phone,) in cursor.fetchall():
                    validation = self.validate_korean_phone(phone)
                    if validation["is_valid"]:
                        valid_phones += 1
                        phone_areas[validation["area_code"]] += 1
                
                # íŒ©ìŠ¤ë²ˆí˜¸ í’ˆì§ˆ ë¶„ì„
                cursor = conn.execute("SELECT fax FROM organizations WHERE fax IS NOT NULL AND fax != '' AND is_active = 1")
                for (fax,) in cursor.fetchall():
                    validation = self.validate_korean_phone(fax)
                    if validation["is_valid"]:
                        valid_faxes += 1
                        fax_areas[validation["area_code"]] += 1
                
                # ì´ë©”ì¼ ë„ë©”ì¸ ë¶„ì„
                cursor = conn.execute("SELECT email FROM organizations WHERE email IS NOT NULL AND email != '' AND is_active = 1")
                for (email,) in cursor.fetchall():
                    domain = self.extract_email_domain(email)
                    if domain:
                        email_domains[domain] += 1
            
            # í’ˆì§ˆ ì§€í‘œ
            stats["quality_metrics"] = {
                "phone_validity_rate": round((valid_phones / phone_count * 100), 1) if phone_count > 0 else 0,
                "fax_validity_rate": round((valid_faxes / fax_count * 100), 1) if fax_count > 0 else 0,
                "completeness_rate": round((complete_count / total_orgs * 100), 1) if total_orgs > 0 else 0,
                "valid_phones": valid_phones,
                "valid_faxes": valid_faxes
            }
            
            # ì§€ì—­ ë¶„í¬
            all_areas = Counter()
            all_areas.update(phone_areas)
            all_areas.update(fax_areas)
            
            stats["geographic_distribution"] = {
                area_code: {
                    "area_name": KOREAN_AREA_CODES.get(area_code, "ì•Œ ìˆ˜ ì—†ìŒ"),
                    "total_contacts": count,
                    "phone_count": phone_areas.get(area_code, 0),
                    "fax_count": fax_areas.get(area_code, 0)
                }
                for area_code, count in all_areas.most_common(20)
            }
            
            # ì´ë©”ì¼ ë„ë©”ì¸ ë¶„ì„
            email_categories = Counter()
            for domain, count in email_domains.most_common(100):
                category = self.categorize_email_domain(domain)
                email_categories[category] += count
            
            stats["email_analysis"] = {
                "top_domains": dict(email_domains.most_common(20)),
                "domain_categories": dict(email_categories),
                "total_unique_domains": len(email_domains)
            }
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
            stats["category_breakdown"] = category_stats
            
            logger.info(f"âœ… CRM ì—°ë½ì²˜ ë¶„ì„ ì™„ë£Œ - ì´ {total_orgs:,}ê°œ ê¸°ê´€")
            return stats
            
        except Exception as e:
            logger.error(f"âŒ CRM ì—°ë½ì²˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def analyze_enrichment_history(self, days: int = 30) -> Dict[str, Any]:
        """ë³´ê°• ì´ë ¥ ë¶„ì„"""
        logger.info(f"ğŸ“ˆ ìµœê·¼ {days}ì¼ ë³´ê°• ì´ë ¥ ë¶„ì„ ì‹œì‘")
        
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            
            with self.db.get_connection() as conn:
                # ë³´ê°• í™œë™ ë¶„ì„ (enrichment_history í…Œì´ë¸”ì´ ìˆë‹¤ê³  ê°€ì •)
                cursor = conn.execute("""
                    SELECT 
                        DATE(updated_at) as date,
                        COUNT(*) as updated_count
                    FROM organizations 
                    WHERE updated_at >= ? AND is_active = 1
                    GROUP BY DATE(updated_at)
                    ORDER BY date DESC
                """, (cutoff_date.isoformat(),))
                
                daily_updates = {}
                for row in cursor.fetchall():
                    date, count = row
                    daily_updates[date] = count
            
            return {
                "analysis_period": f"ìµœê·¼ {days}ì¼",
                "daily_updates": daily_updates,
                "total_updates": sum(daily_updates.values()),
                "average_daily_updates": round(sum(daily_updates.values()) / len(daily_updates), 1) if daily_updates else 0
            }
            
        except Exception as e:
            logger.error(f"âŒ ë³´ê°• ì´ë ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def generate_data_quality_report(self) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“‹ ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        
        try:
            contact_analysis = self.analyze_contact_data()
            enrichment_history = self.analyze_enrichment_history()
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_metrics = contact_analysis.get("quality_metrics", {})
            coverage = contact_analysis.get("contact_coverage", {})
            
            coverage_score = (
                coverage.get("phone", {}).get("rate", 0) +
                coverage.get("fax", {}).get("rate", 0) +
                coverage.get("email", {}).get("rate", 0) +
                coverage.get("homepage", {}).get("rate", 0)
            ) / 4
            
            validity_score = (
                quality_metrics.get("phone_validity_rate", 0) +
                quality_metrics.get("fax_validity_rate", 0)
            ) / 2
            
            completeness_score = quality_metrics.get("completeness_rate", 0)
            
            overall_score = (coverage_score * 0.4 + validity_score * 0.3 + completeness_score * 0.3)
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = []
            
            if quality_metrics.get("phone_validity_rate", 0) < 90:
                recommendations.append({
                    "priority": "high",
                    "category": "data_quality",
                    "issue": "ì „í™”ë²ˆí˜¸ ìœ íš¨ì„± ë‚®ìŒ",
                    "description": f"ì „í™”ë²ˆí˜¸ ìœ íš¨ì„±ì´ {quality_metrics.get('phone_validity_rate', 0):.1f}%ì…ë‹ˆë‹¤.",
                    "action": "ì „í™”ë²ˆí˜¸ í˜•ì‹ ê²€ì¦ ë° ì •ë¦¬ í•„ìš”"
                })
            
            if completeness_score < 50:
                recommendations.append({
                    "priority": "medium",
                    "category": "data_coverage",
                    "issue": "ì—°ë½ì²˜ ì •ë³´ ì™„ì„±ë„ ë‚®ìŒ",
                    "description": f"ì™„ì „í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ ê°€ì§„ ê¸°ê´€ì´ {completeness_score:.1f}%ì…ë‹ˆë‹¤.",
                    "action": "ìë™ ë³´ê°• ì‹œìŠ¤í…œ í™œìš© ê¶Œì¥"
                })
            
            if coverage.get("email", {}).get("rate", 0) < 30:
                recommendations.append({
                    "priority": "medium",
                    "category": "data_coverage",
                    "issue": "ì´ë©”ì¼ ì •ë³´ ë¶€ì¡±",
                    "description": f"ì´ë©”ì¼ ì •ë³´ ë³´ìœ ìœ¨ì´ {coverage.get('email', {}).get('rate', 0):.1f}%ì…ë‹ˆë‹¤.",
                    "action": "ì´ë©”ì¼ ìˆ˜ì§‘ ê°•í™” í•„ìš”"
                })
            
            return {
                "report_info": {
                    "generated_at": datetime.now().isoformat(),
                    "report_type": "data_quality"
                },
                "overall_score": round(overall_score, 1),
                "score_breakdown": {
                    "coverage_score": round(coverage_score, 1),
                    "validity_score": round(validity_score, 1),
                    "completeness_score": round(completeness_score, 1)
                },
                "contact_analysis": contact_analysis,
                "enrichment_history": enrichment_history,
                "recommendations": recommendations
            }
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = CRMStatisticsAnalyzer()

# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@router.get("/overview", summary="í†µê³„ ê°œìš”")
async def get_statistics_overview():
    """í†µê³„ ë¶„ì„ ê°œìš” ì¡°íšŒ"""
    try:
        contact_analysis = analyzer.analyze_contact_data()
        
        return {
            "status": "success",
            "data": {
                "basic_stats": contact_analysis.get("basic_stats", {}),
                "contact_coverage": contact_analysis.get("contact_coverage", {}),
                "quality_metrics": contact_analysis.get("quality_metrics", {}),
                "top_categories": dict(list(contact_analysis.get("category_breakdown", {}).items())[:5])
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ í†µê³„ ê°œìš” ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í†µê³„ ê°œìš” ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@router.get("/contact-analysis", summary="ì—°ë½ì²˜ ë¶„ì„")
async def get_contact_analysis():
    """ìƒì„¸ ì—°ë½ì²˜ ë¶„ì„ ë°ì´í„°"""
    try:
        analysis = analyzer.analyze_contact_data()
        
        return {
            "status": "success",
            "analysis": analysis
        }
        
    except Exception as e:
        logger.error(f"âŒ ì—°ë½ì²˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì—°ë½ì²˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@router.get("/geographic-distribution", summary="ì§€ì—­ë³„ ë¶„í¬")
async def get_geographic_distribution():
    """ì§€ì—­ë³„ ì—°ë½ì²˜ ë¶„í¬ ë¶„ì„"""
    try:
        analysis = analyzer.analyze_contact_data()
        geo_distribution = analysis.get("geographic_distribution", {})
        
        return {
            "status": "success",
            "geographic_data": geo_distribution,
            "summary": {
                "total_regions": len(geo_distribution),
                "top_region": list(geo_distribution.keys())[0] if geo_distribution else None
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ ì§€ì—­ë³„ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì§€ì—­ë³„ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@router.get("/email-analysis", summary="ì´ë©”ì¼ ë¶„ì„")
async def get_email_analysis():
    """ì´ë©”ì¼ ë„ë©”ì¸ ë° ì¹´í…Œê³ ë¦¬ ë¶„ì„"""
    try:
        analysis = analyzer.analyze_contact_data()
        email_analysis = analysis.get("email_analysis", {})
        
        return {
            "status": "success",
            "email_data": email_analysis
        }
        
    except Exception as e:
        logger.error(f"âŒ ì´ë©”ì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì´ë©”ì¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@router.get("/quality-report", summary="ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸")
async def get_quality_report():
    """ì¢…í•© ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸"""
    try:
        report = analyzer.generate_data_quality_report()
        
        return {
            "status": "success",
            "report": report
        }
        
    except Exception as e:
        logger.error(f"âŒ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.get("/enrichment-history", summary="ë³´ê°• ì´ë ¥")
async def get_enrichment_history(days: int = Query(30, ge=1, le=365, description="ë¶„ì„ ê¸°ê°„ (ì¼)")):
    """ë³´ê°• í™œë™ ì´ë ¥ ë¶„ì„"""
    try:
        history = analyzer.analyze_enrichment_history(days)
        
        return {
            "status": "success",
            "history": history
        }
        
    except Exception as e:
        logger.error(f"âŒ ë³´ê°• ì´ë ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë³´ê°• ì´ë ¥ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@router.get("/category-breakdown", summary="ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„")
async def get_category_breakdown():
    """ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë¶„ì„"""
    try:
        analysis = analyzer.analyze_contact_data()
        category_breakdown = analysis.get("category_breakdown", {})
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì™„ì„±ë„ ìˆœìœ„
        category_scores = []
        for category, stats in category_breakdown.items():
            avg_coverage = (
                stats.get("phone_coverage", 0) +
                stats.get("fax_coverage", 0) +
                stats.get("email_coverage", 0) +
                stats.get("homepage_coverage", 0)
            ) / 4
            
            category_scores.append({
                "category": category,
                "total_organizations": stats.get("total", 0),
                "average_coverage": round(avg_coverage, 1),
                "coverage_details": {
                    "phone": stats.get("phone_coverage", 0),
                    "fax": stats.get("fax_coverage", 0),
                    "email": stats.get("email_coverage", 0),
                    "homepage": stats.get("homepage_coverage", 0)
                }
            })
        
        # ì™„ì„±ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        category_scores.sort(key=lambda x: x["average_coverage"], reverse=True)
        
        return {
            "status": "success",
            "category_breakdown": category_breakdown,
            "category_ranking": category_scores
        }
        
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@router.post("/generate-report", summary="ë¦¬í¬íŠ¸ ìƒì„±")
async def generate_comprehensive_report(background_tasks: BackgroundTasks):
    """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
    try:
        # ì¦‰ì‹œ ì‘ë‹µ í›„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¦¬í¬íŠ¸ ìƒì„±
        def generate_report():
            try:
                report = analyzer.generate_data_quality_report()
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"crm_statistics_report_{timestamp}.json"
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
                
                logger.info(f"ğŸ“‹ í†µê³„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {filename}")
                
            except Exception as e:
                logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        
        background_tasks.add_task(generate_report)
        
        return {
            "status": "success",
            "message": "ë¦¬í¬íŠ¸ ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "estimated_time": "2-3ë¶„ ì†Œìš” ì˜ˆìƒ"
        }
        
    except Exception as e:
        logger.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.get("/export-data", summary="ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
async def export_statistics_data(
    format: str = Query("json", regex="^(json|csv)$", description="ë‚´ë³´ë‚´ê¸° í˜•ì‹"),
    include_details: bool = Query(True, description="ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€")
):
    """í†µê³„ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
    try:
        analysis = analyzer.analyze_contact_data()
        
        if format == "json":
            return {
                "status": "success",
                "format": "json",
                "data": analysis if include_details else {
                    "basic_stats": analysis.get("basic_stats", {}),
                    "contact_coverage": analysis.get("contact_coverage", {}),
                    "quality_metrics": analysis.get("quality_metrics", {})
                }
            }
        
        elif format == "csv":
            # CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ë²„ì „)
            csv_data = []
            csv_data.append("Category,Total,Phone_Coverage,Fax_Coverage,Email_Coverage,Homepage_Coverage")
            
            for category, stats in analysis.get("category_breakdown", {}).items():
                csv_data.append(f"{category},{stats.get('total', 0)},{stats.get('phone_coverage', 0)},{stats.get('fax_coverage', 0)},{stats.get('email_coverage', 0)},{stats.get('homepage_coverage', 0)}")
            
            return {
                "status": "success",
                "format": "csv",
                "data": "\n".join(csv_data)
            }
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}")