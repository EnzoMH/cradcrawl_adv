#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VPN ìš°íšŒ ê¸°ëŠ¥ì´ í¬í•¨ëœ URL ì¶”ì¶œê¸°
êµ¬ê¸€ ì°¨ë‹¨ ì‹œ ìë™ìœ¼ë¡œ VPN Gateë¥¼ í†µí•´ ìš°íšŒí•©ë‹ˆë‹¤.
"""

import json
import os
import sys
import time
import random
import re
import logging
import requests
import base64
import tempfile
import subprocess
from typing import List, Dict, Any, Optional
from urllib.parse import quote_plus, urlparse, unquote
from datetime import datetime

# Selenium imports
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options

class VPNManager:
    """VPN ì—°ê²° ê´€ë¦¬"""
    
    def __init__(self):
        self.current_process = None
        self.current_config = None
        self.logger = logging.getLogger('VPN')
    
    def get_vpn_servers(self, country: str) -> List[Dict]:
        """VPN Gate ì„œë²„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            self.logger.info(f"VPN ì„œë²„ ê²€ìƒ‰: {country}")
            response = requests.get("http://www.vpngate.net/api/iphone/", timeout=10)
            vpn_data = response.text.replace("\r", "")
            servers = [line.split(",") for line in vpn_data.split("\n")]
            
            if len(servers) < 3:
                return []
                
            servers = [s for s in servers[2:] if len(s) > 14]
            
            # êµ­ê°€ í•„í„°ë§
            i = 6 if len(country) == 2 else 5
            desired = [s for s in servers if country.lower() in s[i].lower()]
            supported = [s for s in desired if len(s[-1]) > 0]
            
            # ì ìˆ˜ ìˆœ ì •ë ¬
            sorted_servers = sorted(supported, key=lambda s: float(s[2].replace(",", ".")), reverse=True)
            
            result = []
            for server in sorted_servers[:2]:  # ìƒìœ„ 2ê°œë§Œ
                result.append({
                    'config': server[-1],
                    'score': float(server[2].replace(",", ".")),
                    'country': country
                })
            
            self.logger.info(f"{country}ì—ì„œ {len(result)}ê°œ ì„œë²„ ë°œê²¬")
            return result
            
        except Exception as e:
            self.logger.error(f"VPN ì„œë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def connect_vpn(self, country: str) -> bool:
        """VPN ì—°ê²°"""
        try:
            servers = self.get_vpn_servers(country)
            if not servers:
                return False
            
            self.disconnect_vpn()
            
            server = servers[0]
            self.logger.info(f"VPN ì—°ê²° ì‹œë„: {country}")
            
            # ì„ì‹œ ì„¤ì • íŒŒì¼ ìƒì„±
            _, config_path = tempfile.mkstemp(suffix='.ovpn')
            self.current_config = config_path
            
            with open(config_path, 'w') as f:
                config_content = base64.b64decode(server['config']).decode()
                f.write(config_content)
            
            try:
                # OpenVPN ì‹¤í–‰
                self.current_process = subprocess.Popen(
                    ["openvpn", "--config", config_path],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL
                )
                
                time.sleep(8)  # ì—°ê²° ëŒ€ê¸°
                
                if self.current_process.poll() is None:
                    self.logger.info(f"VPN ì—°ê²° ì„±ê³µ: {country}")
                    return True
                else:
                    self.logger.warning(f"VPN ì—°ê²° ì‹¤íŒ¨: {country}")
                    return False
                    
            except FileNotFoundError:
                self.logger.error("OpenVPNì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. VPN ìš°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            self.logger.error(f"VPN ì—°ê²° ì˜¤ë¥˜: {e}")
            return False
    
    def disconnect_vpn(self):
        """VPN ì—°ê²° ì¢…ë£Œ"""
        try:
            if self.current_process:
                self.current_process.terminate()
                time.sleep(2)
                if self.current_process.poll() is None:
                    self.current_process.kill()
                self.current_process = None
                self.logger.info("VPN ì—°ê²° ì¢…ë£Œ")
            
            if self.current_config and os.path.exists(self.current_config):
                os.unlink(self.current_config)
                self.current_config = None
                
        except Exception as e:
            self.logger.error(f"VPN ì¢…ë£Œ ì˜¤ë¥˜: {e}")

class URLExtractorVPN:
    """VPN ìš°íšŒ ê¸°ëŠ¥ì´ í¬í•¨ëœ URL ì¶”ì¶œê¸°"""
    
    def __init__(self, headless: bool = False):
        self.headless = headless
        self.driver = None
        self.logger = self.setup_logger()
        self.vpn_manager = VPNManager()
        self.vpn_countries = ['japan', 'korea', 'singapore']
    
    def setup_logger(self):
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger('URLExtractor')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def setup_driver(self):
        """ì›¹ë“œë¼ì´ë²„ ì„¤ì •"""
        try:
            options = Options()
            if self.headless:
                options.add_argument('--headless')
            
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            
            self.driver = webdriver.Chrome(options=options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            self.logger.info("ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            raise
    
    def close_driver(self):
        """ë“œë¼ì´ë²„ ë° VPN ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            self.driver = None
        self.vpn_manager.disconnect_vpn()
    
    def is_google_blocked(self) -> bool:
        """êµ¬ê¸€ ì°¨ë‹¨ ê°ì§€"""
        try:
            page_source = self.driver.page_source.lower()
            title = self.driver.title.lower()
            
            block_keywords = [
                'unusual traffic', 'captcha', 'blocked', 'automated queries',
                'suspicious activity', 'robot', 'ë¹„ì •ìƒì ì¸ íŠ¸ë˜í”½'
            ]
            
            for keyword in block_keywords:
                if keyword in page_source or keyword in title:
                    self.logger.warning(f"êµ¬ê¸€ ì°¨ë‹¨ ê°ì§€: {keyword}")
                    return True
            
            try:
                if self.driver.find_elements(By.CSS_SELECTOR, '#captcha, .captcha, .g-recaptcha'):
                    self.logger.warning("CAPTCHA ê°ì§€ë¨")
                    return True
            except:
                pass
            
            return False
        except:
            return False
    
    def try_vpn_bypass(self) -> bool:
        """VPN ìš°íšŒ ì‹œë„"""
        try:
            self.logger.info("ğŸ”§ VPN ìš°íšŒ ì‹œë„ ì¤‘...")
            
            for country in self.vpn_countries:
                self.logger.info(f"ğŸŒ VPN ì—°ê²° ì‹œë„: {country}")
                
                if self.vpn_manager.connect_vpn(country):
                    if self.driver:
                        self.driver.quit()
                    time.sleep(3)
                    self.setup_driver()
                    
                    try:
                        self.driver.get("https://www.google.com")
                        time.sleep(2)
                        
                        if not self.is_google_blocked():
                            self.logger.info(f"âœ… VPN ìš°íšŒ ì„±ê³µ: {country}")
                            return True
                        else:
                            self.logger.warning(f"âŒ {country} VPNìœ¼ë¡œë„ ì°¨ë‹¨ë¨")
                    except Exception as e:
                        self.logger.warning(f"VPN í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            
            self.logger.error("ëª¨ë“  VPN ì‹œë„ ì‹¤íŒ¨")
            return False
            
        except Exception as e:
            self.logger.error(f"VPN ìš°íšŒ ì˜¤ë¥˜: {e}")
            return False
    
    def search_with_google(self, organization_name: str) -> List[str]:
        """êµ¬ê¸€ ê²€ìƒ‰ (VPN ìš°íšŒ í¬í•¨)"""
        for attempt in range(2):
            try:
                query = f'{organization_name} í™ˆí˜ì´ì§€'
                url = f"https://www.google.com/search?q={quote_plus(query)}&hl=ko"
                self.driver.get(url)
                time.sleep(3)
                
                if self.is_google_blocked():
                    self.logger.warning(f"êµ¬ê¸€ ì°¨ë‹¨ ê°ì§€ (ì‹œë„ {attempt + 1}/2)")
                    if attempt == 0 and self.try_vpn_bypass():
                        continue
                    else:
                        break
                
                found_urls = []
                selectors = ['h3 a[href*="http"]', '.g a[href*="http"]', '.yuRUbf a[href*="http"]']
                
                for selector in selectors:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        for element in elements[:8]:
                            try:
                                href = element.get_attribute('href')
                                if not href or 'google.com' in href:
                                    continue
                                
                                if '/url?q=' in href:
                                    actual_url = self._extract_google_url(href)
                                    if actual_url:
                                        href = actual_url
                                
                                if self.is_valid_url(href, organization_name):
                                    found_urls.append(href)
                                    self.logger.info(f"êµ¬ê¸€ì—ì„œ ë°œê²¬: {href}")
                            except:
                                continue
                        if found_urls:
                            break
                    except:
                        continue
                
                return found_urls[:3]
                
            except Exception as e:
                self.logger.warning(f"êµ¬ê¸€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return []
    
    def _extract_google_url(self, google_url: str) -> Optional[str]:
        """êµ¬ê¸€ ë¦¬ë‹¤ì´ë ‰íŠ¸ URL ì¶”ì¶œ"""
        try:
            if '/url?q=' in google_url:
                parts = google_url.split('/url?q=')
                if len(parts) > 1:
                    url_part = parts[1].split('&')[0]
                    return unquote(url_part)
            return None
        except:
            return None
    
    def search_with_naver(self, organization_name: str) -> List[str]:
        """ë„¤ì´ë²„ ê²€ìƒ‰"""
        try:
            self.driver.get('https://www.naver.com')
            time.sleep(2)
            
            search_box = WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.ID, "query"))
            )
            
            query = f'{organization_name} í™ˆí˜ì´ì§€'
            search_box.clear()
            search_box.send_keys(query)
            search_box.send_keys(Keys.RETURN)
            time.sleep(3)
            
            found_urls = []
            selectors = ['h3.title a[href*="http"]', '.total_wrap a[href*="http"]']
            
            for selector in selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements[:8]:
                        try:
                            href = element.get_attribute('href')
                            if href and 'naver.com' not in href:
                                if self.is_valid_url(href, organization_name):
                                    found_urls.append(href)
                                    self.logger.info(f"ë„¤ì´ë²„ì—ì„œ ë°œê²¬: {href}")
                        except:
                            continue
                    if found_urls:
                        break
                except:
                    continue
            
            return found_urls[:3]
            
        except Exception as e:
            self.logger.warning(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def is_valid_url(self, url: str, organization_name: str) -> bool:
        """ìœ íš¨í•œ í™ˆí˜ì´ì§€ URLì¸ì§€ í™•ì¸"""
        try:
            if not url or len(url) < 10:
                return False
            
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                return False
            
            domain = parsed.netloc.lower()
            
            exclude_domains = [
                'youtube.com', 'facebook.com', 'instagram.com', 'twitter.com',
                'blog.naver.com', 'cafe.naver.com', 'tistory.com', 'blogspot.com'
            ]
            
            if any(ex in domain for ex in exclude_domains):
                return False
            
            if url.lower().endswith(('.pdf', '.jpg', '.png', '.gif')):
                return False
            
            if any(pattern in url.lower() for pattern in ['/board/', '/bbs/', '/community/']):
                return False
            
            official_tlds = ['.or.kr', '.go.kr', '.ac.kr', '.org', '.church']
            if any(tld in domain for tld in official_tlds):
                return True
            
            name_parts = re.findall(r'[ê°€-í£a-zA-Z]+', organization_name.lower())
            for part in name_parts:
                if len(part) > 2 and part in domain:
                    return True
            
            return len(domain) < 50
            
        except:
            return False
    
    def search_homepage(self, organization_name: str) -> Optional[str]:
        """í™ˆí˜ì´ì§€ ê²€ìƒ‰ (ë„¤ì´ë²„ + êµ¬ê¸€ + VPN ìš°íšŒ)"""
        try:
            if not self.driver:
                self.setup_driver()
            
            all_urls = []
            
            # ë„¤ì´ë²„ ê²€ìƒ‰
            self.logger.info(f"ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰: {organization_name}")
            naver_urls = self.search_with_naver(organization_name)
            all_urls.extend(naver_urls)
            
            time.sleep(random.uniform(2, 4))
            
            # êµ¬ê¸€ ê²€ìƒ‰ (VPN ìš°íšŒ í¬í•¨)
            self.logger.info(f"ğŸ” êµ¬ê¸€ ê²€ìƒ‰: {organization_name}")
            google_urls = self.search_with_google(organization_name)
            all_urls.extend(google_urls)
            
            if all_urls:
                unique_urls = list(set(all_urls))
                best_url = self.select_best_url(unique_urls, organization_name)
                self.logger.info(f"âœ… ìµœì¢… ì„ íƒ: {best_url}")
                return best_url
            
            self.logger.warning(f"âŒ í™ˆí˜ì´ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {organization_name}")
            return None
            
        except Exception as e:
            self.logger.error(f"í™ˆí˜ì´ì§€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None
    
    def select_best_url(self, urls: List[str], organization_name: str) -> str:
        """ìµœì  í™ˆí˜ì´ì§€ URL ì„ íƒ"""
        if not urls:
            return ""
        if len(urls) == 1:
            return urls[0]
        
        scored_urls = []
        for url in urls:
            score = 0
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            if '.or.kr' in domain:
                score += 20
            elif '.go.kr' in domain:
                score += 18
            elif '.ac.kr' in domain:
                score += 16
            elif '.church' in domain:
                score += 15
            elif '.org' in domain:
                score += 12
            elif '.com' in domain:
                score += 5
            
            name_parts = re.findall(r'[ê°€-í£a-zA-Z]+', organization_name.lower())
            for part in name_parts:
                if len(part) > 2 and part in domain:
                    score += 10
            
            path_depth = len([p for p in parsed.path.strip('/').split('/') if p])
            if path_depth == 0:
                score += 8
            elif path_depth <= 2:
                score += 5
            
            if parsed.scheme == 'https':
                score += 3
            
            scored_urls.append((url, score))
        
        scored_urls.sort(key=lambda x: x[1], reverse=True)
        return scored_urls[0][0]
    
    def process_organizations(self, organizations: List[Dict]) -> List[Dict]:
        """ê¸°ê´€ ëª©ë¡ ì²˜ë¦¬"""
        processed = []
        total = len(organizations)
        success = 0
        
        try:
            for i, org in enumerate(organizations, 1):
                try:
                    self.logger.info(f"ì²˜ë¦¬ ì¤‘ ({i}/{total}): {org.get('name', 'Unknown')}")
                    
                    org_copy = org.copy()
                    
                    if org.get('homepage') and org['homepage'].strip():
                        if org['homepage'].startswith(('http://', 'https://')):
                            processed.append(org_copy)
                            success += 1
                            continue
                    
                    homepage = self.search_homepage(org.get('name', ''))
                    
                    if homepage:
                        org_copy['homepage'] = homepage
                        success += 1
                        self.logger.info(f"âœ… í™ˆí˜ì´ì§€ ë°œê²¬: {homepage}")
                    else:
                        org_copy['homepage'] = ""
                        self.logger.warning("âŒ í™ˆí˜ì´ì§€ ê²€ìƒ‰ ì‹¤íŒ¨")
                    
                    processed.append(org_copy)
                    
                    if i % 5 == 0:
                        rate = success / i * 100
                        self.logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {success}/{i} ({rate:.1f}%)")
                    
                    if i < total:
                        time.sleep(random.uniform(2, 4))
                    
                except Exception as e:
                    self.logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    org_copy = org.copy()
                    if not org.get('homepage'):
                        org_copy['homepage'] = ""
                    processed.append(org_copy)
                    
        finally:
            self.close_driver()
        
        return processed

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 70)
    print("ğŸ” í™ˆí˜ì´ì§€ URL ì¶”ì¶œê¸° (VPN ìš°íšŒ ê¸°ëŠ¥ í¬í•¨)")
    print("=" * 70)
    
    try:
        use_headless = False
        print(f"ğŸŒ ë¸Œë¼ìš°ì € ëª¨ë“œ: {'Headless' if use_headless else 'GUI'}")
        print("ğŸ”§ VPN ìš°íšŒ: í™œì„±í™” (êµ¬ê¸€ ì°¨ë‹¨ ì‹œ ìë™ ì‹¤í–‰)")
        print("âš ï¸  OpenVPN ì„¤ì¹˜ ê¶Œì¥")
        
        extractor = URLExtractorVPN(headless=use_headless)
        
        input_file = r"C:\Users\kimyh\makedb\Python\cradcrawl_adv\undefined_converted_20250609_134731.json"
        output_file = f"urls_with_vpn_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {input_file}")
        print(f"ğŸ’¾ ì¶œë ¥ íŒŒì¼: {output_file}")
        
        if not os.path.exists(input_file):
            print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
            return 1
        
        with open(input_file, 'r', encoding='utf-8') as f:
            organizations = json.load(f)
        
        print(f"ğŸ“Š ë¡œë“œëœ ê¸°ê´€ ìˆ˜: {len(organizations)}")
        
        max_process = int(input(f"ì²˜ë¦¬í•  ê¸°ê´€ ìˆ˜ (ì „ì²´: {len(organizations)}, ì—”í„°=ì „ì²´): ") or len(organizations))
        organizations = organizations[:max_process]
        
        print(f"\nğŸ”„ {len(organizations)}ê°œ ê¸°ê´€ ì²˜ë¦¬ ì‹œì‘...")
        print("ğŸ“ ë„¤ì´ë²„ + êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ í™ˆí˜ì´ì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.")
        print("ğŸš€ êµ¬ê¸€ ì°¨ë‹¨ ì‹œ ìë™ìœ¼ë¡œ VPNì„ í†µí•´ ìš°íšŒí•©ë‹ˆë‹¤.")
        
        processed_organizations = extractor.process_organizations(organizations)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(processed_organizations, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_file}")
        
        homepage_found = sum(1 for org in processed_organizations if org.get('homepage') and org['homepage'].strip())
        success_rate = homepage_found / len(processed_organizations) * 100
        
        print(f"ğŸ“ˆ ìµœì¢… í†µê³„:")
        print(f"  - ì „ì²´ ê¸°ê´€: {len(processed_organizations)}ê°œ")
        print(f"  - í™ˆí˜ì´ì§€ ë°œê²¬: {homepage_found}ê°œ")
        print(f"  - ì„±ê³µë¥ : {success_rate:.1f}%")
        
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())