#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í¬ë¡¤ë§ ë°ì´í„° í†µê³„ ë¶„ì„ê¸°
JSON/Excel íŒŒì¼ì˜ í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ë‹¤ì–‘í•œ í†µê³„ë¥¼ ì œê³µí•˜ëŠ” ëª¨ë“ˆ
"""

import json
import os
import glob
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from collections import Counter, defaultdict
import traceback

from settings import (
    KOREAN_AREA_CODES,
    AREA_CODE_LENGTH_RULES,
    PORTAL_EMAIL_DOMAINS,
    GOVERNMENT_EMAIL_SUFFIXES,
    EDUCATION_EMAIL_SUFFIXES,
    BUSINESS_EMAIL_SUFFIXES,
    RELIGIOUS_EMAIL_KEYWORDS,
    get_area_name,
    format_phone_number,
    extract_phone_area_code
)

# Excel ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from openpyxl import load_workbook
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False
    print("âš ï¸ openpyxl ì—†ìŒ - Excel ë¶„ì„ ê¸°ëŠ¥ ë¹„í™œì„±í™”")

class DataStatisticsAnalyzer:
    """í¬ë¡¤ë§ ë°ì´í„° í†µê³„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # constants.pyì—ì„œ ì„í¬íŠ¸í•œ ìƒìˆ˜ë“¤ ì‚¬ìš©
        # self.korean_area_codesëŠ” ì´ì œ constants.KOREAN_AREA_CODESë¥¼ ì‚¬ìš©
        
        self.email_domains = {}
        self.phone_patterns = {}
        self.fax_patterns = {}
        
    def find_latest_files(self) -> Dict[str, Optional[str]]:
        """ìµœì‹  JSON ë° Excel íŒŒì¼ ì°¾ê¸°"""
        files = {
            'json': None,
            'excel': None
        }
        
        # JSON íŒŒì¼ ì°¾ê¸°
        json_pattern = "raw_data_with_homepages_*.json"
        json_files = glob.glob(json_pattern)
        if json_files:
            files['json'] = max(json_files, key=os.path.getctime)
            print(f"ğŸ“‚ JSON íŒŒì¼ ë°œê²¬: {files['json']}")
        
        # Excel íŒŒì¼ ì°¾ê¸°
        excel_pattern = "contact_data_*.xlsx"
        excel_files = glob.glob(excel_pattern)
        if excel_files:
            files['excel'] = max(excel_files, key=os.path.getctime)
            print(f"ğŸ“Š Excel íŒŒì¼ ë°œê²¬: {files['excel']}")
        
        return files
    
    def extract_phone_area_code(self, phone: str) -> Optional[str]:
        """ì „í™”ë²ˆí˜¸ì—ì„œ ì§€ì—­ì½”ë“œ ì¶”ì¶œ"""
        if not phone:
            return None
        
        # ìˆ«ìë§Œ ì¶”ì¶œ
        digits = re.sub(r'[^\d]', '', phone)
        
        # ì§€ì—­ì½”ë“œ ë§¤ì¹­
        for code, area in self.korean_area_codes.items():
            if digits.startswith(code):
                return code
        
        return None
    
    def validate_korean_phone(self, phone: str) -> Dict[str, Any]:
        """í•œêµ­ ì „í™”ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì¦"""
        if not phone:
            return {"is_valid": False, "reason": "ë²ˆí˜¸ ì—†ìŒ"}
        
        digits = re.sub(r'[^\d]', '', phone)
        
        # ê¸¸ì´ ì²´í¬
        if len(digits) < 9 or len(digits) > 11:
            return {"is_valid": False, "reason": "ê¸¸ì´ ì˜¤ë¥˜"}
        
        # ì§€ì—­ì½”ë“œ ì²´í¬
        area_code = self.extract_phone_area_code(phone)
        if not area_code:
            return {"is_valid": False, "reason": "ì§€ì—­ì½”ë“œ ì˜¤ë¥˜"}
        
        # ê¸¸ì´ë³„ ìœ íš¨ì„± ì²´í¬
        area_info = self.korean_area_codes[area_code]
        expected_lengths = {
            '02': [9, 10],  # ì„œìš¸
            '070': [11],    # ì¸í„°ë„·ì „í™”
            '010': [11], '017': [11]  # í•¸ë“œí°
        }
        
        if area_code in expected_lengths:
            if len(digits) not in expected_lengths[area_code]:
                return {"is_valid": False, "reason": "ê¸¸ì´ ë¶ˆì¼ì¹˜"}
        else:
            # ê¸°íƒ€ ì§€ì—­ë²ˆí˜¸ëŠ” 10-11ìë¦¬
            if len(digits) not in [10, 11]:
                return {"is_valid": False, "reason": "ê¸¸ì´ ë¶ˆì¼ì¹˜"}
        
        return {
            "is_valid": True,
            "area_code": area_code,
            "area_name": area_info,
            "formatted": self.format_phone_number(digits, area_code)
        }
    
    def format_phone_number(self, digits: str, area_code: str) -> str:
        """ì „í™”ë²ˆí˜¸ í¬ë§·íŒ… (constantsì˜ í•¨ìˆ˜ ì‚¬ìš©)"""
        return format_phone_number(digits, area_code)
    
    def extract_email_domain(self, email: str) -> Optional[str]:
        """ì´ë©”ì¼ì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
        if not email or '@' not in email:
            return None
        
        try:
            domain = email.split('@')[1].lower()
            return domain
        except:
            return None
    
    def categorize_email_domain(self, domain: str) -> str:
        """ì´ë©”ì¼ ë„ë©”ì¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (constantsì˜ ìƒìˆ˜ë“¤ ì‚¬ìš©)"""
        if not domain:
            return "ê¸°íƒ€"
        
        # constantsì˜ PORTAL_EMAIL_DOMAINS ì‚¬ìš©
        if domain in PORTAL_EMAIL_DOMAINS:
            return "í¬í„¸"
        
        # constantsì˜ GOVERNMENT_EMAIL_SUFFIXES ì‚¬ìš©
        if any(domain.endswith(suffix) for suffix in GOVERNMENT_EMAIL_SUFFIXES):
            return "ì •ë¶€/ê³µê³µ"
        
        # constantsì˜ EDUCATION_EMAIL_SUFFIXES ì‚¬ìš©
        if any(domain.endswith(suffix) for suffix in EDUCATION_EMAIL_SUFFIXES):
            return "êµìœ¡ê¸°ê´€"
        
        # constantsì˜ BUSINESS_EMAIL_SUFFIXES ì‚¬ìš©
        if any(domain.endswith(suffix) for suffix in BUSINESS_EMAIL_SUFFIXES):
            return "ê¸°ì—…/ì¡°ì§"
        
        # constantsì˜ RELIGIOUS_EMAIL_KEYWORDS ì‚¬ìš©
        if any(keyword in domain for keyword in RELIGIOUS_EMAIL_KEYWORDS):
            return "ì¢…êµê¸°ê´€"
        
        return "ê¸°íƒ€"
    
    def analyze_json_data(self, json_file: str) -> Dict[str, Any]:
        """JSON íŒŒì¼ ë°ì´í„° ë¶„ì„"""
        print(f"ğŸ” JSON ë°ì´í„° ë¶„ì„ ì‹œì‘: {json_file}")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # í†µê³„ ì´ˆê¸°í™”
            stats = {
                "file_info": {
                    "filename": json_file,
                    "analysis_time": datetime.now().isoformat()
                },
                "basic_stats": {},
                "categories": {},
                "contact_coverage": {},
                "quality_metrics": {},
                "geographic_distribution": {},
                "email_analysis": {}
            }
            
            # ì¹´ìš´í„° ì´ˆê¸°í™”
            total_orgs = 0
            phone_count = 0
            fax_count = 0
            email_count = 0
            url_count = 0
            complete_contact_count = 0  # ì „í™”+íŒ©ìŠ¤+ì´ë©”ì¼ ëª¨ë‘ ìˆëŠ” ê¸°ê´€
            
            valid_phones = 0
            valid_faxes = 0
            
            phone_areas = Counter()
            fax_areas = Counter()
            email_domains = Counter()
            
            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
            for category, organizations in data.items():
                category_stats = {
                    "count": len(organizations),
                    "phone_count": 0,
                    "fax_count": 0,
                    "email_count": 0,
                    "url_count": 0,
                    "complete_contact_count": 0  # ì „í™”+íŒ©ìŠ¤+ì´ë©”ì¼ ëª¨ë‘ ìˆëŠ” ê¸°ê´€
                }
                
                for org in organizations:
                    total_orgs += 1
                    
                    # ê¸°ë³¸ ì—°ë½ì²˜ ì •ë³´
                    phone = org.get("phone", "")
                    fax = org.get("fax", "")
                    url = org.get("homepage", "")
                    
                    # í™ˆí˜ì´ì§€ íŒŒì‹± ê²°ê³¼
                    homepage_content = org.get("homepage_content", {})
                    parsed_contact = homepage_content.get("parsed_contact", {})
                    
                    # ì „í™”ë²ˆí˜¸ ë¶„ì„
                    final_phone = phone
                    if not final_phone and parsed_contact.get("phones"):
                        final_phone = ", ".join(parsed_contact["phones"])
                    
                    if final_phone:
                        phone_count += 1
                        category_stats["phone_count"] += 1
                        
                        # ì²« ë²ˆì§¸ ì „í™”ë²ˆí˜¸ë§Œ ë¶„ì„ (ì—¬ëŸ¬ ê°œì¸ ê²½ìš°)
                        first_phone = final_phone.split(',')[0].strip()
                        phone_validation = self.validate_korean_phone(first_phone)
                        if phone_validation["is_valid"]:
                            valid_phones += 1
                            area_code = phone_validation["area_code"]
                            phone_areas[area_code] += 1
                    
                    # íŒ©ìŠ¤ë²ˆí˜¸ ë¶„ì„
                    final_fax = fax
                    if not final_fax and parsed_contact.get("faxes"):
                        final_fax = ", ".join(parsed_contact["faxes"])
                    
                    if final_fax:
                        fax_count += 1
                        category_stats["fax_count"] += 1
                        
                        # ì²« ë²ˆì§¸ íŒ©ìŠ¤ë²ˆí˜¸ë§Œ ë¶„ì„ (ì—¬ëŸ¬ ê°œì¸ ê²½ìš°)
                        first_fax = final_fax.split(',')[0].strip()
                        fax_validation = self.validate_korean_phone(first_fax)  # íŒ©ìŠ¤ë„ ì „í™”ë²ˆí˜¸ ê²€ì¦ ë¡œì§ ì‚¬ìš©
                        if fax_validation["is_valid"]:
                            valid_faxes += 1
                            area_code = fax_validation["area_code"]
                            fax_areas[area_code] += 1
                    
                    # ì´ë©”ì¼ ë¶„ì„
                    final_email = ""
                    if parsed_contact.get("emails"):
                        final_email = ", ".join(parsed_contact["emails"])
                    
                    if final_email:
                        email_count += 1
                        category_stats["email_count"] += 1
                        
                        # ì²« ë²ˆì§¸ ì´ë©”ì¼ë§Œ ë¶„ì„ (ì—¬ëŸ¬ ê°œì¸ ê²½ìš°)
                        first_email = final_email.split(',')[0].strip()
                        domain = self.extract_email_domain(first_email)
                        if domain:
                            email_domains[domain] += 1
                    
                    # URL ë¶„ì„
                    if url:
                        url_count += 1
                        category_stats["url_count"] += 1
                    
                    # ì™„ì „í•œ ì—°ë½ì²˜ ì •ë³´ ì²´í¬
                    if final_phone and final_fax and final_email:
                        complete_contact_count += 1
                        category_stats["complete_contact_count"] += 1
                
                stats["categories"][category] = category_stats
            
            # ê¸°ë³¸ í†µê³„
            stats["basic_stats"] = {
                "total_organizations": total_orgs,
                "total_categories": len(data),
                "complete_contacts": complete_contact_count
            }
            
            # ì—°ë½ì²˜ ì»¤ë²„ë¦¬ì§€
            stats["contact_coverage"] = {
                "phone": {"count": phone_count, "rate": round((phone_count / total_orgs * 100), 1) if total_orgs > 0 else 0},
                "fax": {"count": fax_count, "rate": round((fax_count / total_orgs * 100), 1) if total_orgs > 0 else 0},
                "email": {"count": email_count, "rate": round((email_count / total_orgs * 100), 1) if total_orgs > 0 else 0},
                "url": {"count": url_count, "rate": round((url_count / total_orgs * 100), 1) if total_orgs > 0 else 0}
            }
            
            # í’ˆì§ˆ ì§€í‘œ
            stats["quality_metrics"] = {
                "completeness_score": (complete_contact_count / total_orgs * 100) if total_orgs > 0 else 0,
                "phone_coverage": (phone_count / total_orgs * 100) if total_orgs > 0 else 0,
                "fax_coverage": (fax_count / total_orgs * 100) if total_orgs > 0 else 0,
                "email_coverage": (email_count / total_orgs * 100) if total_orgs > 0 else 0,
                "url_coverage": (url_count / total_orgs * 100) if total_orgs > 0 else 0,
                "phone_validity": (valid_phones / phone_count * 100) if phone_count > 0 else 0,
                "fax_validity": (valid_faxes / fax_count * 100) if fax_count > 0 else 0
            }
            
            # ì§€ì—­ ë¶„í¬ (constantsì˜ KOREAN_AREA_CODES ì‚¬ìš©)
            all_areas = Counter()
            all_areas.update(phone_areas)
            all_areas.update(fax_areas)
            
            stats["geographic_distribution"] = {
                area_code: {
                    "area_name": KOREAN_AREA_CODES[area_code],  # constants ì‚¬ìš©
                    "total_contacts": count,
                    "phone_count": phone_areas.get(area_code, 0),
                    "fax_count": fax_areas.get(area_code, 0)
                }
                for area_code, count in all_areas.most_common()
            }
            
            # ì´ë©”ì¼ ë„ë©”ì¸ ë¶„ì„
            email_categories = Counter()
            for domain, count in email_domains.most_common(50):  # ìƒìœ„ 50ê°œ ë„ë©”ì¸ë§Œ
                category = self.categorize_email_domain(domain)
                email_categories[category] += count
            
            stats["email_analysis"] = {
                "top_domains": dict(email_domains.most_common(20)),
                "domain_categories": dict(email_categories),
                "total_unique_domains": len(email_domains)
            }
            
            print(f"âœ… JSON ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
            print(f"ğŸ“Š ì´ ê¸°ê´€: {total_orgs:,}ê°œ")
            print(f"ğŸ“ ì „í™”ë²ˆí˜¸: {phone_count:,}ê°œ ({phone_count/total_orgs*100:.1f}%)")
            print(f"ğŸ“  íŒ©ìŠ¤ë²ˆí˜¸: {fax_count:,}ê°œ ({fax_count/total_orgs*100:.1f}%)")
            print(f"âœ‰ï¸ ì´ë©”ì¼: {email_count:,}ê°œ ({email_count/total_orgs*100:.1f}%)")
            print(f"ğŸŒ í™ˆí˜ì´ì§€: {url_count:,}ê°œ ({url_count/total_orgs*100:.1f}%)")
            
            return stats
            
        except Exception as e:
            print(f"âŒ JSON ë¶„ì„ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return {}
    
    def analyze_excel_data(self, excel_file: str) -> Dict[str, Any]:
        """Excel íŒŒì¼ ë°ì´í„° ë¶„ì„"""
        if not EXCEL_AVAILABLE:
            print("âš ï¸ Excel ë¶„ì„ ë¶ˆê°€ëŠ¥ - openpyxl ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”")
            return {}
        
        print(f"ğŸ“Š Excel ë°ì´í„° ë¶„ì„ ì‹œì‘: {excel_file}")
        
        try:
            wb = load_workbook(excel_file)
            ws = wb.active
            
            stats = {
                "file_info": {
                    "filename": excel_file,
                    "file_size": os.path.getsize(excel_file),
                    "analysis_time": datetime.now().isoformat(),
                    "total_rows": ws.max_row - 1  # í—¤ë” ì œì™¸
                },
                "column_analysis": {},
                "data_quality": {},
                "summary": {}
            }
            
            # í—¤ë” ë¶„ì„
            headers = [cell.value for cell in ws[1]]
            
            # ì»¬ëŸ¼ë³„ ë°ì´í„° ë¶„ì„
            column_stats = {}
            for col_idx, header in enumerate(headers, 1):
                if not header:
                    continue
                
                values = []
                non_empty_count = 0
                
                for row_idx in range(2, ws.max_row + 1):
                    cell_value = ws.cell(row=row_idx, column=col_idx).value
                    if cell_value and str(cell_value).strip():
                        values.append(str(cell_value).strip())
                        non_empty_count += 1
                
                column_stats[header] = {
                    "total_values": len(values),
                    "non_empty_count": non_empty_count,
                    "fill_rate": (non_empty_count / (ws.max_row - 1) * 100) if ws.max_row > 1 else 0,
                    "unique_values": len(set(values)),
                    "sample_values": values[:5] if values else []
                }
                
                # ì „í™”ë²ˆí˜¸/íŒ©ìŠ¤ë²ˆí˜¸ ì»¬ëŸ¼ íŠ¹ë³„ ë¶„ì„
                if "ì „í™”" in header or "phone" in header.lower():
                    valid_count = 0
                    area_distribution = Counter()
                    
                    for value in values:
                        validation = self.validate_korean_phone(value)
                        if validation["is_valid"]:
                            valid_count += 1
                            area_distribution[validation["area_code"]] += 1
                    
                    column_stats[header]["validation"] = {
                        "valid_count": valid_count,
                        "validity_rate": (valid_count / len(values) * 100) if values else 0,
                        "area_distribution": dict(area_distribution.most_common(5))
                    }
                
                # ì´ë©”ì¼ ì»¬ëŸ¼ íŠ¹ë³„ ë¶„ì„
                elif "ì´ë©”ì¼" in header or "email" in header.lower():
                    domain_distribution = Counter()
                    category_distribution = Counter()
                    
                    for value in values:
                        if '@' in value:
                            domain = self.extract_email_domain(value)
                            if domain:
                                domain_distribution[domain] += 1
                                category = self.categorize_email_domain(domain)
                                category_distribution[category] += 1
                    
                    column_stats[header]["analysis"] = {
                        "domain_distribution": dict(domain_distribution.most_common(5)),
                        "category_distribution": dict(category_distribution)
                    }
            
            stats["column_analysis"] = column_stats
            
            # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
            total_rows = ws.max_row - 1
            complete_rows = 0
            
            for row_idx in range(2, ws.max_row + 1):
                row_data = [ws.cell(row=row_idx, column=col).value for col in range(1, len(headers) + 1)]
                if all(data and str(data).strip() for data in row_data[:5]):  # ê¸°ë³¸ 5ê°œ ì»¬ëŸ¼ ì²´í¬
                    complete_rows += 1
            
            stats["data_quality"] = {
                "total_rows": total_rows,
                "complete_rows": complete_rows,
                "completeness_rate": (complete_rows / total_rows * 100) if total_rows > 0 else 0,
                "missing_data_rate": ((total_rows - complete_rows) / total_rows * 100) if total_rows > 0 else 0
            }
            
            # ìš”ì•½
            stats["summary"] = {
                "total_records": total_rows,
                "total_columns": len(headers),
                "data_completeness": round((complete_rows / total_rows * 100), 1) if total_rows > 0 else 0,
                "column_fill_rates": {
                    header: round(data["fill_rate"], 1) 
                    for header, data in column_stats.items()
                }
            }
            
            print(f"âœ… Excel ë¶„ì„ ì™„ë£Œ: {total_rows}ê°œ ë ˆì½”ë“œ ë¶„ì„")
            return stats
            
        except Exception as e:
            print(f"âŒ Excel ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return {}
    
    def generate_comprehensive_report(self, json_stats: Dict, excel_stats: Dict) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“‹ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        report = {
            "report_info": {
                "generated_at": datetime.now().isoformat(),
                "analysis_type": "comprehensive",
                "data_sources": []
            },
            "executive_summary": {},
            "detailed_analysis": {},
            "recommendations": [],
            "data_quality_score": 0
        }
        
        # ë°ì´í„° ì†ŒìŠ¤ ì •ë³´
        if json_stats:
            report["report_info"]["data_sources"].append({
                "type": "JSON",
                "file": json_stats.get("file_info", {}).get("filename", ""),
                "records": json_stats.get("summary", {}).get("total_organizations", 0)
            })
        
        if excel_stats:
            report["report_info"]["data_sources"].append({
                "type": "Excel", 
                "file": excel_stats.get("file_info", {}).get("filename", ""),
                "records": excel_stats.get("summary", {}).get("total_records", 0)
            })
        
        # ê²½ì˜ì§„ ìš”ì•½
        if json_stats:
            summary = json_stats.get("summary", {})
            quality = json_stats.get("quality_metrics", {})
            
            report["executive_summary"] = {
                "total_organizations": summary.get("total_organizations", 0),
                "contact_coverage": {
                    "phone": summary.get("coverage_rates", {}).get("phone", 0),
                    "fax": summary.get("coverage_rates", {}).get("fax", 0),
                    "email": summary.get("coverage_rates", {}).get("email", 0),
                    "url": summary.get("coverage_rates", {}).get("url", 0)
                },
                "data_quality": {
                    "phone_validity": quality.get("phone_validity", 0),
                    "fax_validity": quality.get("fax_validity", 0),
                    "completeness": quality.get("completeness_score", 0)
                },
                "top_regions": list(json_stats.get("geographic_distribution", {}).keys())[:5]
            }
        
        # ìƒì„¸ ë¶„ì„
        report["detailed_analysis"] = {
            "json_analysis": json_stats,
            "excel_analysis": excel_stats
        }
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []
        
        if json_stats:
            quality = json_stats.get("quality_metrics", {})
            
            if quality.get("phone_validity", 0) < 90:
                recommendations.append({
                    "priority": "high",
                    "category": "data_quality",
                    "issue": "ì „í™”ë²ˆí˜¸ ìœ íš¨ì„± ë‚®ìŒ",
                    "description": f"ì „í™”ë²ˆí˜¸ ìœ íš¨ì„±ì´ {quality.get('phone_validity', 0):.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.",
                    "action": "ì „í™”ë²ˆí˜¸ í˜•ì‹ ê²€ì¦ ë¡œì§ ê°•í™” í•„ìš”"
                })
            
            if quality.get("completeness_score", 0) < 50:
                recommendations.append({
                    "priority": "medium",
                    "category": "data_coverage",
                    "issue": "ì—°ë½ì²˜ ì •ë³´ ì™„ì„±ë„ ë‚®ìŒ",
                    "description": f"ì™„ì „í•œ ì—°ë½ì²˜ ì •ë³´ë¥¼ ê°€ì§„ ê¸°ê´€ì´ {quality.get('completeness_score', 0):.1f}%ì— ë¶ˆê³¼í•©ë‹ˆë‹¤.",
                    "action": "ì¶”ê°€ í¬ë¡¤ë§ ì†ŒìŠ¤ ë°œêµ´ ë˜ëŠ” ìˆ˜ë™ ë³´ì™„ í•„ìš”"
                })
            
            if quality.get("email_coverage", 0) < 30:
                recommendations.append({
                    "priority": "medium",
                    "category": "data_coverage", 
                    "issue": "ì´ë©”ì¼ ì •ë³´ ë¶€ì¡±",
                    "description": f"ì´ë©”ì¼ ì •ë³´ ë³´ìœ ìœ¨ì´ {quality.get('email_coverage', 0):.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.",
                    "action": "ì´ë©”ì¼ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ ê°œì„  ë˜ëŠ” ì¶”ê°€ ì†ŒìŠ¤ í™œìš©"
                })
        
        report["recommendations"] = recommendations
        
        # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        if json_stats:
            quality = json_stats.get("quality_metrics", {})
            coverage_score = (
                quality.get("phone_coverage", 0) + 
                quality.get("fax_coverage", 0) + 
                quality.get("email_coverage", 0) + 
                quality.get("url_coverage", 0)
            ) / 4
            
            validity_score = (
                quality.get("phone_validity", 0) + 
                quality.get("fax_validity", 0)
            ) / 2
            
            completeness_score = quality.get("completeness_score", 0)
            
            overall_score = (coverage_score * 0.4 + validity_score * 0.3 + completeness_score * 0.3)
            report["data_quality_score"] = round(overall_score, 1)
        
        print("âœ… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        return report
    
    def print_summary_report(self, stats: Dict[str, Any]):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ì½˜ì†” ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š í¬ë¡¤ë§ ë°ì´í„° í†µê³„ ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 80)
        
        if "summary" in stats:
            summary = stats["summary"]
            print(f"\nğŸ“ˆ ê¸°ë³¸ í†µê³„:")
            print(f"   ì´ ê¸°ê´€ ìˆ˜: {summary.get('total_organizations', 0):,}ê°œ")
            print(f"   ì¹´í…Œê³ ë¦¬ ìˆ˜: {summary.get('total_categories', 0)}ê°œ")
            
            print(f"\nğŸ“ ì—°ë½ì²˜ ë³´ìœ  í˜„í™©:")
            coverage = summary.get("coverage_rates", {})
            counts = summary.get("contact_counts", {})
            print(f"   ì „í™”ë²ˆí˜¸: {counts.get('phone', 0):,}ê°œ ({coverage.get('phone', 0)}%)")
            print(f"   íŒ©ìŠ¤ë²ˆí˜¸: {counts.get('fax', 0):,}ê°œ ({coverage.get('fax', 0)}%)")
            print(f"   ì´ë©”ì¼: {counts.get('email', 0):,}ê°œ ({coverage.get('email', 0)}%)")
            print(f"   í™ˆí˜ì´ì§€: {counts.get('url', 0):,}ê°œ ({coverage.get('url', 0)}%)")
            
            print(f"\nğŸ¯ ë°ì´í„° í’ˆì§ˆ ì§€í‘œ:")
            quality = summary.get("quality_scores", {})
            print(f"   ì „í™”ë²ˆí˜¸ ìœ íš¨ì„±: {quality.get('phone_validity', 0)}%")
            print(f"   íŒ©ìŠ¤ë²ˆí˜¸ ìœ íš¨ì„±: {quality.get('fax_validity', 0)}%")
            print(f"   ì •ë³´ ì™„ì„±ë„: {quality.get('completeness', 0)}%")
        
        if "geographic_distribution" in stats:
            print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ë¶„í¬ (ìƒìœ„ 5ê°œ):")
            geo_dist = stats["geographic_distribution"]
            for i, (code, info) in enumerate(list(geo_dist.items())[:5]):
                area_name = info.get("area_name", "ì•Œ ìˆ˜ ì—†ìŒ")
                total = info.get("total_contacts", 0)
                print(f"   {i+1}. {area_name}({code}): {total}ê°œ ì—°ë½ì²˜")
        
        if "contact_analysis" in stats:
            email_stats = stats["contact_analysis"].get("email_stats", {})
            if "category_distribution" in email_stats:
                print(f"\nğŸ“§ ì´ë©”ì¼ ë„ë©”ì¸ ë¶„ë¥˜:")
                for category, count in email_stats["category_distribution"].items():
                    print(f"   {category}: {count}ê°œ")
        
        print("\n" + "=" * 80)
    
    def save_report_to_json(self, report: Dict[str, Any], filename: Optional[str] = None) -> str:
        """ë¦¬í¬íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"data_analysis_report_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def get_api_summary(self, stats: Dict[str, Any]) -> Dict[str, Any]:
        """ì›¹ APIìš© ìš”ì•½ ë°ì´í„° ìƒì„±"""
        if not stats or "summary" not in stats:
            return {}
        
        summary = stats["summary"]
        quality = stats.get("quality_metrics", {})
        
        api_data = {
            "basic_stats": {
                "total_organizations": summary.get("total_organizations", 0),
                "total_categories": summary.get("total_categories", 0)
            },
            "contact_coverage": {
                "phone": {
                    "count": summary.get("contact_counts", {}).get("phone", 0),
                    "rate": summary.get("coverage_rates", {}).get("phone", 0)
                },
                "fax": {
                    "count": summary.get("contact_counts", {}).get("fax", 0),
                    "rate": summary.get("coverage_rates", {}).get("fax", 0)
                },
                "email": {
                    "count": summary.get("contact_counts", {}).get("email", 0),
                    "rate": summary.get("coverage_rates", {}).get("email", 0)
                },
                "url": {
                    "count": summary.get("contact_counts", {}).get("url", 0),
                    "rate": summary.get("coverage_rates", {}).get("url", 0)
                }
            },
            "quality_metrics": {
                "phone_validity": quality.get("phone_validity", 0),
                "fax_validity": quality.get("fax_validity", 0),
                "completeness_score": quality.get("completeness_score", 0),
                "overall_score": stats.get("data_quality_score", 0)
            },
            "top_regions": [],
            "email_categories": {}
        }
        
        # ìƒìœ„ ì§€ì—­ ì •ë³´
        if "geographic_distribution" in stats:
            geo_dist = stats["geographic_distribution"]
            api_data["top_regions"] = [
                {
                    "code": code,
                    "name": info.get("area_name", ""),
                    "contact_count": info.get("total_contacts", 0)
                }
                for code, info in list(geo_dist.items())[:5]
            ]
        
        # ì´ë©”ì¼ ì¹´í…Œê³ ë¦¬ ë¶„í¬
        if "contact_analysis" in stats:
            email_stats = stats["contact_analysis"].get("email_stats", {})
            if "category_distribution" in email_stats:
                api_data["email_categories"] = email_stats["category_distribution"]
        
        return api_data

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸ“Š í¬ë¡¤ë§ ë°ì´í„° í†µê³„ ë¶„ì„ê¸°")
    print("=" * 80)
    
    analyzer = DataStatisticsAnalyzer()
    
    # ìµœì‹  íŒŒì¼ ì°¾ê¸°
    files = analyzer.find_latest_files()
    
    if not files['json'] and not files['excel']:
        print("âŒ ë¶„ì„í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ raw_data_with_homepages_*.json ë˜ëŠ” contact_data_*.xlsx íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    # ë¶„ì„ ì‹¤í–‰
    json_stats = {}
    excel_stats = {}
    
    if files['json']:
        json_stats = analyzer.analyze_json_data(files['json'])
    
    if files['excel']:
        excel_stats = analyzer.analyze_excel_data(files['excel'])
    
    # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    if json_stats or excel_stats:
        comprehensive_report = analyzer.generate_comprehensive_report(json_stats, excel_stats)
        
        # ì½˜ì†” ì¶œë ¥
        if json_stats:
            analyzer.print_summary_report(json_stats)
        
        # JSON ë¦¬í¬íŠ¸ ì €ì¥
        report_file = analyzer.save_report_to_json(comprehensive_report)
        
        # APIìš© ìš”ì•½ ë°ì´í„° ìƒì„± (ì˜ˆì‹œ)
        if json_stats:
            api_summary = analyzer.get_api_summary(json_stats)
            print(f"\nğŸŒ APIìš© ìš”ì•½ ë°ì´í„° ìƒì„± ì™„ë£Œ (ì›¹ ì—°ë™ ì¤€ë¹„)")
            print(f"   ê¸°ê´€ ìˆ˜: {api_summary.get('basic_stats', {}).get('total_organizations', 0)}")
            print(f"   í’ˆì§ˆ ì ìˆ˜: {api_summary.get('quality_metrics', {}).get('overall_score', 0)}")
        
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ìƒì„¸ ë¦¬í¬íŠ¸: {report_file}")
    else:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 