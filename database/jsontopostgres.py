# json_to_postgres.py (ë¡œì»¬ì—ì„œ ìƒì„±)
import json
import psycopg2
import psycopg2.extras
from datetime import datetime

class JSONToPostgresMigrator:
    def __init__(self, json_file_path: str, postgres_url: str):
        self.json_file_path = json_file_path
        self.postgres_url = postgres_url
        
    def load_json_data(self):
        """JSON íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… JSON íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(data):,}ê°œ ë ˆì½”ë“œ")
            return data
        except Exception as e:
            print(f"âŒ JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def create_table(self, cursor):
        """PostgreSQL í…Œì´ë¸” ìƒì„±"""
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS organizations (
            id SERIAL PRIMARY KEY,
            name VARCHAR(200) NOT NULL,
            type VARCHAR(100) DEFAULT 'CHURCH',
            category VARCHAR(50) DEFAULT 'ì¢…êµì‹œì„¤',
            homepage TEXT,
            phone VARCHAR(100),
            fax VARCHAR(100),
            email VARCHAR(100),
            mobile VARCHAR(100),
            postal_code VARCHAR(10),
            address TEXT,
            organization_size VARCHAR(100),
            founding_year INTEGER,
            member_count INTEGER,
            denomination VARCHAR(100),
            contact_status VARCHAR(100) DEFAULT 'NEW',
            priority VARCHAR(50) DEFAULT 'MEDIUM',
            assigned_to VARCHAR(50),
            lead_source VARCHAR(50) DEFAULT 'DATABASE',
            estimated_value INTEGER DEFAULT 0,
            sales_notes TEXT,
            internal_notes TEXT,
            last_contact_date DATE,
            next_follow_up_date DATE,
            crawling_data JSONB,
            ai_crawled BOOLEAN DEFAULT FALSE,
            last_crawled_at TIMESTAMP,
            created_by VARCHAR(50),
            updated_by VARCHAR(50),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            is_active BOOLEAN DEFAULT TRUE
        );
        
        CREATE INDEX IF NOT EXISTS idx_organizations_name ON organizations(name);
        CREATE INDEX IF NOT EXISTS idx_organizations_type ON organizations(type);
        CREATE INDEX IF NOT EXISTS idx_organizations_is_active ON organizations(is_active);
        """
        
        cursor.execute(create_table_sql)
        print("âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
    
    def safe_get_value(self, row_dict, key: str, default=None):
        """ì•ˆì „í•˜ê²Œ ê°’ ê°€ì ¸ì˜¤ê¸°"""
        value = row_dict.get(key, default)
        if value == '' or value is None:
            return default
        return value
    
    def migrate_data(self, batch_size: int = 1000):
        """JSON ë°ì´í„°ë¥¼ PostgreSQLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        print("ğŸš€ JSON â†’ PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        json_data = self.load_json_data()
        if not json_data:
            return
        
        try:
            conn = psycopg2.connect(self.postgres_url)
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ìƒì„±
            self.create_table(cursor)
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            cursor.execute("SELECT COUNT(*) FROM organizations")
            existing_count = cursor.fetchone()[0]
            
            if existing_count > 0:
                print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° {existing_count:,}ê°œ ë°œê²¬")
                response = input("ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
                if response in ['y', 'yes']:
                    cursor.execute("TRUNCATE TABLE organizations RESTART IDENTITY")
                    print("ğŸ§¹ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
                else:
                    print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì·¨ì†Œ")
                    return
            
            # ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
            migrated_count = 0
            batch_data = []
            
            for i, row in enumerate(json_data):
                try:
                    # ë°ì´í„° ë§¤í•‘
                    insert_data = (
                        self.safe_get_value(row, 'name', ''),
                        self.safe_get_value(row, 'type', 'CHURCH'),
                        self.safe_get_value(row, 'category', 'ì¢…êµì‹œì„¤'),
                        self.safe_get_value(row, 'homepage'),
                        self.safe_get_value(row, 'phone'),
                        self.safe_get_value(row, 'fax'),
                        self.safe_get_value(row, 'email'),
                        self.safe_get_value(row, 'mobile'),
                        self.safe_get_value(row, 'postal_code'),
                        self.safe_get_value(row, 'address'),
                        self.safe_get_value(row, 'organization_size'),
                        self.safe_get_value(row, 'founding_year'),
                        self.safe_get_value(row, 'member_count'),
                        self.safe_get_value(row, 'denomination'),
                        self.safe_get_value(row, 'contact_status', 'NEW'),
                        self.safe_get_value(row, 'priority', 'MEDIUM'),
                        self.safe_get_value(row, 'assigned_to'),
                        self.safe_get_value(row, 'lead_source', 'DATABASE'),
                        self.safe_get_value(row, 'estimated_value', 0),
                        self.safe_get_value(row, 'sales_notes'),
                        self.safe_get_value(row, 'internal_notes'),
                        self.safe_get_value(row, 'last_contact_date'),
                        self.safe_get_value(row, 'next_follow_up_date'),
                        json.dumps(self.safe_get_value(row, 'crawling_data')) if row.get('crawling_data') else None,
                        bool(self.safe_get_value(row, 'ai_crawled', False)),
                        self.safe_get_value(row, 'last_crawled_at'),
                        self.safe_get_value(row, 'created_by'),
                        self.safe_get_value(row, 'updated_by'),
                        self.safe_get_value(row, 'created_at'),
                        self.safe_get_value(row, 'updated_at'),
                        bool(self.safe_get_value(row, 'is_active', True))
                    )
                    
                    batch_data.append(insert_data)
                    
                    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‚½ì…
                    if len(batch_data) >= batch_size:
                        cursor.executemany("""
                            INSERT INTO organizations (
                                name, type, category, homepage, phone, fax, email, mobile,
                                postal_code, address, organization_size, founding_year, 
                                member_count, denomination, contact_status, priority,
                                assigned_to, lead_source, estimated_value, sales_notes,
                                internal_notes, last_contact_date, next_follow_up_date,
                                crawling_data, ai_crawled, last_crawled_at, created_by,
                                updated_by, created_at, updated_at, is_active
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, batch_data)
                        
                        conn.commit()
                        migrated_count += len(batch_data)
                        batch_data = []
                        
                        # ì§„í–‰ ìƒí™© ì¶œë ¥
                        percentage = (migrated_count / len(json_data)) * 100
                        print(f"ğŸ“ˆ ì§„í–‰ë¥ : {migrated_count:,}/{len(json_data):,} ({percentage:.1f}%)")
                
                except Exception as e:
                    print(f"âŒ ë ˆì½”ë“œ {i} ì˜¤ë¥˜: {str(e)[:100]}")
            
            # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
            if batch_data:
                cursor.executemany("""
                    INSERT INTO organizations (
                        name, type, category, homepage, phone, fax, email, mobile,
                        postal_code, address, organization_size, founding_year, 
                        member_count, denomination, contact_status, priority,
                        assigned_to, lead_source, estimated_value, sales_notes,
                        internal_notes, last_contact_date, next_follow_up_date,
                        crawling_data, ai_crawled, last_crawled_at, created_by,
                        updated_by, created_at, updated_at, is_active
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, batch_data)
                conn.commit()
                migrated_count += len(batch_data)
            
            # ìµœì¢… ê²°ê³¼
            cursor.execute("SELECT COUNT(*) FROM organizations")
            final_count = cursor.fetchone()[0]
            
            print(f"\nğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
            print(f"ğŸ“Š ìµœì¢… PostgreSQL ë°ì´í„°: {final_count:,}ê°œ")
            print(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë°ì´í„°: {migrated_count:,}ê°œ")
            
        except Exception as e:
            print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            conn.rollback()
            raise
        finally:
            conn.close()

def main():
    json_file_path = "database/organizations_backup_utf8.json"
    postgres_url = "postgresql://isgs003:Smh213417!@localhost:5432/crad_db_local"
    
    print("ğŸ”„ JSON â†’ PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜")
    print("="*50)
    
    migrator = JSONToPostgresMigrator(json_file_path, postgres_url)
    
    try:
        start_time = datetime.now()
        migrator.migrate_data(batch_size=1000)
        end_time = datetime.now()
        
        print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {end_time - start_time}")
        
    except Exception as e:
        print(f"\nâŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()